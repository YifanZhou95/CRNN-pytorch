2018-03-08 18:07:24 start epoch 1/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:07:24 iter 1 loss = 96.907005
2018-03-08 18:07:28 iter 25 loss = 21.818222
2018-03-08 18:07:33 iter 50 loss = 17.193417
2018-03-08 18:07:37 iter 75 loss = 20.606865
2018-03-08 18:07:42 iter 100 loss = 18.535027
2018-03-08 18:07:46 iter 125 loss = 24.556904
2018-03-08 18:07:46 epoch 1/500 average_loss = 21.702228

2018-03-08 18:07:46 start epoch 2/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:07:47 iter 1 loss = 26.533051
2018-03-08 18:07:51 iter 25 loss = 21.041035
2018-03-08 18:07:55 iter 50 loss = 20.461063
2018-03-08 18:08:00 iter 75 loss = 16.269157
2018-03-08 18:08:04 iter 100 loss = 21.891045
2018-03-08 18:08:09 iter 125 loss = 20.312092
2018-03-08 18:08:09 epoch 2/500 average_loss = 20.379531

2018-03-08 18:08:09 start epoch 3/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:08:09 iter 1 loss = 18.489965
2018-03-08 18:08:13 iter 25 loss = 16.361383
2018-03-08 18:08:18 iter 50 loss = 20.025789
2018-03-08 18:08:22 iter 75 loss = 23.261982
2018-03-08 18:08:27 iter 100 loss = 20.925390
2018-03-08 18:08:31 iter 125 loss = 19.005007
2018-03-08 18:08:31 epoch 3/500 average_loss = 20.012179

2018-03-08 18:08:31 start epoch 4/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:08:32 iter 1 loss = 21.607689
2018-03-08 18:08:36 iter 25 loss = 16.429071
2018-03-08 18:08:40 iter 50 loss = 20.694752
2018-03-08 18:08:45 iter 75 loss = 18.467579
2018-03-08 18:08:49 iter 100 loss = 17.334642
2018-03-08 18:08:54 iter 125 loss = 20.920788
2018-03-08 18:08:54 epoch 4/500 average_loss = 19.734710

2018-03-08 18:08:54 start epoch 5/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:08:54 iter 1 loss = 19.723129
2018-03-08 18:08:59 iter 25 loss = 17.299231
2018-03-08 18:09:03 iter 50 loss = 22.247919
2018-03-08 18:09:08 iter 75 loss = 19.170950
2018-03-08 18:09:12 iter 100 loss = 14.935895
2018-03-08 18:09:16 iter 125 loss = 20.401230
2018-03-08 18:09:16 epoch 5/500 average_loss = 19.643488

2018-03-08 18:09:16 start epoch 6/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:09:17 iter 1 loss = 18.998177
2018-03-08 18:09:21 iter 25 loss = 21.725466
2018-03-08 18:09:26 iter 50 loss = 17.216059
2018-03-08 18:09:30 iter 75 loss = 20.651289
2018-03-08 18:09:35 iter 100 loss = 18.709543
2018-03-08 18:09:39 iter 125 loss = 19.292507
2018-03-08 18:09:39 epoch 6/500 average_loss = 19.549079

2018-03-08 18:09:39 start epoch 7/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:09:39 iter 1 loss = 20.185814
2018-03-08 18:09:44 iter 25 loss = 19.606697
2018-03-08 18:09:48 iter 50 loss = 21.079483
2018-03-08 18:09:53 iter 75 loss = 16.033066
2018-03-08 18:09:57 iter 100 loss = 25.426863
2018-03-08 18:10:02 iter 125 loss = 20.338842
2018-03-08 18:10:02 epoch 7/500 average_loss = 19.394553

2018-03-08 18:10:02 start epoch 8/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:10:02 iter 1 loss = 18.315308
2018-03-08 18:10:06 iter 25 loss = 20.289532
2018-03-08 18:10:11 iter 50 loss = 20.447617
2018-03-08 18:10:15 iter 75 loss = 19.170822
2018-03-08 18:10:20 iter 100 loss = 18.020023
2018-03-08 18:10:24 iter 125 loss = 17.022755
2018-03-08 18:10:24 epoch 8/500 average_loss = 19.364626

2018-03-08 18:10:24 start epoch 9/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:10:25 iter 1 loss = 19.259396
2018-03-08 18:10:29 iter 25 loss = 14.990511
2018-03-08 18:10:33 iter 50 loss = 25.319294
2018-03-08 18:10:38 iter 75 loss = 21.661901
2018-03-08 18:10:42 iter 100 loss = 24.603853
2018-03-08 18:10:47 iter 125 loss = 19.278440
2018-03-08 18:10:47 epoch 9/500 average_loss = 19.445845

2018-03-08 18:10:47 start epoch 10/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:10:47 iter 1 loss = 17.220890
2018-03-08 18:10:52 iter 25 loss = 24.243441
2018-03-08 18:10:56 iter 50 loss = 18.182663
2018-03-08 18:11:01 iter 75 loss = 21.816355
2018-03-08 18:11:05 iter 100 loss = 21.660894
2018-03-08 18:11:10 iter 125 loss = 20.544140
2018-03-08 18:11:10 epoch 10/500 average_loss = 19.354747

2018-03-08 18:11:10 start epoch 11/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:11:10 iter 1 loss = 16.688021
2018-03-08 18:11:14 iter 25 loss = 16.016275
2018-03-08 18:11:19 iter 50 loss = 15.731082
2018-03-08 18:11:23 iter 75 loss = 18.246149
2018-03-08 18:11:28 iter 100 loss = 16.308897
2018-03-08 18:11:32 iter 125 loss = 18.662148
2018-03-08 18:11:32 epoch 11/500 average_loss = 19.240181

2018-03-08 18:11:32 start epoch 12/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:11:33 iter 1 loss = 17.615854
2018-03-08 18:11:37 iter 25 loss = 21.921160
2018-03-08 18:11:41 iter 50 loss = 22.202631
2018-03-08 18:11:46 iter 75 loss = 17.209532
2018-03-08 18:11:50 iter 100 loss = 20.060696
2018-03-08 18:11:55 iter 125 loss = 14.996473
2018-03-08 18:11:55 epoch 12/500 average_loss = 19.181678

2018-03-08 18:11:55 start epoch 13/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:11:55 iter 1 loss = 19.337530
2018-03-08 18:12:00 iter 25 loss = 24.587700
2018-03-08 18:12:04 iter 50 loss = 18.049646
2018-03-08 18:12:09 iter 75 loss = 15.025309
2018-03-08 18:12:13 iter 100 loss = 20.541937
2018-03-08 18:12:18 iter 125 loss = 15.748579
2018-03-08 18:12:18 epoch 13/500 average_loss = 19.120072

2018-03-08 18:12:18 start epoch 14/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:12:18 iter 1 loss = 13.681462
2018-03-08 18:12:22 iter 25 loss = 19.741428
2018-03-08 18:12:27 iter 50 loss = 21.533895
2018-03-08 18:12:31 iter 75 loss = 19.097195
2018-03-08 18:12:36 iter 100 loss = 17.057045
2018-03-08 18:12:40 iter 125 loss = 20.175461
2018-03-08 18:12:40 epoch 14/500 average_loss = 19.311547

2018-03-08 18:12:40 start epoch 15/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:12:41 iter 1 loss = 16.152937
2018-03-08 18:12:45 iter 25 loss = 17.906172
2018-03-08 18:12:49 iter 50 loss = 16.757183
2018-03-08 18:12:54 iter 75 loss = 19.647318
2018-03-08 18:12:58 iter 100 loss = 18.772261
2018-03-08 18:13:03 iter 125 loss = 17.868559
2018-03-08 18:13:03 epoch 15/500 average_loss = 19.205155

2018-03-08 18:13:03 start epoch 16/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:13:03 iter 1 loss = 19.463636
2018-03-08 18:13:08 iter 25 loss = 21.082602
2018-03-08 18:13:12 iter 50 loss = 23.547485
2018-03-08 18:13:17 iter 75 loss = 15.301641
2018-03-08 18:13:21 iter 100 loss = 18.905497
2018-03-08 18:13:26 iter 125 loss = 15.617015
2018-03-08 18:13:26 epoch 16/500 average_loss = 19.175017

2018-03-08 18:13:26 start epoch 17/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:13:26 iter 1 loss = 20.420525
2018-03-08 18:13:30 iter 25 loss = 17.284172
2018-03-08 18:13:35 iter 50 loss = 19.748446
2018-03-08 18:13:39 iter 75 loss = 22.365223
2018-03-08 18:13:44 iter 100 loss = 19.982443
2018-03-08 18:13:48 iter 125 loss = 17.926483
2018-03-08 18:13:48 epoch 17/500 average_loss = 19.120209

2018-03-08 18:13:48 start epoch 18/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:13:49 iter 1 loss = 21.426739
2018-03-08 18:13:53 iter 25 loss = 16.000700
2018-03-08 18:13:57 iter 50 loss = 18.560854
2018-03-08 18:14:02 iter 75 loss = 19.947012
2018-03-08 18:14:06 iter 100 loss = 26.523966
2018-03-08 18:14:11 iter 125 loss = 18.168203
2018-03-08 18:14:11 epoch 18/500 average_loss = 19.103946

2018-03-08 18:14:11 start epoch 19/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:14:11 iter 1 loss = 21.810581
2018-03-08 18:14:16 iter 25 loss = 16.329515
2018-03-08 18:14:20 iter 50 loss = 19.093050
2018-03-08 18:14:25 iter 75 loss = 18.794382
2018-03-08 18:14:29 iter 100 loss = 21.079279
2018-03-08 18:14:34 iter 125 loss = 23.883137
2018-03-08 18:14:34 epoch 19/500 average_loss = 19.100337

2018-03-08 18:14:34 start epoch 20/500: learning_rate = 0.004 sequence_len = 28
2018-03-08 18:14:34 iter 1 loss = 24.423679
2018-03-08 18:14:38 iter 25 loss = 18.436615
2018-03-08 18:14:43 iter 50 loss = 21.617371
2018-03-08 18:14:47 iter 75 loss = 15.974052
2018-03-08 18:14:52 iter 100 loss = 19.562046
2018-03-08 18:14:56 iter 125 loss = 20.857098
2018-03-08 18:14:56 epoch 20/500 average_loss = 18.988795

2018-03-08 18:14:56 start epoch 21/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:14:57 iter 1 loss = 24.587269
2018-03-08 18:15:01 iter 25 loss = 20.581837
2018-03-08 18:15:06 iter 50 loss = 16.590490
2018-03-08 18:15:10 iter 75 loss = 19.278858
2018-03-08 18:15:15 iter 100 loss = 17.207766
2018-03-08 18:15:19 iter 125 loss = 18.604380
2018-03-08 18:15:19 epoch 21/500 average_loss = 18.926911

2018-03-08 18:15:19 start epoch 22/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:15:19 iter 1 loss = 17.395548
2018-03-08 18:15:24 iter 25 loss = 17.345572
2018-03-08 18:15:28 iter 50 loss = 15.964894
2018-03-08 18:15:33 iter 75 loss = 16.813143
2018-03-08 18:15:37 iter 100 loss = 19.638184
2018-03-08 18:15:42 iter 125 loss = 17.057049
2018-03-08 18:15:42 epoch 22/500 average_loss = 18.940365

2018-03-08 18:15:42 start epoch 23/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:15:42 iter 1 loss = 17.887699
2018-03-08 18:15:46 iter 25 loss = 19.762991
2018-03-08 18:15:51 iter 50 loss = 21.095530
2018-03-08 18:15:55 iter 75 loss = 19.271828
2018-03-08 18:16:00 iter 100 loss = 21.283695
2018-03-08 18:16:05 iter 125 loss = 20.569893
2018-03-08 18:16:05 epoch 23/500 average_loss = 18.916355

2018-03-08 18:16:05 start epoch 24/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:16:05 iter 1 loss = 20.357822
2018-03-08 18:16:09 iter 25 loss = 19.630209
2018-03-08 18:16:14 iter 50 loss = 20.071882
2018-03-08 18:16:18 iter 75 loss = 21.059841
2018-03-08 18:16:23 iter 100 loss = 23.801985
2018-03-08 18:16:27 iter 125 loss = 15.722183
2018-03-08 18:16:27 epoch 24/500 average_loss = 18.893069

2018-03-08 18:16:27 start epoch 25/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:16:27 iter 1 loss = 18.301058
2018-03-08 18:16:32 iter 25 loss = 20.871357
2018-03-08 18:16:36 iter 50 loss = 19.772747
2018-03-08 18:16:41 iter 75 loss = 21.994530
2018-03-08 18:16:45 iter 100 loss = 23.424194
2018-03-08 18:16:50 iter 125 loss = 21.507015
2018-03-08 18:16:50 epoch 25/500 average_loss = 18.857184

2018-03-08 18:16:50 start epoch 26/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:16:50 iter 1 loss = 20.352421
2018-03-08 18:16:54 iter 25 loss = 21.931208
2018-03-08 18:16:59 iter 50 loss = 21.915049
2018-03-08 18:17:03 iter 75 loss = 19.659956
2018-03-08 18:17:08 iter 100 loss = 17.427139
2018-03-08 18:17:12 iter 125 loss = 14.808034
2018-03-08 18:17:12 epoch 26/500 average_loss = 18.795920

2018-03-08 18:17:12 start epoch 27/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:17:13 iter 1 loss = 20.176662
2018-03-08 18:17:17 iter 25 loss = 17.413315
2018-03-08 18:17:22 iter 50 loss = 17.490746
2018-03-08 18:17:26 iter 75 loss = 20.943792
2018-03-08 18:17:31 iter 100 loss = 17.976830
2018-03-08 18:17:35 iter 125 loss = 19.306358
2018-03-08 18:17:35 epoch 27/500 average_loss = 18.801411

2018-03-08 18:17:35 start epoch 28/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:17:35 iter 1 loss = 18.945868
2018-03-08 18:17:40 iter 25 loss = 22.601673
2018-03-08 18:17:44 iter 50 loss = 17.123808
2018-03-08 18:17:49 iter 75 loss = 13.992483
2018-03-08 18:17:53 iter 100 loss = 19.690886
2018-03-08 18:17:58 iter 125 loss = 19.110338
2018-03-08 18:17:58 epoch 28/500 average_loss = 18.768891

2018-03-08 18:17:58 start epoch 29/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:17:58 iter 1 loss = 18.442415
2018-03-08 18:18:03 iter 25 loss = 16.884558
2018-03-08 18:18:07 iter 50 loss = 16.049156
2018-03-08 18:18:12 iter 75 loss = 19.890194
2018-03-08 18:18:16 iter 100 loss = 15.062999
2018-03-08 18:18:21 iter 125 loss = 17.109697
2018-03-08 18:18:21 epoch 29/500 average_loss = 18.716427

2018-03-08 18:18:21 start epoch 30/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:18:21 iter 1 loss = 18.864908
2018-03-08 18:18:25 iter 25 loss = 18.517855
2018-03-08 18:18:30 iter 50 loss = 16.272306
2018-03-08 18:18:34 iter 75 loss = 18.067764
2018-03-08 18:18:39 iter 100 loss = 18.805630
2018-03-08 18:18:43 iter 125 loss = 20.529049
2018-03-08 18:18:43 epoch 30/500 average_loss = 18.768778

2018-03-08 18:18:43 start epoch 31/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:18:44 iter 1 loss = 17.340546
2018-03-08 18:18:48 iter 25 loss = 17.198406
2018-03-08 18:18:53 iter 50 loss = 16.136002
2018-03-08 18:18:57 iter 75 loss = 19.782818
2018-03-08 18:19:02 iter 100 loss = 20.639658
2018-03-08 18:19:06 iter 125 loss = 17.391457
2018-03-08 18:19:06 epoch 31/500 average_loss = 18.744273

2018-03-08 18:19:06 start epoch 32/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:19:06 iter 1 loss = 16.093695
2018-03-08 18:19:11 iter 25 loss = 18.894547
2018-03-08 18:19:15 iter 50 loss = 17.564325
2018-03-08 18:19:20 iter 75 loss = 20.091867
2018-03-08 18:19:24 iter 100 loss = 18.337364
2018-03-08 18:19:29 iter 125 loss = 19.476824
2018-03-08 18:19:29 epoch 32/500 average_loss = 18.728049

2018-03-08 18:19:29 start epoch 33/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:19:29 iter 1 loss = 15.590405
2018-03-08 18:19:33 iter 25 loss = 18.044168
2018-03-08 18:19:38 iter 50 loss = 24.050549
2018-03-08 18:19:42 iter 75 loss = 17.745285
2018-03-08 18:19:47 iter 100 loss = 17.943399
2018-03-08 18:19:51 iter 125 loss = 15.284894
2018-03-08 18:19:51 epoch 33/500 average_loss = 18.787207

2018-03-08 18:19:51 start epoch 34/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:19:52 iter 1 loss = 19.105127
2018-03-08 18:19:56 iter 25 loss = 15.023628
2018-03-08 18:20:01 iter 50 loss = 18.104265
2018-03-08 18:20:05 iter 75 loss = 20.248020
2018-03-08 18:20:10 iter 100 loss = 15.971252
2018-03-08 18:20:14 iter 125 loss = 21.629923
2018-03-08 18:20:14 epoch 34/500 average_loss = 18.734797

2018-03-08 18:20:14 start epoch 35/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:20:14 iter 1 loss = 14.889001
2018-03-08 18:20:19 iter 25 loss = 21.106504
2018-03-08 18:20:23 iter 50 loss = 18.045250
2018-03-08 18:20:28 iter 75 loss = 17.343891
2018-03-08 18:20:32 iter 100 loss = 19.163370
2018-03-08 18:20:37 iter 125 loss = 20.942602
2018-03-08 18:20:37 epoch 35/500 average_loss = 18.659879

2018-03-08 18:20:37 start epoch 36/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:20:37 iter 1 loss = 19.180975
2018-03-08 18:20:41 iter 25 loss = 15.712568
2018-03-08 18:20:46 iter 50 loss = 18.054674
2018-03-08 18:20:50 iter 75 loss = 19.255587
2018-03-08 18:20:55 iter 100 loss = 18.615814
2018-03-08 18:20:59 iter 125 loss = 17.953758
2018-03-08 18:20:59 epoch 36/500 average_loss = 18.646466

2018-03-08 18:20:59 start epoch 37/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:21:00 iter 1 loss = 16.449627
2018-03-08 18:21:04 iter 25 loss = 21.040869
2018-03-08 18:21:09 iter 50 loss = 16.251141
2018-03-08 18:21:13 iter 75 loss = 21.001343
2018-03-08 18:21:18 iter 100 loss = 16.869822
2018-03-08 18:21:22 iter 125 loss = 18.351660
2018-03-08 18:21:22 epoch 37/500 average_loss = 18.679304

2018-03-08 18:21:22 start epoch 38/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:21:22 iter 1 loss = 21.196295
2018-03-08 18:21:27 iter 25 loss = 23.386240
2018-03-08 18:21:31 iter 50 loss = 17.486670
2018-03-08 18:21:36 iter 75 loss = 21.249546
2018-03-08 18:21:40 iter 100 loss = 22.835787
2018-03-08 18:21:45 iter 125 loss = 16.963566
2018-03-08 18:21:45 epoch 38/500 average_loss = 18.619823

2018-03-08 18:21:45 start epoch 39/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:21:45 iter 1 loss = 19.213383
2018-03-08 18:21:49 iter 25 loss = 18.422955
2018-03-08 18:21:54 iter 50 loss = 22.456528
2018-03-08 18:21:58 iter 75 loss = 16.972254
2018-03-08 18:22:03 iter 100 loss = 16.338703
2018-03-08 18:22:07 iter 125 loss = 21.626093
2018-03-08 18:22:07 epoch 39/500 average_loss = 18.572391

2018-03-08 18:22:07 start epoch 40/500: learning_rate = 0.0032 sequence_len = 28
2018-03-08 18:22:08 iter 1 loss = 19.282585
2018-03-08 18:22:12 iter 25 loss = 16.855383
2018-03-08 18:22:17 iter 50 loss = 24.739716
2018-03-08 18:22:21 iter 75 loss = 16.310162
2018-03-08 18:22:26 iter 100 loss = 21.767387
2018-03-08 18:22:30 iter 125 loss = 19.889860
2018-03-08 18:22:30 epoch 40/500 average_loss = 18.578565

2018-03-08 18:22:30 start epoch 41/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:22:30 iter 1 loss = 15.625856
2018-03-08 18:22:35 iter 25 loss = 15.109112
2018-03-08 18:22:39 iter 50 loss = 16.681295
2018-03-08 18:22:44 iter 75 loss = 19.291393
2018-03-08 18:22:48 iter 100 loss = 16.795168
2018-03-08 18:22:53 iter 125 loss = 19.505007
2018-03-08 18:22:53 epoch 41/500 average_loss = 18.496672

2018-03-08 18:22:53 start epoch 42/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:22:53 iter 1 loss = 15.521307
2018-03-08 18:22:57 iter 25 loss = 22.728134
2018-03-08 18:23:02 iter 50 loss = 18.106243
2018-03-08 18:23:06 iter 75 loss = 13.986211
2018-03-08 18:23:11 iter 100 loss = 21.710064
2018-03-08 18:23:15 iter 125 loss = 21.373131
2018-03-08 18:23:15 epoch 42/500 average_loss = 18.509217

2018-03-08 18:23:15 start epoch 43/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:23:16 iter 1 loss = 20.456905
2018-03-08 18:23:20 iter 25 loss = 19.325586
2018-03-08 18:23:25 iter 50 loss = 16.135363
2018-03-08 18:23:29 iter 75 loss = 15.176552
2018-03-08 18:23:34 iter 100 loss = 19.654345
2018-03-08 18:23:38 iter 125 loss = 17.777800
2018-03-08 18:23:38 epoch 43/500 average_loss = 18.419554

2018-03-08 18:23:38 start epoch 44/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:23:39 iter 1 loss = 16.381498
2018-03-08 18:23:43 iter 25 loss = 18.029652
2018-03-08 18:23:47 iter 50 loss = 17.291933
2018-03-08 18:23:52 iter 75 loss = 18.222658
2018-03-08 18:23:56 iter 100 loss = 21.367764
2018-03-08 18:24:01 iter 125 loss = 20.403519
2018-03-08 18:24:01 epoch 44/500 average_loss = 18.408189

2018-03-08 18:24:01 start epoch 45/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:24:01 iter 1 loss = 19.338821
2018-03-08 18:24:06 iter 25 loss = 15.850437
2018-03-08 18:24:10 iter 50 loss = 19.977854
2018-03-08 18:24:15 iter 75 loss = 16.553030
2018-03-08 18:24:19 iter 100 loss = 16.530170
2018-03-08 18:24:24 iter 125 loss = 16.400578
2018-03-08 18:24:24 epoch 45/500 average_loss = 18.423968

2018-03-08 18:24:24 start epoch 46/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:24:24 iter 1 loss = 19.391357
2018-03-08 18:24:28 iter 25 loss = 16.910076
2018-03-08 18:24:33 iter 50 loss = 20.063957
2018-03-08 18:24:37 iter 75 loss = 13.754360
2018-03-08 18:24:42 iter 100 loss = 15.202701
2018-03-08 18:24:46 iter 125 loss = 16.571690
2018-03-08 18:24:46 epoch 46/500 average_loss = 18.380453

2018-03-08 18:24:46 start epoch 47/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:24:47 iter 1 loss = 17.006691
2018-03-08 18:24:51 iter 25 loss = 19.051575
2018-03-08 18:24:56 iter 50 loss = 15.697043
2018-03-08 18:25:00 iter 75 loss = 19.637981
2018-03-08 18:25:05 iter 100 loss = 20.460161
2018-03-08 18:25:09 iter 125 loss = 15.951268
2018-03-08 18:25:09 epoch 47/500 average_loss = 18.405203

2018-03-08 18:25:09 start epoch 48/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:25:09 iter 1 loss = 20.259798
2018-03-08 18:25:14 iter 25 loss = 18.257370
2018-03-08 18:25:18 iter 50 loss = 16.535828
2018-03-08 18:25:23 iter 75 loss = 20.225555
2018-03-08 18:25:27 iter 100 loss = 17.678154
2018-03-08 18:25:32 iter 125 loss = 18.646572
2018-03-08 18:25:32 epoch 48/500 average_loss = 18.432787

2018-03-08 18:25:32 start epoch 49/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:25:32 iter 1 loss = 19.324715
2018-03-08 18:25:37 iter 25 loss = 18.941151
2018-03-08 18:25:41 iter 50 loss = 20.142700
2018-03-08 18:25:46 iter 75 loss = 14.573767
2018-03-08 18:25:50 iter 100 loss = 18.367981
2018-03-08 18:25:55 iter 125 loss = 15.617344
2018-03-08 18:25:55 epoch 49/500 average_loss = 18.336332

2018-03-08 18:25:55 start epoch 50/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:25:55 iter 1 loss = 24.878195
2018-03-08 18:25:59 iter 25 loss = 18.095432
2018-03-08 18:26:04 iter 50 loss = 16.208488
2018-03-08 18:26:08 iter 75 loss = 20.473261
2018-03-08 18:26:13 iter 100 loss = 16.566021
2018-03-08 18:26:17 iter 125 loss = 20.776928
2018-03-08 18:26:17 epoch 50/500 average_loss = 18.308057

2018-03-08 18:26:17 start epoch 51/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:26:18 iter 1 loss = 17.870350
2018-03-08 18:26:22 iter 25 loss = 20.761621
2018-03-08 18:26:26 iter 50 loss = 20.726562
2018-03-08 18:26:31 iter 75 loss = 19.939409
2018-03-08 18:26:35 iter 100 loss = 19.567242
2018-03-08 18:26:40 iter 125 loss = 16.712343
2018-03-08 18:26:40 epoch 51/500 average_loss = 18.311938

2018-03-08 18:26:40 start epoch 52/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:26:40 iter 1 loss = 19.153397
2018-03-08 18:26:45 iter 25 loss = 17.905764
2018-03-08 18:26:49 iter 50 loss = 19.918823
2018-03-08 18:26:54 iter 75 loss = 16.298046
2018-03-08 18:26:58 iter 100 loss = 21.062960
2018-03-08 18:27:03 iter 125 loss = 18.365662
2018-03-08 18:27:03 epoch 52/500 average_loss = 18.224226

2018-03-08 18:27:03 start epoch 53/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:27:03 iter 1 loss = 17.263386
2018-03-08 18:27:07 iter 25 loss = 16.501125
2018-03-08 18:27:12 iter 50 loss = 23.574377
2018-03-08 18:27:16 iter 75 loss = 22.282398
2018-03-08 18:27:21 iter 100 loss = 20.397583
2018-03-08 18:27:25 iter 125 loss = 20.043940
2018-03-08 18:27:25 epoch 53/500 average_loss = 18.226692

2018-03-08 18:27:25 start epoch 54/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:27:26 iter 1 loss = 17.922857
2018-03-08 18:27:30 iter 25 loss = 19.507074
2018-03-08 18:27:35 iter 50 loss = 16.259436
2018-03-08 18:27:39 iter 75 loss = 16.626045
2018-03-08 18:27:44 iter 100 loss = 16.895758
2018-03-08 18:27:48 iter 125 loss = 19.328796
2018-03-08 18:27:48 epoch 54/500 average_loss = 18.201606

2018-03-08 18:27:48 start epoch 55/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:27:48 iter 1 loss = 20.195761
2018-03-08 18:27:53 iter 25 loss = 20.929749
2018-03-08 18:27:57 iter 50 loss = 18.971972
2018-03-08 18:28:02 iter 75 loss = 18.540499
2018-03-08 18:28:06 iter 100 loss = 17.132050
2018-03-08 18:28:11 iter 125 loss = 16.685740
2018-03-08 18:28:11 epoch 55/500 average_loss = 18.120784

2018-03-08 18:28:11 start epoch 56/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:28:11 iter 1 loss = 16.828707
2018-03-08 18:28:15 iter 25 loss = 20.727123
2018-03-08 18:28:20 iter 50 loss = 20.588800
2018-03-08 18:28:25 iter 75 loss = 16.947920
2018-03-08 18:28:29 iter 100 loss = 18.045841
2018-03-08 18:28:34 iter 125 loss = 22.339849
2018-03-08 18:28:34 epoch 56/500 average_loss = 18.182057

2018-03-08 18:28:34 start epoch 57/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:28:34 iter 1 loss = 20.513094
2018-03-08 18:28:38 iter 25 loss = 19.291084
2018-03-08 18:28:43 iter 50 loss = 14.960169
2018-03-08 18:28:47 iter 75 loss = 22.779753
2018-03-08 18:28:52 iter 100 loss = 19.614965
2018-03-08 18:28:56 iter 125 loss = 17.464609
2018-03-08 18:28:56 epoch 57/500 average_loss = 18.183821

2018-03-08 18:28:56 start epoch 58/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:28:57 iter 1 loss = 18.164293
2018-03-08 18:29:01 iter 25 loss = 17.495842
2018-03-08 18:29:05 iter 50 loss = 16.451752
2018-03-08 18:29:10 iter 75 loss = 20.996387
2018-03-08 18:29:14 iter 100 loss = 24.477036
2018-03-08 18:29:19 iter 125 loss = 19.244669
2018-03-08 18:29:19 epoch 58/500 average_loss = 18.054759

2018-03-08 18:29:19 start epoch 59/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:29:19 iter 1 loss = 16.281643
2018-03-08 18:29:24 iter 25 loss = 18.329134
2018-03-08 18:29:28 iter 50 loss = 21.285471
2018-03-08 18:29:33 iter 75 loss = 16.603483
2018-03-08 18:29:37 iter 100 loss = 18.107374
2018-03-08 18:29:42 iter 125 loss = 20.123043
2018-03-08 18:29:42 epoch 59/500 average_loss = 18.082892

2018-03-08 18:29:42 start epoch 60/500: learning_rate = 0.0025600000000000006 sequence_len = 28
2018-03-08 18:29:42 iter 1 loss = 15.938325
2018-03-08 18:29:46 iter 25 loss = 17.247881
2018-03-08 18:29:51 iter 50 loss = 16.061680
2018-03-08 18:29:55 iter 75 loss = 19.950865
2018-03-08 18:30:00 iter 100 loss = 18.064140
2018-03-08 18:30:04 iter 125 loss = 17.096516
2018-03-08 18:30:04 epoch 60/500 average_loss = 18.067366

2018-03-08 18:30:04 start epoch 61/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:30:05 iter 1 loss = 19.352037
2018-03-08 18:30:09 iter 25 loss = 20.288351
2018-03-08 18:30:14 iter 50 loss = 16.009926
2018-03-08 18:30:18 iter 75 loss = 15.982824
2018-03-08 18:30:23 iter 100 loss = 21.429686
2018-03-08 18:30:27 iter 125 loss = 17.947668
2018-03-08 18:30:27 epoch 61/500 average_loss = 17.944531

2018-03-08 18:30:27 start epoch 62/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:30:28 iter 1 loss = 16.156906
2018-03-08 18:30:32 iter 25 loss = 17.113073
2018-03-08 18:30:36 iter 50 loss = 18.036512
2018-03-08 18:30:41 iter 75 loss = 19.500742
2018-03-08 18:30:46 iter 100 loss = 16.956022
2018-03-08 18:30:50 iter 125 loss = 16.235659
2018-03-08 18:30:50 epoch 62/500 average_loss = 17.909244

2018-03-08 18:30:50 start epoch 63/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:30:50 iter 1 loss = 16.295776
2018-03-08 18:30:55 iter 25 loss = 19.836472
2018-03-08 18:30:59 iter 50 loss = 15.230442
2018-03-08 18:31:04 iter 75 loss = 15.138105
2018-03-08 18:31:08 iter 100 loss = 17.947798
2018-03-08 18:31:13 iter 125 loss = 16.794584
2018-03-08 18:31:13 epoch 63/500 average_loss = 17.843274

2018-03-08 18:31:13 start epoch 64/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:31:13 iter 1 loss = 21.447897
2018-03-08 18:31:17 iter 25 loss = 18.222902
2018-03-08 18:31:22 iter 50 loss = 14.529103
2018-03-08 18:31:26 iter 75 loss = 16.579279
2018-03-08 18:31:31 iter 100 loss = 22.289890
2018-03-08 18:31:35 iter 125 loss = 16.117371
2018-03-08 18:31:35 epoch 64/500 average_loss = 17.879154

2018-03-08 18:31:35 start epoch 65/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:31:36 iter 1 loss = 15.769674
2018-03-08 18:31:40 iter 25 loss = 20.530619
2018-03-08 18:31:45 iter 50 loss = 16.807001
2018-03-08 18:31:49 iter 75 loss = 21.219025
2018-03-08 18:31:54 iter 100 loss = 14.894098
2018-03-08 18:31:58 iter 125 loss = 20.792627
2018-03-08 18:31:58 epoch 65/500 average_loss = 17.824391

2018-03-08 18:31:58 start epoch 66/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:31:58 iter 1 loss = 17.760334
2018-03-08 18:32:03 iter 25 loss = 17.915472
2018-03-08 18:32:07 iter 50 loss = 20.022480
2018-03-08 18:32:12 iter 75 loss = 15.741132
2018-03-08 18:32:16 iter 100 loss = 16.055363
2018-03-08 18:32:21 iter 125 loss = 20.308756
2018-03-08 18:32:21 epoch 66/500 average_loss = 17.840713

2018-03-08 18:32:21 start epoch 67/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:32:21 iter 1 loss = 17.762506
2018-03-08 18:32:25 iter 25 loss = 19.061451
2018-03-08 18:32:30 iter 50 loss = 14.455230
2018-03-08 18:32:34 iter 75 loss = 18.829185
2018-03-08 18:32:39 iter 100 loss = 16.529369
2018-03-08 18:32:44 iter 125 loss = 17.495474
2018-03-08 18:32:44 epoch 67/500 average_loss = 17.784505

2018-03-08 18:32:44 start epoch 68/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:32:44 iter 1 loss = 16.895840
2018-03-08 18:32:48 iter 25 loss = 18.129259
2018-03-08 18:32:53 iter 50 loss = 14.914793
2018-03-08 18:32:57 iter 75 loss = 20.654766
2018-03-08 18:33:02 iter 100 loss = 19.759432
2018-03-08 18:33:06 iter 125 loss = 15.861520
2018-03-08 18:33:06 epoch 68/500 average_loss = 17.768990

2018-03-08 18:33:06 start epoch 69/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:33:07 iter 1 loss = 15.640811
2018-03-08 18:33:11 iter 25 loss = 14.449934
2018-03-08 18:33:15 iter 50 loss = 18.357246
2018-03-08 18:33:20 iter 75 loss = 17.051485
2018-03-08 18:33:24 iter 100 loss = 17.046852
2018-03-08 18:33:29 iter 125 loss = 18.245668
2018-03-08 18:33:29 epoch 69/500 average_loss = 17.808848

2018-03-08 18:33:29 start epoch 70/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:33:29 iter 1 loss = 17.736105
2018-03-08 18:33:34 iter 25 loss = 16.437263
2018-03-08 18:33:38 iter 50 loss = 18.022259
2018-03-08 18:33:43 iter 75 loss = 18.960682
2018-03-08 18:33:47 iter 100 loss = 14.296585
2018-03-08 18:33:52 iter 125 loss = 14.166307
2018-03-08 18:33:52 epoch 70/500 average_loss = 17.727749

2018-03-08 18:33:52 start epoch 71/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:33:52 iter 1 loss = 19.613714
2018-03-08 18:33:56 iter 25 loss = 19.399326
2018-03-08 18:34:01 iter 50 loss = 16.115746
2018-03-08 18:34:05 iter 75 loss = 18.847385
2018-03-08 18:34:10 iter 100 loss = 16.744034
2018-03-08 18:34:15 iter 125 loss = 16.789383
2018-03-08 18:34:15 epoch 71/500 average_loss = 17.678187

2018-03-08 18:34:15 start epoch 72/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:34:15 iter 1 loss = 16.829372
2018-03-08 18:34:19 iter 25 loss = 19.241793
2018-03-08 18:34:24 iter 50 loss = 19.999062
2018-03-08 18:34:28 iter 75 loss = 23.783846
2018-03-08 18:34:33 iter 100 loss = 19.640339
2018-03-08 18:34:37 iter 125 loss = 16.257305
2018-03-08 18:34:37 epoch 72/500 average_loss = 17.629992

2018-03-08 18:34:37 start epoch 73/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:34:38 iter 1 loss = 15.300871
2018-03-08 18:34:42 iter 25 loss = 17.852116
2018-03-08 18:34:46 iter 50 loss = 18.664053
2018-03-08 18:34:51 iter 75 loss = 16.785824
2018-03-08 18:34:55 iter 100 loss = 17.062426
2018-03-08 18:35:00 iter 125 loss = 15.257578
2018-03-08 18:35:00 epoch 73/500 average_loss = 17.569772

2018-03-08 18:35:00 start epoch 74/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:35:00 iter 1 loss = 15.236259
2018-03-08 18:35:05 iter 25 loss = 18.259970
2018-03-08 18:35:09 iter 50 loss = 17.965281
2018-03-08 18:35:14 iter 75 loss = 18.909481
2018-03-08 18:35:18 iter 100 loss = 15.665773
2018-03-08 18:35:23 iter 125 loss = 17.503967
2018-03-08 18:35:23 epoch 74/500 average_loss = 17.547410

2018-03-08 18:35:23 start epoch 75/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:35:23 iter 1 loss = 15.168174
2018-03-08 18:35:27 iter 25 loss = 20.890551
2018-03-08 18:35:32 iter 50 loss = 16.988087
2018-03-08 18:35:36 iter 75 loss = 23.009321
2018-03-08 18:35:41 iter 100 loss = 15.497682
2018-03-08 18:35:45 iter 125 loss = 18.846895
2018-03-08 18:35:45 epoch 75/500 average_loss = 17.617920

2018-03-08 18:35:45 start epoch 76/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:35:46 iter 1 loss = 20.697336
2018-03-08 18:35:50 iter 25 loss = 18.730616
2018-03-08 18:35:54 iter 50 loss = 18.538967
2018-03-08 18:35:59 iter 75 loss = 16.639915
2018-03-08 18:36:04 iter 100 loss = 14.727904
2018-03-08 18:36:08 iter 125 loss = 18.288689
2018-03-08 18:36:08 epoch 76/500 average_loss = 17.564123

2018-03-08 18:36:08 start epoch 77/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:36:08 iter 1 loss = 19.957569
2018-03-08 18:36:13 iter 25 loss = 16.740273
2018-03-08 18:36:17 iter 50 loss = 20.237284
2018-03-08 18:36:22 iter 75 loss = 19.276993
2018-03-08 18:36:26 iter 100 loss = 17.778389
2018-03-08 18:36:31 iter 125 loss = 16.461546
2018-03-08 18:36:31 epoch 77/500 average_loss = 17.496627

2018-03-08 18:36:31 start epoch 78/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:36:31 iter 1 loss = 16.405375
2018-03-08 18:36:35 iter 25 loss = 18.727642
2018-03-08 18:36:40 iter 50 loss = 15.197959
2018-03-08 18:36:44 iter 75 loss = 17.237152
2018-03-08 18:36:49 iter 100 loss = 17.351460
2018-03-08 18:36:53 iter 125 loss = 23.322105
2018-03-08 18:36:53 epoch 78/500 average_loss = 17.446278

2018-03-08 18:36:53 start epoch 79/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:36:54 iter 1 loss = 15.958452
2018-03-08 18:36:58 iter 25 loss = 16.093628
2018-03-08 18:37:03 iter 50 loss = 21.129591
2018-03-08 18:37:07 iter 75 loss = 13.106340
2018-03-08 18:37:12 iter 100 loss = 16.791447
2018-03-08 18:37:16 iter 125 loss = 16.330370
2018-03-08 18:37:16 epoch 79/500 average_loss = 17.436445

2018-03-08 18:37:16 start epoch 80/500: learning_rate = 0.0020480000000000003 sequence_len = 28
2018-03-08 18:37:16 iter 1 loss = 19.891037
2018-03-08 18:37:21 iter 25 loss = 16.929680
2018-03-08 18:37:25 iter 50 loss = 17.207699
2018-03-08 18:37:30 iter 75 loss = 18.118616
2018-03-08 18:37:34 iter 100 loss = 15.915450
2018-03-08 18:37:39 iter 125 loss = 17.007378
2018-03-08 18:37:39 epoch 80/500 average_loss = 17.393114

2018-03-08 18:37:39 start epoch 81/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:37:39 iter 1 loss = 16.175760
2018-03-08 18:37:43 iter 25 loss = 17.064770
2018-03-08 18:37:48 iter 50 loss = 21.259529
2018-03-08 18:37:52 iter 75 loss = 12.720884
2018-03-08 18:37:57 iter 100 loss = 15.915300
2018-03-08 18:38:01 iter 125 loss = 20.905464
2018-03-08 18:38:01 epoch 81/500 average_loss = 17.283384

2018-03-08 18:38:01 start epoch 82/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:38:02 iter 1 loss = 16.427465
2018-03-08 18:38:06 iter 25 loss = 15.067273
2018-03-08 18:38:11 iter 50 loss = 18.112923
2018-03-08 18:38:15 iter 75 loss = 16.836803
2018-03-08 18:38:20 iter 100 loss = 20.014122
2018-03-08 18:38:24 iter 125 loss = 14.877429
2018-03-08 18:38:24 epoch 82/500 average_loss = 17.264544

2018-03-08 18:38:24 start epoch 83/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:38:24 iter 1 loss = 18.536324
2018-03-08 18:38:29 iter 25 loss = 16.530855
2018-03-08 18:38:33 iter 50 loss = 15.251826
2018-03-08 18:38:38 iter 75 loss = 17.390863
2018-03-08 18:38:42 iter 100 loss = 16.133015
2018-03-08 18:38:47 iter 125 loss = 20.310009
2018-03-08 18:38:47 epoch 83/500 average_loss = 17.222826

2018-03-08 18:38:47 start epoch 84/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:38:47 iter 1 loss = 16.922029
2018-03-08 18:38:52 iter 25 loss = 20.357056
2018-03-08 18:38:56 iter 50 loss = 19.223280
2018-03-08 18:39:01 iter 75 loss = 19.061853
2018-03-08 18:39:05 iter 100 loss = 16.961676
2018-03-08 18:39:10 iter 125 loss = 16.714830
2018-03-08 18:39:10 epoch 84/500 average_loss = 17.179326

2018-03-08 18:39:10 start epoch 85/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:39:10 iter 1 loss = 16.848074
2018-03-08 18:39:14 iter 25 loss = 18.180866
2018-03-08 18:39:19 iter 50 loss = 15.514663
2018-03-08 18:39:23 iter 75 loss = 20.062609
2018-03-08 18:39:28 iter 100 loss = 14.967273
2018-03-08 18:39:32 iter 125 loss = 21.937971
2018-03-08 18:39:32 epoch 85/500 average_loss = 17.212362

2018-03-08 18:39:32 start epoch 86/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:39:33 iter 1 loss = 23.910368
2018-03-08 18:39:37 iter 25 loss = 13.838153
2018-03-08 18:39:41 iter 50 loss = 18.379154
2018-03-08 18:39:46 iter 75 loss = 22.419994
2018-03-08 18:39:50 iter 100 loss = 16.250095
2018-03-08 18:39:55 iter 125 loss = 17.625069
2018-03-08 18:39:55 epoch 86/500 average_loss = 17.125232

2018-03-08 18:39:55 start epoch 87/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:39:55 iter 1 loss = 15.367160
2018-03-08 18:40:00 iter 25 loss = 15.944833
2018-03-08 18:40:04 iter 50 loss = 17.165720
2018-03-08 18:40:09 iter 75 loss = 18.061951
2018-03-08 18:40:13 iter 100 loss = 15.139756
2018-03-08 18:40:18 iter 125 loss = 15.684336
2018-03-08 18:40:18 epoch 87/500 average_loss = 17.067329

2018-03-08 18:40:18 start epoch 88/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:40:18 iter 1 loss = 18.304876
2018-03-08 18:40:22 iter 25 loss = 13.470742
2018-03-08 18:40:27 iter 50 loss = 16.918934
2018-03-08 18:40:31 iter 75 loss = 18.063290
2018-03-08 18:40:36 iter 100 loss = 16.000580
2018-03-08 18:40:40 iter 125 loss = 16.074932
2018-03-08 18:40:40 epoch 88/500 average_loss = 16.989158

2018-03-08 18:40:40 start epoch 89/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:40:41 iter 1 loss = 19.361609
2018-03-08 18:40:45 iter 25 loss = 20.635723
2018-03-08 18:40:50 iter 50 loss = 17.256041
2018-03-08 18:40:54 iter 75 loss = 16.259354
2018-03-08 18:40:59 iter 100 loss = 19.008057
2018-03-08 18:41:03 iter 125 loss = 18.282822
2018-03-08 18:41:03 epoch 89/500 average_loss = 16.943198

2018-03-08 18:41:03 start epoch 90/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:41:03 iter 1 loss = 14.455806
2018-03-08 18:41:08 iter 25 loss = 18.303383
2018-03-08 18:41:12 iter 50 loss = 15.130024
2018-03-08 18:41:17 iter 75 loss = 13.838177
2018-03-08 18:41:21 iter 100 loss = 14.205015
2018-03-08 18:41:26 iter 125 loss = 14.934461
2018-03-08 18:41:26 epoch 90/500 average_loss = 16.939880

2018-03-08 18:41:26 start epoch 91/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:41:26 iter 1 loss = 12.936696
2018-03-08 18:41:30 iter 25 loss = 16.489220
2018-03-08 18:41:35 iter 50 loss = 16.122854
2018-03-08 18:41:39 iter 75 loss = 22.968227
2018-03-08 18:41:44 iter 100 loss = 16.315231
2018-03-08 18:41:48 iter 125 loss = 12.689540
2018-03-08 18:41:48 epoch 91/500 average_loss = 16.914145

2018-03-08 18:41:48 start epoch 92/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:41:49 iter 1 loss = 16.806921
2018-03-08 18:41:53 iter 25 loss = 15.668571
2018-03-08 18:41:58 iter 50 loss = 17.888021
2018-03-08 18:42:02 iter 75 loss = 14.800798
2018-03-08 18:42:07 iter 100 loss = 16.686178
2018-03-08 18:42:11 iter 125 loss = 15.537531
2018-03-08 18:42:11 epoch 92/500 average_loss = 16.836519

2018-03-08 18:42:11 start epoch 93/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:42:11 iter 1 loss = 16.274714
2018-03-08 18:42:16 iter 25 loss = 14.102241
2018-03-08 18:42:20 iter 50 loss = 16.409452
2018-03-08 18:42:25 iter 75 loss = 19.126492
2018-03-08 18:42:29 iter 100 loss = 15.852448
2018-03-08 18:42:34 iter 125 loss = 18.368279
2018-03-08 18:42:34 epoch 93/500 average_loss = 16.817548

2018-03-08 18:42:34 start epoch 94/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:42:34 iter 1 loss = 12.800158
2018-03-08 18:42:38 iter 25 loss = 14.791000
2018-03-08 18:42:43 iter 50 loss = 15.236997
2018-03-08 18:42:47 iter 75 loss = 20.276558
2018-03-08 18:42:52 iter 100 loss = 17.736311
2018-03-08 18:42:57 iter 125 loss = 17.431087
2018-03-08 18:42:57 epoch 94/500 average_loss = 16.766783

2018-03-08 18:42:57 start epoch 95/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:42:57 iter 1 loss = 17.067408
2018-03-08 18:43:01 iter 25 loss = 14.408916
2018-03-08 18:43:06 iter 50 loss = 18.830950
2018-03-08 18:43:10 iter 75 loss = 19.274887
2018-03-08 18:43:15 iter 100 loss = 17.504438
2018-03-08 18:43:19 iter 125 loss = 18.619812
2018-03-08 18:43:19 epoch 95/500 average_loss = 16.739089

2018-03-08 18:43:19 start epoch 96/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:43:20 iter 1 loss = 15.748695
2018-03-08 18:43:24 iter 25 loss = 16.995378
2018-03-08 18:43:28 iter 50 loss = 16.554586
2018-03-08 18:43:33 iter 75 loss = 22.115078
2018-03-08 18:43:37 iter 100 loss = 12.903894
2018-03-08 18:43:42 iter 125 loss = 16.806644
2018-03-08 18:43:42 epoch 96/500 average_loss = 16.709612

2018-03-08 18:43:42 start epoch 97/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:43:42 iter 1 loss = 15.347061
2018-03-08 18:43:47 iter 25 loss = 15.123737
2018-03-08 18:43:51 iter 50 loss = 16.060163
2018-03-08 18:43:56 iter 75 loss = 14.604833
2018-03-08 18:44:00 iter 100 loss = 17.690195
2018-03-08 18:44:05 iter 125 loss = 15.402462
2018-03-08 18:44:05 epoch 97/500 average_loss = 16.679858

2018-03-08 18:44:05 start epoch 98/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:44:05 iter 1 loss = 14.026067
2018-03-08 18:44:09 iter 25 loss = 16.329441
2018-03-08 18:44:14 iter 50 loss = 17.248987
2018-03-08 18:44:18 iter 75 loss = 12.968126
2018-03-08 18:44:23 iter 100 loss = 18.248951
2018-03-08 18:44:27 iter 125 loss = 17.081459
2018-03-08 18:44:27 epoch 98/500 average_loss = 16.638100

2018-03-08 18:44:27 start epoch 99/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:44:27 iter 1 loss = 17.069172
2018-03-08 18:44:32 iter 25 loss = 18.677729
2018-03-08 18:44:36 iter 50 loss = 17.861374
2018-03-08 18:44:41 iter 75 loss = 14.731535
2018-03-08 18:44:45 iter 100 loss = 16.895464
2018-03-08 18:44:50 iter 125 loss = 13.824854
2018-03-08 18:44:50 epoch 99/500 average_loss = 16.610356

2018-03-08 18:44:50 start epoch 100/500: learning_rate = 0.0016384000000000004 sequence_len = 28
2018-03-08 18:44:50 iter 1 loss = 17.966244
2018-03-08 18:44:54 iter 25 loss = 19.138031
2018-03-08 18:44:59 iter 50 loss = 16.553051
2018-03-08 18:45:03 iter 75 loss = 17.120121
2018-03-08 18:45:08 iter 100 loss = 12.430461
2018-03-08 18:45:12 iter 125 loss = 16.779318
2018-03-08 18:45:12 epoch 100/500 average_loss = 16.526167

2018-03-08 18:45:12 start epoch 101/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:45:13 iter 1 loss = 18.338894
2018-03-08 18:45:17 iter 25 loss = 12.885703
2018-03-08 18:45:22 iter 50 loss = 15.078614
2018-03-08 18:45:26 iter 75 loss = 17.904293
2018-03-08 18:45:31 iter 100 loss = 18.805298
2018-03-08 18:45:35 iter 125 loss = 16.691442
2018-03-08 18:45:35 epoch 101/500 average_loss = 16.415397

2018-03-08 18:45:35 start epoch 102/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:45:35 iter 1 loss = 17.508429
2018-03-08 18:45:40 iter 25 loss = 14.801181
2018-03-08 18:45:44 iter 50 loss = 18.049475
2018-03-08 18:45:49 iter 75 loss = 13.653245
2018-03-08 18:45:53 iter 100 loss = 13.682026
2018-03-08 18:45:58 iter 125 loss = 12.007798
2018-03-08 18:45:58 epoch 102/500 average_loss = 16.348172

2018-03-08 18:45:58 start epoch 103/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:45:58 iter 1 loss = 16.110003
2018-03-08 18:46:02 iter 25 loss = 16.231256
2018-03-08 18:46:07 iter 50 loss = 16.249058
2018-03-08 18:46:11 iter 75 loss = 12.818233
2018-03-08 18:46:16 iter 100 loss = 18.712429
2018-03-08 18:46:21 iter 125 loss = 17.929148
2018-03-08 18:46:21 epoch 103/500 average_loss = 16.203105

2018-03-08 18:46:21 start epoch 104/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:46:21 iter 1 loss = 16.678385
2018-03-08 18:46:25 iter 25 loss = 14.136773
2018-03-08 18:46:30 iter 50 loss = 17.181377
2018-03-08 18:46:34 iter 75 loss = 16.127308
2018-03-08 18:46:39 iter 100 loss = 15.258638
2018-03-08 18:46:43 iter 125 loss = 15.851398
2018-03-08 18:46:43 epoch 104/500 average_loss = 16.150038

2018-03-08 18:46:43 start epoch 105/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:46:44 iter 1 loss = 19.839962
2018-03-08 18:46:48 iter 25 loss = 18.536192
2018-03-08 18:46:52 iter 50 loss = 14.341011
2018-03-08 18:46:57 iter 75 loss = 14.412797
2018-03-08 18:47:01 iter 100 loss = 17.072323
2018-03-08 18:47:06 iter 125 loss = 17.243839
2018-03-08 18:47:06 epoch 105/500 average_loss = 16.115802

2018-03-08 18:47:06 start epoch 106/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:47:06 iter 1 loss = 20.443521
2018-03-08 18:47:11 iter 25 loss = 20.543846
2018-03-08 18:47:15 iter 50 loss = 15.943633
2018-03-08 18:47:19 iter 75 loss = 19.406557
2018-03-08 18:47:24 iter 100 loss = 18.151760
2018-03-08 18:47:28 iter 125 loss = 12.524321
2018-03-08 18:47:28 epoch 106/500 average_loss = 15.989769

2018-03-08 18:47:28 start epoch 107/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:47:29 iter 1 loss = 15.284183
2018-03-08 18:47:33 iter 25 loss = 14.774312
2018-03-08 18:47:38 iter 50 loss = 15.794364
2018-03-08 18:47:42 iter 75 loss = 14.299110
2018-03-08 18:47:47 iter 100 loss = 13.244475
2018-03-08 18:47:51 iter 125 loss = 17.988594
2018-03-08 18:47:51 epoch 107/500 average_loss = 15.964123

2018-03-08 18:47:51 start epoch 108/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:47:52 iter 1 loss = 17.679678
2018-03-08 18:47:56 iter 25 loss = 13.874424
2018-03-08 18:48:00 iter 50 loss = 18.185106
2018-03-08 18:48:05 iter 75 loss = 16.988104
2018-03-08 18:48:09 iter 100 loss = 16.976461
2018-03-08 18:48:14 iter 125 loss = 16.806000
2018-03-08 18:48:14 epoch 108/500 average_loss = 15.968079

2018-03-08 18:48:14 start epoch 109/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:48:14 iter 1 loss = 18.808607
2018-03-08 18:48:19 iter 25 loss = 15.178726
2018-03-08 18:48:23 iter 50 loss = 13.314198
2018-03-08 18:48:28 iter 75 loss = 16.099676
2018-03-08 18:48:32 iter 100 loss = 14.906651
2018-03-08 18:48:37 iter 125 loss = 17.082886
2018-03-08 18:48:37 epoch 109/500 average_loss = 16.033806

2018-03-08 18:48:37 start epoch 110/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:48:37 iter 1 loss = 14.931562
2018-03-08 18:48:41 iter 25 loss = 14.405062
2018-03-08 18:48:46 iter 50 loss = 17.668533
2018-03-08 18:48:50 iter 75 loss = 16.112181
2018-03-08 18:48:55 iter 100 loss = 15.399438
2018-03-08 18:48:59 iter 125 loss = 18.627472
2018-03-08 18:48:59 epoch 110/500 average_loss = 16.009164

2018-03-08 18:48:59 start epoch 111/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:49:00 iter 1 loss = 14.101076
2018-03-08 18:49:04 iter 25 loss = 20.537706
2018-03-08 18:49:09 iter 50 loss = 16.011328
2018-03-08 18:49:13 iter 75 loss = 16.074492
2018-03-08 18:49:18 iter 100 loss = 19.039524
2018-03-08 18:49:22 iter 125 loss = 17.194481
2018-03-08 18:49:22 epoch 111/500 average_loss = 15.832782

2018-03-08 18:49:22 start epoch 112/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:49:22 iter 1 loss = 15.761858
2018-03-08 18:49:27 iter 25 loss = 14.307680
2018-03-08 18:49:31 iter 50 loss = 16.178186
2018-03-08 18:49:36 iter 75 loss = 18.224167
2018-03-08 18:49:40 iter 100 loss = 14.012815
2018-03-08 18:49:45 iter 125 loss = 19.106730
2018-03-08 18:49:45 epoch 112/500 average_loss = 15.719294

2018-03-08 18:49:45 start epoch 113/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:49:45 iter 1 loss = 13.327361
2018-03-08 18:49:49 iter 25 loss = 17.867298
2018-03-08 18:49:54 iter 50 loss = 15.499117
2018-03-08 18:49:58 iter 75 loss = 15.819833
2018-03-08 18:50:03 iter 100 loss = 11.967400
2018-03-08 18:50:08 iter 125 loss = 18.688562
2018-03-08 18:50:08 epoch 113/500 average_loss = 15.596613

2018-03-08 18:50:08 start epoch 114/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:50:08 iter 1 loss = 14.877326
2018-03-08 18:50:12 iter 25 loss = 17.716331
2018-03-08 18:50:17 iter 50 loss = 14.905475
2018-03-08 18:50:21 iter 75 loss = 13.060348
2018-03-08 18:50:26 iter 100 loss = 14.135069
2018-03-08 18:50:30 iter 125 loss = 19.790730
2018-03-08 18:50:30 epoch 114/500 average_loss = 15.532687

2018-03-08 18:50:30 start epoch 115/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:50:31 iter 1 loss = 15.328873
2018-03-08 18:50:35 iter 25 loss = 14.947634
2018-03-08 18:50:39 iter 50 loss = 15.921432
2018-03-08 18:50:44 iter 75 loss = 17.985666
2018-03-08 18:50:48 iter 100 loss = 17.346264
2018-03-08 18:50:53 iter 125 loss = 15.496072
2018-03-08 18:50:53 epoch 115/500 average_loss = 15.505674

2018-03-08 18:50:53 start epoch 116/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:50:53 iter 1 loss = 11.467937
2018-03-08 18:50:57 iter 25 loss = 18.968082
2018-03-08 18:51:02 iter 50 loss = 15.611276
2018-03-08 18:51:06 iter 75 loss = 14.105257
2018-03-08 18:51:11 iter 100 loss = 17.631987
2018-03-08 18:51:15 iter 125 loss = 18.589701
2018-03-08 18:51:15 epoch 116/500 average_loss = 15.423442

2018-03-08 18:51:15 start epoch 117/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:51:16 iter 1 loss = 13.331799
2018-03-08 18:51:20 iter 25 loss = 12.667897
2018-03-08 18:51:25 iter 50 loss = 18.673969
2018-03-08 18:51:29 iter 75 loss = 14.108339
2018-03-08 18:51:34 iter 100 loss = 15.223282
2018-03-08 18:51:38 iter 125 loss = 13.700009
2018-03-08 18:51:38 epoch 117/500 average_loss = 15.474906

2018-03-08 18:51:38 start epoch 118/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:51:38 iter 1 loss = 13.477031
2018-03-08 18:51:43 iter 25 loss = 15.071527
2018-03-08 18:51:47 iter 50 loss = 15.532274
2018-03-08 18:51:52 iter 75 loss = 15.843739
2018-03-08 18:51:56 iter 100 loss = 14.341698
2018-03-08 18:52:01 iter 125 loss = 18.469246
2018-03-08 18:52:01 epoch 118/500 average_loss = 15.295913

2018-03-08 18:52:01 start epoch 119/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:52:01 iter 1 loss = 20.092548
2018-03-08 18:52:05 iter 25 loss = 13.516948
2018-03-08 18:52:10 iter 50 loss = 11.155045
2018-03-08 18:52:14 iter 75 loss = 15.356452
2018-03-08 18:52:19 iter 100 loss = 14.319657
2018-03-08 18:52:24 iter 125 loss = 14.297576
2018-03-08 18:52:24 epoch 119/500 average_loss = 15.471528

2018-03-08 18:52:24 start epoch 120/500: learning_rate = 0.0013107200000000005 sequence_len = 28
2018-03-08 18:52:24 iter 1 loss = 17.668957
2018-03-08 18:52:28 iter 25 loss = 15.005078
2018-03-08 18:52:33 iter 50 loss = 16.960142
2018-03-08 18:52:37 iter 75 loss = 20.358866
2018-03-08 18:52:42 iter 100 loss = 18.008684
2018-03-08 18:52:46 iter 125 loss = 16.865803
2018-03-08 18:52:46 epoch 120/500 average_loss = 15.126138

2018-03-08 18:52:46 start epoch 121/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:52:47 iter 1 loss = 14.905000
2018-03-08 18:52:51 iter 25 loss = 17.879309
2018-03-08 18:52:55 iter 50 loss = 15.484652
2018-03-08 18:53:00 iter 75 loss = 12.822238
2018-03-08 18:53:04 iter 100 loss = 13.505065
2018-03-08 18:53:09 iter 125 loss = 18.314775
2018-03-08 18:53:09 epoch 121/500 average_loss = 14.912978

2018-03-08 18:53:09 start epoch 122/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:53:09 iter 1 loss = 14.155912
2018-03-08 18:53:14 iter 25 loss = 16.106314
2018-03-08 18:53:18 iter 50 loss = 18.909575
2018-03-08 18:53:23 iter 75 loss = 18.406088
2018-03-08 18:53:27 iter 100 loss = 13.054141
2018-03-08 18:53:32 iter 125 loss = 10.733090
2018-03-08 18:53:32 epoch 122/500 average_loss = 14.787624

2018-03-08 18:53:32 start epoch 123/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:53:32 iter 1 loss = 9.985723
2018-03-08 18:53:36 iter 25 loss = 13.822255
2018-03-08 18:53:41 iter 50 loss = 13.145952
2018-03-08 18:53:45 iter 75 loss = 14.885858
2018-03-08 18:53:50 iter 100 loss = 12.700225
2018-03-08 18:53:54 iter 125 loss = 13.565500
2018-03-08 18:53:54 epoch 123/500 average_loss = 14.732870

2018-03-08 18:53:54 start epoch 124/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:53:55 iter 1 loss = 13.735400
2018-03-08 18:53:59 iter 25 loss = 16.279051
2018-03-08 18:54:04 iter 50 loss = 13.579461
2018-03-08 18:54:08 iter 75 loss = 14.114074
2018-03-08 18:54:13 iter 100 loss = 14.653313
2018-03-08 18:54:17 iter 125 loss = 10.305630
2018-03-08 18:54:17 epoch 124/500 average_loss = 14.707359

2018-03-08 18:54:17 start epoch 125/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:54:17 iter 1 loss = 13.784613
2018-03-08 18:54:22 iter 25 loss = 13.166009
2018-03-08 18:54:26 iter 50 loss = 13.589135
2018-03-08 18:54:31 iter 75 loss = 16.648705
2018-03-08 18:54:35 iter 100 loss = 12.989168
2018-03-08 18:54:40 iter 125 loss = 12.253040
2018-03-08 18:54:40 epoch 125/500 average_loss = 14.562344

2018-03-08 18:54:40 start epoch 126/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:54:40 iter 1 loss = 17.099365
2018-03-08 18:54:44 iter 25 loss = 16.680029
2018-03-08 18:54:49 iter 50 loss = 16.446255
2018-03-08 18:54:53 iter 75 loss = 14.078012
2018-03-08 18:54:58 iter 100 loss = 13.146242
2018-03-08 18:55:02 iter 125 loss = 12.380086
2018-03-08 18:55:02 epoch 126/500 average_loss = 14.514718

2018-03-08 18:55:02 start epoch 127/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:55:03 iter 1 loss = 10.357200
2018-03-08 18:55:07 iter 25 loss = 12.173650
2018-03-08 18:55:12 iter 50 loss = 17.419777
2018-03-08 18:55:16 iter 75 loss = 13.960848
2018-03-08 18:55:21 iter 100 loss = 15.220395
2018-03-08 18:55:25 iter 125 loss = 13.045783
2018-03-08 18:55:25 epoch 127/500 average_loss = 14.419008

2018-03-08 18:55:25 start epoch 128/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:55:25 iter 1 loss = 11.820655
2018-03-08 18:55:30 iter 25 loss = 12.799631
2018-03-08 18:55:34 iter 50 loss = 15.012187
2018-03-08 18:55:39 iter 75 loss = 16.501589
2018-03-08 18:55:43 iter 100 loss = 14.555101
2018-03-08 18:55:48 iter 125 loss = 14.273392
2018-03-08 18:55:48 epoch 128/500 average_loss = 14.294825

2018-03-08 18:55:48 start epoch 129/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:55:48 iter 1 loss = 13.149076
2018-03-08 18:55:52 iter 25 loss = 14.660324
2018-03-08 18:55:57 iter 50 loss = 17.136795
2018-03-08 18:56:01 iter 75 loss = 14.834536
2018-03-08 18:56:06 iter 100 loss = 15.762618
2018-03-08 18:56:10 iter 125 loss = 12.791460
2018-03-08 18:56:10 epoch 129/500 average_loss = 14.261038

2018-03-08 18:56:10 start epoch 130/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:56:11 iter 1 loss = 14.424353
2018-03-08 18:56:15 iter 25 loss = 12.212161
2018-03-08 18:56:19 iter 50 loss = 10.557467
2018-03-08 18:56:24 iter 75 loss = 13.376857
2018-03-08 18:56:28 iter 100 loss = 14.104038
2018-03-08 18:56:33 iter 125 loss = 12.359495
2018-03-08 18:56:33 epoch 130/500 average_loss = 14.129097

2018-03-08 18:56:33 start epoch 131/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:56:33 iter 1 loss = 11.916909
2018-03-08 18:56:38 iter 25 loss = 12.072766
2018-03-08 18:56:42 iter 50 loss = 18.984772
2018-03-08 18:56:47 iter 75 loss = 16.369892
2018-03-08 18:56:51 iter 100 loss = 12.554314
2018-03-08 18:56:56 iter 125 loss = 13.582725
2018-03-08 18:56:56 epoch 131/500 average_loss = 14.023819

2018-03-08 18:56:56 start epoch 132/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:56:56 iter 1 loss = 11.902323
2018-03-08 18:57:00 iter 25 loss = 15.025389
2018-03-08 18:57:05 iter 50 loss = 15.271871
2018-03-08 18:57:09 iter 75 loss = 12.890656
2018-03-08 18:57:14 iter 100 loss = 18.282303
2018-03-08 18:57:18 iter 125 loss = 13.604503
2018-03-08 18:57:18 epoch 132/500 average_loss = 13.911126

2018-03-08 18:57:18 start epoch 133/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:57:19 iter 1 loss = 14.838511
2018-03-08 18:57:23 iter 25 loss = 9.920397
2018-03-08 18:57:27 iter 50 loss = 15.950257
2018-03-08 18:57:32 iter 75 loss = 10.271481
2018-03-08 18:57:36 iter 100 loss = 14.132998
2018-03-08 18:57:41 iter 125 loss = 10.976227
2018-03-08 18:57:41 epoch 133/500 average_loss = 13.815563

2018-03-08 18:57:41 start epoch 134/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:57:41 iter 1 loss = 15.428668
2018-03-08 18:57:46 iter 25 loss = 11.339172
2018-03-08 18:57:50 iter 50 loss = 15.859368
2018-03-08 18:57:55 iter 75 loss = 13.165509
2018-03-08 18:57:59 iter 100 loss = 14.284536
2018-03-08 18:58:04 iter 125 loss = 13.793464
2018-03-08 18:58:04 epoch 134/500 average_loss = 13.606462

2018-03-08 18:58:04 start epoch 135/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:58:04 iter 1 loss = 12.988403
2018-03-08 18:58:08 iter 25 loss = 14.951091
2018-03-08 18:58:13 iter 50 loss = 16.106405
2018-03-08 18:58:17 iter 75 loss = 15.317199
2018-03-08 18:58:22 iter 100 loss = 17.023132
2018-03-08 18:58:26 iter 125 loss = 15.866108
2018-03-08 18:58:26 epoch 135/500 average_loss = 13.598241

2018-03-08 18:58:26 start epoch 136/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:58:27 iter 1 loss = 11.989921
2018-03-08 18:58:31 iter 25 loss = 12.966384
2018-03-08 18:58:36 iter 50 loss = 13.777257
2018-03-08 18:58:40 iter 75 loss = 12.711976
2018-03-08 18:58:45 iter 100 loss = 13.250530
2018-03-08 18:58:49 iter 125 loss = 14.364804
2018-03-08 18:58:49 epoch 136/500 average_loss = 13.502546

2018-03-08 18:58:49 start epoch 137/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:58:49 iter 1 loss = 14.835047
2018-03-08 18:58:54 iter 25 loss = 14.377214
2018-03-08 18:58:58 iter 50 loss = 9.966486
2018-03-08 18:59:03 iter 75 loss = 14.174681
2018-03-08 18:59:07 iter 100 loss = 14.346952
2018-03-08 18:59:12 iter 125 loss = 11.840891
2018-03-08 18:59:12 epoch 137/500 average_loss = 13.316124

2018-03-08 18:59:12 start epoch 138/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:59:12 iter 1 loss = 11.231375
2018-03-08 18:59:17 iter 25 loss = 15.281316
2018-03-08 18:59:21 iter 50 loss = 14.632611
2018-03-08 18:59:26 iter 75 loss = 13.381388
2018-03-08 18:59:30 iter 100 loss = 11.504315
2018-03-08 18:59:35 iter 125 loss = 15.113343
2018-03-08 18:59:35 epoch 138/500 average_loss = 13.195222

2018-03-08 18:59:35 start epoch 139/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:59:35 iter 1 loss = 10.345231
2018-03-08 18:59:39 iter 25 loss = 11.036860
2018-03-08 18:59:44 iter 50 loss = 10.970812
2018-03-08 18:59:48 iter 75 loss = 15.847956
2018-03-08 18:59:53 iter 100 loss = 14.021117
2018-03-08 18:59:57 iter 125 loss = 16.726204
2018-03-08 18:59:57 epoch 139/500 average_loss = 13.039515

2018-03-08 18:59:57 start epoch 140/500: learning_rate = 0.0010485760000000005 sequence_len = 28
2018-03-08 18:59:58 iter 1 loss = 10.594344
2018-03-08 19:00:02 iter 25 loss = 14.409817
2018-03-08 19:00:06 iter 50 loss = 13.717185
2018-03-08 19:00:11 iter 75 loss = 11.390017
2018-03-08 19:00:16 iter 100 loss = 12.285069
2018-03-08 19:00:20 iter 125 loss = 10.704957
2018-03-08 19:00:20 epoch 140/500 average_loss = 12.920862

2018-03-08 19:00:20 start epoch 141/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:00:20 iter 1 loss = 12.562417
2018-03-08 19:00:25 iter 25 loss = 14.504689
2018-03-08 19:00:29 iter 50 loss = 15.040196
2018-03-08 19:00:34 iter 75 loss = 12.584751
2018-03-08 19:00:38 iter 100 loss = 10.569016
2018-03-08 19:00:43 iter 125 loss = 11.532226
2018-03-08 19:00:43 epoch 141/500 average_loss = 12.636625

2018-03-08 19:00:43 start epoch 142/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:00:43 iter 1 loss = 14.307447
2018-03-08 19:00:48 iter 25 loss = 13.766310
2018-03-08 19:00:52 iter 50 loss = 13.393775
2018-03-08 19:00:57 iter 75 loss = 11.139296
2018-03-08 19:01:01 iter 100 loss = 13.689097
2018-03-08 19:01:06 iter 125 loss = 10.847818
2018-03-08 19:01:06 epoch 142/500 average_loss = 12.523177

2018-03-08 19:01:06 start epoch 143/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:01:06 iter 1 loss = 12.251003
2018-03-08 19:01:10 iter 25 loss = 12.428148
2018-03-08 19:01:15 iter 50 loss = 9.046121
2018-03-08 19:01:19 iter 75 loss = 8.939742
2018-03-08 19:01:24 iter 100 loss = 14.069750
2018-03-08 19:01:28 iter 125 loss = 12.389160
2018-03-08 19:01:28 epoch 143/500 average_loss = 12.394189

2018-03-08 19:01:28 start epoch 144/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:01:29 iter 1 loss = 11.789694
2018-03-08 19:01:33 iter 25 loss = 14.068152
2018-03-08 19:01:37 iter 50 loss = 10.729381
2018-03-08 19:01:42 iter 75 loss = 13.542243
2018-03-08 19:01:46 iter 100 loss = 13.202755
2018-03-08 19:01:51 iter 125 loss = 13.602747
2018-03-08 19:01:51 epoch 144/500 average_loss = 12.300452

2018-03-08 19:01:51 start epoch 145/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:01:51 iter 1 loss = 12.067240
2018-03-08 19:01:56 iter 25 loss = 15.180237
2018-03-08 19:02:00 iter 50 loss = 13.415331
2018-03-08 19:02:05 iter 75 loss = 9.391553
2018-03-08 19:02:09 iter 100 loss = 14.401488
2018-03-08 19:02:14 iter 125 loss = 11.891836
2018-03-08 19:02:14 epoch 145/500 average_loss = 12.122088

2018-03-08 19:02:14 start epoch 146/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:02:14 iter 1 loss = 14.363291
2018-03-08 19:02:18 iter 25 loss = 12.256807
2018-03-08 19:02:23 iter 50 loss = 9.575367
2018-03-08 19:02:27 iter 75 loss = 11.706890
2018-03-08 19:02:32 iter 100 loss = 7.452138
2018-03-08 19:02:36 iter 125 loss = 11.840265
2018-03-08 19:02:36 epoch 146/500 average_loss = 11.883283

2018-03-08 19:02:36 start epoch 147/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:02:37 iter 1 loss = 11.429680
2018-03-08 19:02:41 iter 25 loss = 12.097802
2018-03-08 19:02:45 iter 50 loss = 14.516785
2018-03-08 19:02:50 iter 75 loss = 9.321638
2018-03-08 19:02:54 iter 100 loss = 10.930150
2018-03-08 19:02:59 iter 125 loss = 9.486477
2018-03-08 19:02:59 epoch 147/500 average_loss = 11.701248

2018-03-08 19:02:59 start epoch 148/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:02:59 iter 1 loss = 8.602993
2018-03-08 19:03:04 iter 25 loss = 9.688825
2018-03-08 19:03:08 iter 50 loss = 14.996989
2018-03-08 19:03:13 iter 75 loss = 9.451141
2018-03-08 19:03:17 iter 100 loss = 11.049500
2018-03-08 19:03:22 iter 125 loss = 12.211631
2018-03-08 19:03:22 epoch 148/500 average_loss = 11.575491

2018-03-08 19:03:22 start epoch 149/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:03:22 iter 1 loss = 10.367030
2018-03-08 19:03:26 iter 25 loss = 15.270748
2018-03-08 19:03:31 iter 50 loss = 16.570988
2018-03-08 19:03:35 iter 75 loss = 10.063768
2018-03-08 19:03:40 iter 100 loss = 13.518251
2018-03-08 19:03:44 iter 125 loss = 13.183392
2018-03-08 19:03:44 epoch 149/500 average_loss = 11.423345

2018-03-08 19:03:44 start epoch 150/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:03:45 iter 1 loss = 10.356212
2018-03-08 19:03:49 iter 25 loss = 10.780730
2018-03-08 19:03:54 iter 50 loss = 9.062533
2018-03-08 19:03:58 iter 75 loss = 11.486238
2018-03-08 19:04:03 iter 100 loss = 8.140190
2018-03-08 19:04:07 iter 125 loss = 10.427097
2018-03-08 19:04:07 epoch 150/500 average_loss = 11.194728

2018-03-08 19:04:07 start epoch 151/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:04:07 iter 1 loss = 12.723567
2018-03-08 19:04:12 iter 25 loss = 8.777260
2018-03-08 19:04:16 iter 50 loss = 14.752062
2018-03-08 19:04:21 iter 75 loss = 11.137527
2018-03-08 19:04:25 iter 100 loss = 11.114267
2018-03-08 19:04:30 iter 125 loss = 8.196344
2018-03-08 19:04:30 epoch 151/500 average_loss = 11.116993

2018-03-08 19:04:30 start epoch 152/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:04:30 iter 1 loss = 11.602296
2018-03-08 19:04:34 iter 25 loss = 13.391674
2018-03-08 19:04:39 iter 50 loss = 10.367799
2018-03-08 19:04:43 iter 75 loss = 10.120804
2018-03-08 19:04:48 iter 100 loss = 11.718800
2018-03-08 19:04:52 iter 125 loss = 7.711541
2018-03-08 19:04:52 epoch 152/500 average_loss = 11.027690

2018-03-08 19:04:52 start epoch 153/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:04:53 iter 1 loss = 10.206535
2018-03-08 19:04:57 iter 25 loss = 12.982333
2018-03-08 19:05:02 iter 50 loss = 13.457897
2018-03-08 19:05:06 iter 75 loss = 8.426716
2018-03-08 19:05:11 iter 100 loss = 12.432254
2018-03-08 19:05:15 iter 125 loss = 8.624132
2018-03-08 19:05:15 epoch 153/500 average_loss = 10.915786

2018-03-08 19:05:15 start epoch 154/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:05:15 iter 1 loss = 11.546945
2018-03-08 19:05:20 iter 25 loss = 14.739177
2018-03-08 19:05:24 iter 50 loss = 9.104985
2018-03-08 19:05:29 iter 75 loss = 13.322535
2018-03-08 19:05:33 iter 100 loss = 10.396193
2018-03-08 19:05:38 iter 125 loss = 11.219056
2018-03-08 19:05:38 epoch 154/500 average_loss = 10.868510

2018-03-08 19:05:38 start epoch 155/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:05:38 iter 1 loss = 11.154890
2018-03-08 19:05:42 iter 25 loss = 10.418092
2018-03-08 19:05:47 iter 50 loss = 13.209807
2018-03-08 19:05:51 iter 75 loss = 9.391437
2018-03-08 19:05:56 iter 100 loss = 7.765548
2018-03-08 19:06:00 iter 125 loss = 16.769705
2018-03-08 19:06:00 epoch 155/500 average_loss = 10.437849

2018-03-08 19:06:00 start epoch 156/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:06:01 iter 1 loss = 7.667987
2018-03-08 19:06:05 iter 25 loss = 11.260698
2018-03-08 19:06:10 iter 50 loss = 10.482198
2018-03-08 19:06:14 iter 75 loss = 10.126208
2018-03-08 19:06:19 iter 100 loss = 11.087463
2018-03-08 19:06:23 iter 125 loss = 10.643365
2018-03-08 19:06:23 epoch 156/500 average_loss = 10.292157

2018-03-08 19:06:23 start epoch 157/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:06:24 iter 1 loss = 11.400126
2018-03-08 19:06:28 iter 25 loss = 11.935000
2018-03-08 19:06:32 iter 50 loss = 10.029941
2018-03-08 19:06:37 iter 75 loss = 9.793942
2018-03-08 19:06:41 iter 100 loss = 9.142332
2018-03-08 19:06:46 iter 125 loss = 10.405263
2018-03-08 19:06:46 epoch 157/500 average_loss = 10.179849

2018-03-08 19:06:46 start epoch 158/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:06:46 iter 1 loss = 11.479281
2018-03-08 19:06:51 iter 25 loss = 9.174651
2018-03-08 19:06:55 iter 50 loss = 9.746034
2018-03-08 19:07:00 iter 75 loss = 10.749884
2018-03-08 19:07:04 iter 100 loss = 10.758852
2018-03-08 19:07:09 iter 125 loss = 9.643299
2018-03-08 19:07:09 epoch 158/500 average_loss = 9.927921

2018-03-08 19:07:09 start epoch 159/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:07:09 iter 1 loss = 14.576803
2018-03-08 19:07:13 iter 25 loss = 10.827083
2018-03-08 19:07:18 iter 50 loss = 9.523973
2018-03-08 19:07:22 iter 75 loss = 9.236382
2018-03-08 19:07:27 iter 100 loss = 10.723438
2018-03-08 19:07:31 iter 125 loss = 9.348193
2018-03-08 19:07:31 epoch 159/500 average_loss = 9.703421

2018-03-08 19:07:31 start epoch 160/500: learning_rate = 0.0008388608000000004 sequence_len = 28
2018-03-08 19:07:32 iter 1 loss = 9.781560
2018-03-08 19:07:36 iter 25 loss = 10.381550
2018-03-08 19:07:41 iter 50 loss = 9.913524
2018-03-08 19:07:45 iter 75 loss = 11.190755
2018-03-08 19:07:50 iter 100 loss = 8.416461
2018-03-08 19:07:54 iter 125 loss = 9.592112
2018-03-08 19:07:54 epoch 160/500 average_loss = 9.458137

2018-03-08 19:07:54 start epoch 161/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:07:54 iter 1 loss = 8.880149
2018-03-08 19:07:59 iter 25 loss = 10.985281
2018-03-08 19:08:03 iter 50 loss = 7.219095
2018-03-08 19:08:08 iter 75 loss = 9.490526
2018-03-08 19:08:12 iter 100 loss = 7.144788
2018-03-08 19:08:17 iter 125 loss = 4.928303
2018-03-08 19:08:17 epoch 161/500 average_loss = 9.213199

2018-03-08 19:08:17 start epoch 162/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:08:17 iter 1 loss = 8.729210
2018-03-08 19:08:21 iter 25 loss = 10.252551
2018-03-08 19:08:26 iter 50 loss = 7.773274
2018-03-08 19:08:30 iter 75 loss = 7.793456
2018-03-08 19:08:35 iter 100 loss = 8.459970
2018-03-08 19:08:39 iter 125 loss = 5.942829
2018-03-08 19:08:39 epoch 162/500 average_loss = 8.977574

2018-03-08 19:08:39 start epoch 163/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:08:40 iter 1 loss = 9.547190
2018-03-08 19:08:44 iter 25 loss = 6.546638
2018-03-08 19:08:48 iter 50 loss = 8.473321
2018-03-08 19:08:53 iter 75 loss = 9.223266
2018-03-08 19:08:57 iter 100 loss = 10.394855
2018-03-08 19:09:02 iter 125 loss = 6.116466
2018-03-08 19:09:02 epoch 163/500 average_loss = 8.801574

2018-03-08 19:09:02 start epoch 164/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:09:02 iter 1 loss = 7.499070
2018-03-08 19:09:07 iter 25 loss = 8.242444
2018-03-08 19:09:11 iter 50 loss = 3.981971
2018-03-08 19:09:16 iter 75 loss = 7.639490
2018-03-08 19:09:20 iter 100 loss = 6.476680
2018-03-08 19:09:25 iter 125 loss = 8.586714
2018-03-08 19:09:25 epoch 164/500 average_loss = 8.643556

2018-03-08 19:09:25 start epoch 165/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:09:25 iter 1 loss = 9.838006
2018-03-08 19:09:29 iter 25 loss = 6.085719
2018-03-08 19:09:34 iter 50 loss = 9.115996
2018-03-08 19:09:38 iter 75 loss = 10.113126
2018-03-08 19:09:43 iter 100 loss = 11.609374
2018-03-08 19:09:47 iter 125 loss = 7.994668
2018-03-08 19:09:47 epoch 165/500 average_loss = 8.449408

2018-03-08 19:09:47 start epoch 166/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:09:48 iter 1 loss = 10.271822
2018-03-08 19:09:52 iter 25 loss = 9.897830
2018-03-08 19:09:57 iter 50 loss = 7.796832
2018-03-08 19:10:01 iter 75 loss = 6.498860
2018-03-08 19:10:06 iter 100 loss = 8.021913
2018-03-08 19:10:10 iter 125 loss = 10.152410
2018-03-08 19:10:10 epoch 166/500 average_loss = 8.282483

2018-03-08 19:10:10 start epoch 167/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:10:10 iter 1 loss = 7.721219
2018-03-08 19:10:15 iter 25 loss = 7.836401
2018-03-08 19:10:19 iter 50 loss = 6.503266
2018-03-08 19:10:24 iter 75 loss = 7.740662
2018-03-08 19:10:28 iter 100 loss = 6.824678
2018-03-08 19:10:33 iter 125 loss = 8.849044
2018-03-08 19:10:33 epoch 167/500 average_loss = 8.275341

2018-03-08 19:10:33 start epoch 168/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:10:33 iter 1 loss = 7.761986
2018-03-08 19:10:38 iter 25 loss = 9.203713
2018-03-08 19:10:42 iter 50 loss = 7.565244
2018-03-08 19:10:47 iter 75 loss = 7.877383
2018-03-08 19:10:51 iter 100 loss = 8.478478
2018-03-08 19:10:56 iter 125 loss = 6.238974
2018-03-08 19:10:56 epoch 168/500 average_loss = 7.839902

2018-03-08 19:10:56 start epoch 169/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:10:56 iter 1 loss = 6.256137
2018-03-08 19:11:00 iter 25 loss = 10.094778
2018-03-08 19:11:05 iter 50 loss = 4.981079
2018-03-08 19:11:09 iter 75 loss = 8.207273
2018-03-08 19:11:14 iter 100 loss = 4.752101
2018-03-08 19:11:18 iter 125 loss = 9.680070
2018-03-08 19:11:18 epoch 169/500 average_loss = 7.666151

2018-03-08 19:11:18 start epoch 170/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:11:18 iter 1 loss = 9.675342
2018-03-08 19:11:23 iter 25 loss = 6.611403
2018-03-08 19:11:27 iter 50 loss = 11.438168
2018-03-08 19:11:32 iter 75 loss = 6.499012
2018-03-08 19:11:36 iter 100 loss = 9.474809
2018-03-08 19:11:41 iter 125 loss = 5.570875
2018-03-08 19:11:41 epoch 170/500 average_loss = 7.555580

2018-03-08 19:11:41 start epoch 171/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:11:41 iter 1 loss = 7.004663
2018-03-08 19:11:45 iter 25 loss = 9.289925
2018-03-08 19:11:50 iter 50 loss = 6.229413
2018-03-08 19:11:54 iter 75 loss = 6.547937
2018-03-08 19:11:59 iter 100 loss = 10.506907
2018-03-08 19:12:03 iter 125 loss = 7.021217
2018-03-08 19:12:03 epoch 171/500 average_loss = 7.218949

2018-03-08 19:12:03 start epoch 172/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:12:04 iter 1 loss = 5.403197
2018-03-08 19:12:08 iter 25 loss = 5.759188
2018-03-08 19:12:13 iter 50 loss = 6.262228
2018-03-08 19:12:17 iter 75 loss = 7.169234
2018-03-08 19:12:22 iter 100 loss = 6.542900
2018-03-08 19:12:26 iter 125 loss = 6.719784
2018-03-08 19:12:26 epoch 172/500 average_loss = 7.092759

2018-03-08 19:12:26 start epoch 173/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:12:27 iter 1 loss = 5.774484
2018-03-08 19:12:31 iter 25 loss = 7.733954
2018-03-08 19:12:35 iter 50 loss = 3.878299
2018-03-08 19:12:40 iter 75 loss = 5.882998
2018-03-08 19:12:44 iter 100 loss = 12.582721
2018-03-08 19:12:49 iter 125 loss = 6.376991
2018-03-08 19:12:49 epoch 173/500 average_loss = 6.905853

2018-03-08 19:12:49 start epoch 174/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:12:49 iter 1 loss = 10.288407
2018-03-08 19:12:54 iter 25 loss = 4.723929
2018-03-08 19:12:58 iter 50 loss = 5.031021
2018-03-08 19:13:03 iter 75 loss = 7.948125
2018-03-08 19:13:07 iter 100 loss = 7.202598
2018-03-08 19:13:12 iter 125 loss = 7.661669
2018-03-08 19:13:12 epoch 174/500 average_loss = 6.671058

2018-03-08 19:13:12 start epoch 175/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:13:12 iter 1 loss = 5.911405
2018-03-08 19:13:16 iter 25 loss = 7.204905
2018-03-08 19:13:21 iter 50 loss = 8.347774
2018-03-08 19:13:25 iter 75 loss = 8.670153
2018-03-08 19:13:30 iter 100 loss = 6.910172
2018-03-08 19:13:34 iter 125 loss = 7.861695
2018-03-08 19:13:34 epoch 175/500 average_loss = 6.362879

2018-03-08 19:13:34 start epoch 176/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:13:35 iter 1 loss = 7.113429
2018-03-08 19:13:39 iter 25 loss = 6.492712
2018-03-08 19:13:43 iter 50 loss = 5.369847
2018-03-08 19:13:48 iter 75 loss = 4.114840
2018-03-08 19:13:52 iter 100 loss = 7.584651
2018-03-08 19:13:57 iter 125 loss = 5.230526
2018-03-08 19:13:57 epoch 176/500 average_loss = 6.281216

2018-03-08 19:13:57 start epoch 177/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:13:57 iter 1 loss = 7.793108
2018-03-08 19:14:02 iter 25 loss = 5.655772
2018-03-08 19:14:06 iter 50 loss = 4.622310
2018-03-08 19:14:11 iter 75 loss = 6.701264
2018-03-08 19:14:15 iter 100 loss = 6.951792
2018-03-08 19:14:20 iter 125 loss = 6.725945
2018-03-08 19:14:20 epoch 177/500 average_loss = 5.998217

2018-03-08 19:14:20 start epoch 178/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:14:20 iter 1 loss = 6.182891
2018-03-08 19:14:24 iter 25 loss = 2.616933
2018-03-08 19:14:29 iter 50 loss = 6.531046
2018-03-08 19:14:33 iter 75 loss = 6.112081
2018-03-08 19:14:38 iter 100 loss = 3.843343
2018-03-08 19:14:42 iter 125 loss = 5.515803
2018-03-08 19:14:42 epoch 178/500 average_loss = 5.783387

2018-03-08 19:14:42 start epoch 179/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:14:43 iter 1 loss = 5.125729
2018-03-08 19:14:47 iter 25 loss = 4.815613
2018-03-08 19:14:51 iter 50 loss = 4.685357
2018-03-08 19:14:56 iter 75 loss = 4.477552
2018-03-08 19:15:00 iter 100 loss = 6.143092
2018-03-08 19:15:05 iter 125 loss = 5.135909
2018-03-08 19:15:05 epoch 179/500 average_loss = 5.620972

2018-03-08 19:15:05 start epoch 180/500: learning_rate = 0.0006710886400000004 sequence_len = 28
2018-03-08 19:15:05 iter 1 loss = 7.027503
2018-03-08 19:15:09 iter 25 loss = 5.549111
2018-03-08 19:15:14 iter 50 loss = 3.565343
2018-03-08 19:15:18 iter 75 loss = 10.603332
2018-03-08 19:15:23 iter 100 loss = 4.259562
2018-03-08 19:15:27 iter 125 loss = 5.162560
2018-03-08 19:15:27 epoch 180/500 average_loss = 5.400326

2018-03-08 19:15:27 start epoch 181/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:15:28 iter 1 loss = 4.341733
2018-03-08 19:15:32 iter 25 loss = 4.860752
2018-03-08 19:15:37 iter 50 loss = 3.856999
2018-03-08 19:15:41 iter 75 loss = 5.159884
2018-03-08 19:15:46 iter 100 loss = 3.422512
2018-03-08 19:15:50 iter 125 loss = 5.216937
2018-03-08 19:15:50 epoch 181/500 average_loss = 5.003834

2018-03-08 19:15:50 start epoch 182/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:15:50 iter 1 loss = 3.276183
2018-03-08 19:15:55 iter 25 loss = 5.028887
2018-03-08 19:15:59 iter 50 loss = 3.854985
2018-03-08 19:16:04 iter 75 loss = 5.269560
2018-03-08 19:16:08 iter 100 loss = 3.419203
2018-03-08 19:16:13 iter 125 loss = 3.882983
2018-03-08 19:16:13 epoch 182/500 average_loss = 4.690259

2018-03-08 19:16:13 start epoch 183/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:16:13 iter 1 loss = 2.687712
2018-03-08 19:16:17 iter 25 loss = 2.673383
2018-03-08 19:16:22 iter 50 loss = 5.105788
2018-03-08 19:16:27 iter 75 loss = 3.629991
2018-03-08 19:16:31 iter 100 loss = 3.818667
2018-03-08 19:16:36 iter 125 loss = 7.858913
2018-03-08 19:16:36 epoch 183/500 average_loss = 4.624182

2018-03-08 19:16:36 start epoch 184/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:16:36 iter 1 loss = 3.473762
2018-03-08 19:16:40 iter 25 loss = 4.223597
2018-03-08 19:16:45 iter 50 loss = 3.923047
2018-03-08 19:16:49 iter 75 loss = 4.649187
2018-03-08 19:16:54 iter 100 loss = 3.653983
2018-03-08 19:16:58 iter 125 loss = 5.765708
2018-03-08 19:16:58 epoch 184/500 average_loss = 4.442886

2018-03-08 19:16:58 start epoch 185/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:16:59 iter 1 loss = 7.164298
2018-03-08 19:17:03 iter 25 loss = 5.093094
2018-03-08 19:17:07 iter 50 loss = 4.399744
2018-03-08 19:17:12 iter 75 loss = 2.912484
2018-03-08 19:17:16 iter 100 loss = 5.867140
2018-03-08 19:17:21 iter 125 loss = 5.557035
2018-03-08 19:17:21 epoch 185/500 average_loss = 4.240437

2018-03-08 19:17:21 start epoch 186/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:17:21 iter 1 loss = 4.062156
2018-03-08 19:17:26 iter 25 loss = 3.311960
2018-03-08 19:17:30 iter 50 loss = 5.039804
2018-03-08 19:17:35 iter 75 loss = 4.812932
2018-03-08 19:17:39 iter 100 loss = 5.554128
2018-03-08 19:17:44 iter 125 loss = 3.783259
2018-03-08 19:17:44 epoch 186/500 average_loss = 4.019617

2018-03-08 19:17:44 start epoch 187/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:17:44 iter 1 loss = 2.978233
2018-03-08 19:17:48 iter 25 loss = 4.274752
2018-03-08 19:17:53 iter 50 loss = 3.921135
2018-03-08 19:17:57 iter 75 loss = 1.651983
2018-03-08 19:18:02 iter 100 loss = 3.853238
2018-03-08 19:18:06 iter 125 loss = 3.645679
2018-03-08 19:18:06 epoch 187/500 average_loss = 3.862819

2018-03-08 19:18:06 start epoch 188/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:18:07 iter 1 loss = 3.074008
2018-03-08 19:18:11 iter 25 loss = 3.012133
2018-03-08 19:18:16 iter 50 loss = 5.145976
2018-03-08 19:18:20 iter 75 loss = 4.386749
2018-03-08 19:18:25 iter 100 loss = 2.407958
2018-03-08 19:18:29 iter 125 loss = 3.096771
2018-03-08 19:18:29 epoch 188/500 average_loss = 3.620595

2018-03-08 19:18:29 start epoch 189/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:18:30 iter 1 loss = 5.531521
2018-03-08 19:18:34 iter 25 loss = 3.618239
2018-03-08 19:18:38 iter 50 loss = 2.454950
2018-03-08 19:18:43 iter 75 loss = 3.651427
2018-03-08 19:18:47 iter 100 loss = 2.575164
2018-03-08 19:18:52 iter 125 loss = 3.099373
2018-03-08 19:18:52 epoch 189/500 average_loss = 3.405359

2018-03-08 19:18:52 start epoch 190/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:18:52 iter 1 loss = 2.411551
2018-03-08 19:18:57 iter 25 loss = 4.033774
2018-03-08 19:19:01 iter 50 loss = 2.467620
2018-03-08 19:19:06 iter 75 loss = 3.911086
2018-03-08 19:19:10 iter 100 loss = 2.427505
2018-03-08 19:19:15 iter 125 loss = 3.405576
2018-03-08 19:19:15 epoch 190/500 average_loss = 3.291984

2018-03-08 19:19:15 start epoch 191/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:19:15 iter 1 loss = 3.658116
2018-03-08 19:19:19 iter 25 loss = 3.996294
2018-03-08 19:19:24 iter 50 loss = 3.463677
2018-03-08 19:19:28 iter 75 loss = 4.750719
2018-03-08 19:19:33 iter 100 loss = 6.897083
2018-03-08 19:19:37 iter 125 loss = 2.631788
2018-03-08 19:19:37 epoch 191/500 average_loss = 3.123295

2018-03-08 19:19:37 start epoch 192/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:19:38 iter 1 loss = 3.263946
2018-03-08 19:19:42 iter 25 loss = 2.343475
2018-03-08 19:19:46 iter 50 loss = 4.556880
2018-03-08 19:19:51 iter 75 loss = 1.890146
2018-03-08 19:19:56 iter 100 loss = 1.693790
2018-03-08 19:20:00 iter 125 loss = 1.861744
2018-03-08 19:20:00 epoch 192/500 average_loss = 2.923781

2018-03-08 19:20:00 start epoch 193/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:20:00 iter 1 loss = 5.811708
2018-03-08 19:20:05 iter 25 loss = 2.431707
2018-03-08 19:20:09 iter 50 loss = 3.074174
2018-03-08 19:20:14 iter 75 loss = 2.331316
2018-03-08 19:20:18 iter 100 loss = 3.260937
2018-03-08 19:20:23 iter 125 loss = 3.199259
2018-03-08 19:20:23 epoch 193/500 average_loss = 2.805565

2018-03-08 19:20:23 start epoch 194/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:20:23 iter 1 loss = 2.304454
2018-03-08 19:20:27 iter 25 loss = 2.785383
2018-03-08 19:20:32 iter 50 loss = 3.893705
2018-03-08 19:20:36 iter 75 loss = 3.053225
2018-03-08 19:20:41 iter 100 loss = 2.552413
2018-03-08 19:20:45 iter 125 loss = 2.177151
2018-03-08 19:20:45 epoch 194/500 average_loss = 2.604182

2018-03-08 19:20:45 start epoch 195/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:20:46 iter 1 loss = 2.010342
2018-03-08 19:20:50 iter 25 loss = 2.899449
2018-03-08 19:20:55 iter 50 loss = 2.182443
2018-03-08 19:20:59 iter 75 loss = 1.544280
2018-03-08 19:21:04 iter 100 loss = 5.267935
2018-03-08 19:21:08 iter 125 loss = 3.230400
2018-03-08 19:21:08 epoch 195/500 average_loss = 2.479722

2018-03-08 19:21:08 start epoch 196/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:21:09 iter 1 loss = 1.802877
2018-03-08 19:21:13 iter 25 loss = 0.849006
2018-03-08 19:21:17 iter 50 loss = 3.975789
2018-03-08 19:21:22 iter 75 loss = 2.484893
2018-03-08 19:21:26 iter 100 loss = 3.626054
2018-03-08 19:21:31 iter 125 loss = 3.180977
2018-03-08 19:21:31 epoch 196/500 average_loss = 2.356845

2018-03-08 19:21:31 start epoch 197/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:21:31 iter 1 loss = 5.700984
2018-03-08 19:21:36 iter 25 loss = 2.145600
2018-03-08 19:21:40 iter 50 loss = 1.694910
2018-03-08 19:21:45 iter 75 loss = 2.620368
2018-03-08 19:21:49 iter 100 loss = 3.351726
2018-03-08 19:21:54 iter 125 loss = 3.434710
2018-03-08 19:21:54 epoch 197/500 average_loss = 2.197913

2018-03-08 19:21:54 start epoch 198/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:21:54 iter 1 loss = 1.985741
2018-03-08 19:21:58 iter 25 loss = 1.865352
2018-03-08 19:22:03 iter 50 loss = 1.513009
2018-03-08 19:22:07 iter 75 loss = 2.907713
2018-03-08 19:22:12 iter 100 loss = 2.995685
2018-03-08 19:22:16 iter 125 loss = 2.453768
2018-03-08 19:22:16 epoch 198/500 average_loss = 2.112842

2018-03-08 19:22:16 start epoch 199/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:22:17 iter 1 loss = 1.597140
2018-03-08 19:22:21 iter 25 loss = 1.454707
2018-03-08 19:22:26 iter 50 loss = 1.455836
2018-03-08 19:22:30 iter 75 loss = 1.899583
2018-03-08 19:22:35 iter 100 loss = 2.552548
2018-03-08 19:22:39 iter 125 loss = 1.208901
2018-03-08 19:22:39 epoch 199/500 average_loss = 1.928457

2018-03-08 19:22:39 start epoch 200/500: learning_rate = 0.0005368709120000003 sequence_len = 28
2018-03-08 19:22:39 iter 1 loss = 1.242332
2018-03-08 19:22:44 iter 25 loss = 1.695055
2018-03-08 19:22:48 iter 50 loss = 2.423180
2018-03-08 19:22:53 iter 75 loss = 1.750789
2018-03-08 19:22:57 iter 100 loss = 1.693467
2018-03-08 19:23:02 iter 125 loss = 1.234011
2018-03-08 19:23:02 epoch 200/500 average_loss = 1.753134

2018-03-08 19:23:02 start epoch 201/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:23:02 iter 1 loss = 1.842937
2018-03-08 19:23:06 iter 25 loss = 2.092656
2018-03-08 19:23:11 iter 50 loss = 1.824775
2018-03-08 19:23:15 iter 75 loss = 0.598432
2018-03-08 19:23:20 iter 100 loss = 0.976877
2018-03-08 19:23:25 iter 125 loss = 1.430074
2018-03-08 19:23:25 epoch 201/500 average_loss = 1.581373

2018-03-08 19:23:25 start epoch 202/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:23:25 iter 1 loss = 1.040709
2018-03-08 19:23:29 iter 25 loss = 1.834235
2018-03-08 19:23:34 iter 50 loss = 0.723648
2018-03-08 19:23:38 iter 75 loss = 0.594097
2018-03-08 19:23:43 iter 100 loss = 1.034965
2018-03-08 19:23:47 iter 125 loss = 0.979651
2018-03-08 19:23:47 epoch 202/500 average_loss = 1.392249

2018-03-08 19:23:47 start epoch 203/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:23:48 iter 1 loss = 1.061839
2018-03-08 19:23:52 iter 25 loss = 1.091229
2018-03-08 19:23:56 iter 50 loss = 0.933876
2018-03-08 19:24:01 iter 75 loss = 0.774851
2018-03-08 19:24:05 iter 100 loss = 1.312761
2018-03-08 19:24:10 iter 125 loss = 2.850335
2018-03-08 19:24:10 epoch 203/500 average_loss = 1.384848

2018-03-08 19:24:10 start epoch 204/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:24:10 iter 1 loss = 1.388992
2018-03-08 19:24:15 iter 25 loss = 0.910715
2018-03-08 19:24:19 iter 50 loss = 1.165313
2018-03-08 19:24:24 iter 75 loss = 0.647309
2018-03-08 19:24:28 iter 100 loss = 2.592779
2018-03-08 19:24:33 iter 125 loss = 2.280507
2018-03-08 19:24:33 epoch 204/500 average_loss = 1.266535

2018-03-08 19:24:33 start epoch 205/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:24:33 iter 1 loss = 1.209756
2018-03-08 19:24:37 iter 25 loss = 2.593600
2018-03-08 19:24:42 iter 50 loss = 1.704360
2018-03-08 19:24:46 iter 75 loss = 1.230445
2018-03-08 19:24:51 iter 100 loss = 0.686054
2018-03-08 19:24:55 iter 125 loss = 0.789311
2018-03-08 19:24:55 epoch 205/500 average_loss = 1.132369

2018-03-08 19:24:55 start epoch 206/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:24:56 iter 1 loss = 1.154987
2018-03-08 19:25:00 iter 25 loss = 1.512707
2018-03-08 19:25:05 iter 50 loss = 0.661530
2018-03-08 19:25:09 iter 75 loss = 1.403314
2018-03-08 19:25:14 iter 100 loss = 1.476315
2018-03-08 19:25:18 iter 125 loss = 0.883850
2018-03-08 19:25:18 epoch 206/500 average_loss = 1.049501

2018-03-08 19:25:18 start epoch 207/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:25:19 iter 1 loss = 0.620963
2018-03-08 19:25:23 iter 25 loss = 0.978018
2018-03-08 19:25:28 iter 50 loss = 0.835926
2018-03-08 19:25:32 iter 75 loss = 0.583252
2018-03-08 19:25:37 iter 100 loss = 0.952811
2018-03-08 19:25:41 iter 125 loss = 0.991776
2018-03-08 19:25:41 epoch 207/500 average_loss = 1.027483

2018-03-08 19:25:41 start epoch 208/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:25:41 iter 1 loss = 0.644064
2018-03-08 19:25:46 iter 25 loss = 0.765927
2018-03-08 19:25:50 iter 50 loss = 0.851877
2018-03-08 19:25:55 iter 75 loss = 1.699063
2018-03-08 19:25:59 iter 100 loss = 0.867723
2018-03-08 19:26:04 iter 125 loss = 1.323448
2018-03-08 19:26:04 epoch 208/500 average_loss = 0.935084

2018-03-08 19:26:04 start epoch 209/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:26:04 iter 1 loss = 0.415345
2018-03-08 19:26:09 iter 25 loss = 0.902233
2018-03-08 19:26:13 iter 50 loss = 0.440118
2018-03-08 19:26:18 iter 75 loss = 0.548185
2018-03-08 19:26:22 iter 100 loss = 0.776855
2018-03-08 19:26:27 iter 125 loss = 0.594942
2018-03-08 19:26:27 epoch 209/500 average_loss = 0.862128

2018-03-08 19:26:27 start epoch 210/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:26:27 iter 1 loss = 0.556058
2018-03-08 19:26:31 iter 25 loss = 0.867801
2018-03-08 19:26:36 iter 50 loss = 0.491824
2018-03-08 19:26:40 iter 75 loss = 0.506447
2018-03-08 19:26:45 iter 100 loss = 0.717113
2018-03-08 19:26:49 iter 125 loss = 0.707258
2018-03-08 19:26:49 epoch 210/500 average_loss = 0.819241

2018-03-08 19:26:49 start epoch 211/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:26:50 iter 1 loss = 0.463123
2018-03-08 19:26:54 iter 25 loss = 0.343845
2018-03-08 19:26:59 iter 50 loss = 1.056643
2018-03-08 19:27:03 iter 75 loss = 0.805113
2018-03-08 19:27:08 iter 100 loss = 0.645295
2018-03-08 19:27:12 iter 125 loss = 0.589146
2018-03-08 19:27:12 epoch 211/500 average_loss = 0.768039

2018-03-08 19:27:12 start epoch 212/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:27:13 iter 1 loss = 2.231835
2018-03-08 19:27:17 iter 25 loss = 0.664782
2018-03-08 19:27:21 iter 50 loss = 0.979702
2018-03-08 19:27:26 iter 75 loss = 1.009038
2018-03-08 19:27:30 iter 100 loss = 0.503534
2018-03-08 19:27:35 iter 125 loss = 0.622646
2018-03-08 19:27:35 epoch 212/500 average_loss = 0.750301

2018-03-08 19:27:35 start epoch 213/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:27:35 iter 1 loss = 0.437190
2018-03-08 19:27:40 iter 25 loss = 0.846689
2018-03-08 19:27:44 iter 50 loss = 0.486428
2018-03-08 19:27:49 iter 75 loss = 1.319913
2018-03-08 19:27:53 iter 100 loss = 0.819880
2018-03-08 19:27:58 iter 125 loss = 1.069931
2018-03-08 19:27:58 epoch 213/500 average_loss = 0.745671

2018-03-08 19:27:58 start epoch 214/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:27:58 iter 1 loss = 0.440571
2018-03-08 19:28:02 iter 25 loss = 0.660750
2018-03-08 19:28:07 iter 50 loss = 0.785866
2018-03-08 19:28:11 iter 75 loss = 0.881407
2018-03-08 19:28:16 iter 100 loss = 0.991346
2018-03-08 19:28:20 iter 125 loss = 0.799300
2018-03-08 19:28:20 epoch 214/500 average_loss = 0.628795

2018-03-08 19:28:20 start epoch 215/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:28:21 iter 1 loss = 0.416586
2018-03-08 19:28:25 iter 25 loss = 0.447688
2018-03-08 19:28:30 iter 50 loss = 1.106461
2018-03-08 19:28:34 iter 75 loss = 0.829040
2018-03-08 19:28:39 iter 100 loss = 0.526345
2018-03-08 19:28:43 iter 125 loss = 0.496279
2018-03-08 19:28:43 epoch 215/500 average_loss = 0.594135

2018-03-08 19:28:43 start epoch 216/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:28:43 iter 1 loss = 0.550167
2018-03-08 19:28:48 iter 25 loss = 0.222489
2018-03-08 19:28:52 iter 50 loss = 0.421047
2018-03-08 19:28:57 iter 75 loss = 0.578653
2018-03-08 19:29:01 iter 100 loss = 0.846488
2018-03-08 19:29:06 iter 125 loss = 0.436231
2018-03-08 19:29:06 epoch 216/500 average_loss = 0.549850

2018-03-08 19:29:06 start epoch 217/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:29:06 iter 1 loss = 0.604457
2018-03-08 19:29:11 iter 25 loss = 0.725416
2018-03-08 19:29:15 iter 50 loss = 0.420610
2018-03-08 19:29:20 iter 75 loss = 0.281889
2018-03-08 19:29:24 iter 100 loss = 0.466504
2018-03-08 19:29:29 iter 125 loss = 0.449882
2018-03-08 19:29:29 epoch 217/500 average_loss = 0.525071

2018-03-08 19:29:29 start epoch 218/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:29:29 iter 1 loss = 0.302497
2018-03-08 19:29:33 iter 25 loss = 0.289472
2018-03-08 19:29:38 iter 50 loss = 0.187576
2018-03-08 19:29:42 iter 75 loss = 0.315421
2018-03-08 19:29:47 iter 100 loss = 0.518157
2018-03-08 19:29:51 iter 125 loss = 0.631601
2018-03-08 19:29:51 epoch 218/500 average_loss = 0.460236

2018-03-08 19:29:51 start epoch 219/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:29:52 iter 1 loss = 0.597248
2018-03-08 19:29:56 iter 25 loss = 0.611437
2018-03-08 19:30:00 iter 50 loss = 0.447040
2018-03-08 19:30:05 iter 75 loss = 0.289085
2018-03-08 19:30:10 iter 100 loss = 0.337785
2018-03-08 19:30:14 iter 125 loss = 0.268662
2018-03-08 19:30:14 epoch 219/500 average_loss = 0.474080

2018-03-08 19:30:14 start epoch 220/500: learning_rate = 0.00042949672960000023 sequence_len = 28
2018-03-08 19:30:14 iter 1 loss = 0.249637
2018-03-08 19:30:19 iter 25 loss = 0.433073
2018-03-08 19:30:23 iter 50 loss = 0.261736
2018-03-08 19:30:28 iter 75 loss = 0.915926
2018-03-08 19:30:32 iter 100 loss = 0.649917
2018-03-08 19:30:37 iter 125 loss = 0.375428
2018-03-08 19:30:37 epoch 220/500 average_loss = 0.406015

2018-03-08 19:30:37 start epoch 221/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:30:37 iter 1 loss = 0.305837
2018-03-08 19:30:42 iter 25 loss = 0.664516
2018-03-08 19:30:46 iter 50 loss = 0.135985
2018-03-08 19:30:51 iter 75 loss = 0.357046
2018-03-08 19:30:55 iter 100 loss = 0.633911
2018-03-08 19:31:00 iter 125 loss = 0.481676
2018-03-08 19:31:00 epoch 221/500 average_loss = 0.350161

2018-03-08 19:31:00 start epoch 222/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:31:00 iter 1 loss = 0.354163
2018-03-08 19:31:04 iter 25 loss = 0.444150
2018-03-08 19:31:09 iter 50 loss = 0.211333
2018-03-08 19:31:13 iter 75 loss = 0.706547
2018-03-08 19:31:18 iter 100 loss = 0.274121
2018-03-08 19:31:22 iter 125 loss = 0.338749
2018-03-08 19:31:22 epoch 222/500 average_loss = 0.278321

2018-03-08 19:31:22 start epoch 223/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:31:23 iter 1 loss = 0.157873
2018-03-08 19:31:27 iter 25 loss = 0.497835
2018-03-08 19:31:32 iter 50 loss = 0.148826
2018-03-08 19:31:36 iter 75 loss = 0.163011
2018-03-08 19:31:41 iter 100 loss = 0.240933
2018-03-08 19:31:45 iter 125 loss = 0.314382
2018-03-08 19:31:45 epoch 223/500 average_loss = 0.263449

2018-03-08 19:31:45 start epoch 224/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:31:45 iter 1 loss = 0.195437
2018-03-08 19:31:50 iter 25 loss = 0.141576
2018-03-08 19:31:54 iter 50 loss = 0.203217
2018-03-08 19:31:59 iter 75 loss = 0.253203
2018-03-08 19:32:03 iter 100 loss = 0.116623
2018-03-08 19:32:08 iter 125 loss = 0.337815
2018-03-08 19:32:08 epoch 224/500 average_loss = 0.263796

2018-03-08 19:32:08 start epoch 225/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:32:08 iter 1 loss = 0.219769
2018-03-08 19:32:13 iter 25 loss = 0.206703
2018-03-08 19:32:17 iter 50 loss = 0.196623
2018-03-08 19:32:22 iter 75 loss = 0.386870
2018-03-08 19:32:26 iter 100 loss = 0.287292
2018-03-08 19:32:31 iter 125 loss = 0.226225
2018-03-08 19:32:31 epoch 225/500 average_loss = 0.262256

2018-03-08 19:32:31 start epoch 226/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:32:31 iter 1 loss = 0.258543
2018-03-08 19:32:35 iter 25 loss = 0.271922
2018-03-08 19:32:40 iter 50 loss = 0.279719
2018-03-08 19:32:44 iter 75 loss = 0.292996
2018-03-08 19:32:49 iter 100 loss = 0.337075
2018-03-08 19:32:53 iter 125 loss = 0.241250
2018-03-08 19:32:53 epoch 226/500 average_loss = 0.241408

2018-03-08 19:32:53 start epoch 227/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:32:54 iter 1 loss = 0.162697
2018-03-08 19:32:58 iter 25 loss = 0.212967
2018-03-08 19:33:02 iter 50 loss = 0.122531
2018-03-08 19:33:07 iter 75 loss = 0.141270
2018-03-08 19:33:12 iter 100 loss = 0.153088
2018-03-08 19:33:16 iter 125 loss = 0.296838
2018-03-08 19:33:16 epoch 227/500 average_loss = 0.227222

2018-03-08 19:33:16 start epoch 228/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:33:16 iter 1 loss = 0.285241
2018-03-08 19:33:21 iter 25 loss = 0.191106
2018-03-08 19:33:25 iter 50 loss = 0.148890
2018-03-08 19:33:30 iter 75 loss = 0.130477
2018-03-08 19:33:34 iter 100 loss = 0.338788
2018-03-08 19:33:39 iter 125 loss = 0.182371
2018-03-08 19:33:39 epoch 228/500 average_loss = 0.209384

2018-03-08 19:33:39 start epoch 229/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:33:39 iter 1 loss = 0.174800
2018-03-08 19:33:43 iter 25 loss = 0.255651
2018-03-08 19:33:48 iter 50 loss = 0.151001
2018-03-08 19:33:52 iter 75 loss = 0.127954
2018-03-08 19:33:57 iter 100 loss = 0.109880
2018-03-08 19:34:02 iter 125 loss = 0.118773
2018-03-08 19:34:02 epoch 229/500 average_loss = 0.218068

2018-03-08 19:34:02 start epoch 230/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:34:02 iter 1 loss = 0.137711
2018-03-08 19:34:06 iter 25 loss = 0.233971
2018-03-08 19:34:11 iter 50 loss = 0.152179
2018-03-08 19:34:15 iter 75 loss = 0.239949
2018-03-08 19:34:20 iter 100 loss = 0.202472
2018-03-08 19:34:24 iter 125 loss = 0.159537
2018-03-08 19:34:24 epoch 230/500 average_loss = 0.202732

2018-03-08 19:34:24 start epoch 231/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:34:25 iter 1 loss = 0.141457
2018-03-08 19:34:29 iter 25 loss = 0.455955
2018-03-08 19:34:33 iter 50 loss = 0.125356
2018-03-08 19:34:38 iter 75 loss = 0.171877
2018-03-08 19:34:43 iter 100 loss = 0.098863
2018-03-08 19:34:47 iter 125 loss = 0.457041
2018-03-08 19:34:47 epoch 231/500 average_loss = 0.220196

2018-03-08 19:34:47 start epoch 232/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:34:47 iter 1 loss = 0.257379
2018-03-08 19:34:52 iter 25 loss = 0.240789
2018-03-08 19:34:56 iter 50 loss = 0.121378
2018-03-08 19:35:01 iter 75 loss = 0.341279
2018-03-08 19:35:05 iter 100 loss = 0.328308
2018-03-08 19:35:10 iter 125 loss = 0.297876
2018-03-08 19:35:10 epoch 232/500 average_loss = 0.235687

2018-03-08 19:35:10 start epoch 233/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:35:10 iter 1 loss = 0.222631
2018-03-08 19:35:14 iter 25 loss = 0.151584
2018-03-08 19:35:19 iter 50 loss = 0.120470
2018-03-08 19:35:23 iter 75 loss = 0.138709
2018-03-08 19:35:28 iter 100 loss = 0.193121
2018-03-08 19:35:32 iter 125 loss = 0.182106
2018-03-08 19:35:32 epoch 233/500 average_loss = 0.182846

2018-03-08 19:35:32 start epoch 234/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:35:33 iter 1 loss = 0.144868
2018-03-08 19:35:37 iter 25 loss = 0.119790
2018-03-08 19:35:42 iter 50 loss = 0.087098
2018-03-08 19:35:46 iter 75 loss = 0.123165
2018-03-08 19:35:51 iter 100 loss = 0.114447
2018-03-08 19:35:55 iter 125 loss = 0.148920
2018-03-08 19:35:55 epoch 234/500 average_loss = 0.161626

2018-03-08 19:35:55 start epoch 235/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:35:56 iter 1 loss = 0.054680
2018-03-08 19:36:00 iter 25 loss = 0.119007
2018-03-08 19:36:04 iter 50 loss = 0.121713
2018-03-08 19:36:09 iter 75 loss = 0.154529
2018-03-08 19:36:13 iter 100 loss = 0.155531
2018-03-08 19:36:18 iter 125 loss = 0.167864
2018-03-08 19:36:18 epoch 235/500 average_loss = 0.145418

2018-03-08 19:36:18 start epoch 236/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:36:18 iter 1 loss = 0.082236
2018-03-08 19:36:23 iter 25 loss = 0.109802
2018-03-08 19:36:27 iter 50 loss = 0.124496
2018-03-08 19:36:32 iter 75 loss = 0.106869
2018-03-08 19:36:36 iter 100 loss = 0.300802
2018-03-08 19:36:41 iter 125 loss = 0.184149
2018-03-08 19:36:41 epoch 236/500 average_loss = 0.134681

2018-03-08 19:36:41 start epoch 237/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:36:41 iter 1 loss = 0.192444
2018-03-08 19:36:45 iter 25 loss = 0.144613
2018-03-08 19:36:50 iter 50 loss = 0.150772
2018-03-08 19:36:54 iter 75 loss = 0.099522
2018-03-08 19:36:59 iter 100 loss = 0.092707
2018-03-08 19:37:03 iter 125 loss = 0.179607
2018-03-08 19:37:03 epoch 237/500 average_loss = 0.153448

2018-03-08 19:37:03 start epoch 238/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:37:04 iter 1 loss = 0.118935
2018-03-08 19:37:08 iter 25 loss = 0.224601
2018-03-08 19:37:12 iter 50 loss = 0.157414
2018-03-08 19:37:17 iter 75 loss = 0.266209
2018-03-08 19:37:22 iter 100 loss = 0.145840
2018-03-08 19:37:26 iter 125 loss = 0.153049
2018-03-08 19:37:26 epoch 238/500 average_loss = 0.183518

2018-03-08 19:37:26 start epoch 239/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:37:26 iter 1 loss = 0.104505
2018-03-08 19:37:31 iter 25 loss = 0.125229
2018-03-08 19:37:35 iter 50 loss = 0.083176
2018-03-08 19:37:40 iter 75 loss = 0.075018
2018-03-08 19:37:44 iter 100 loss = 0.149169
2018-03-08 19:37:49 iter 125 loss = 0.245547
2018-03-08 19:37:49 epoch 239/500 average_loss = 0.190133

2018-03-08 19:37:49 start epoch 240/500: learning_rate = 0.0003435973836800002 sequence_len = 28
2018-03-08 19:37:49 iter 1 loss = 0.101534
2018-03-08 19:37:53 iter 25 loss = 0.128403
2018-03-08 19:37:58 iter 50 loss = 0.378067
2018-03-08 19:38:03 iter 75 loss = 0.136300
2018-03-08 19:38:07 iter 100 loss = 0.234978
2018-03-08 19:38:12 iter 125 loss = 0.227319
2018-03-08 19:38:12 epoch 240/500 average_loss = 0.182568

2018-03-08 19:38:12 start epoch 241/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:38:12 iter 1 loss = 0.149144
2018-03-08 19:38:16 iter 25 loss = 0.121745
2018-03-08 19:38:21 iter 50 loss = 0.112395
2018-03-08 19:38:25 iter 75 loss = 0.087098
2018-03-08 19:38:30 iter 100 loss = 0.154145
2018-03-08 19:38:34 iter 125 loss = 0.109463
2018-03-08 19:38:34 epoch 241/500 average_loss = 0.137306

2018-03-08 19:38:34 start epoch 242/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:38:35 iter 1 loss = 0.078873
2018-03-08 19:38:39 iter 25 loss = 0.113259
2018-03-08 19:38:44 iter 50 loss = 0.092096
2018-03-08 19:38:48 iter 75 loss = 0.151234
2018-03-08 19:38:53 iter 100 loss = 0.070432
2018-03-08 19:38:57 iter 125 loss = 0.080742
2018-03-08 19:38:57 epoch 242/500 average_loss = 0.088873

2018-03-08 19:38:57 start epoch 243/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:38:57 iter 1 loss = 0.030473
2018-03-08 19:39:02 iter 25 loss = 0.055614
2018-03-08 19:39:06 iter 50 loss = 0.041262
2018-03-08 19:39:11 iter 75 loss = 0.047798
2018-03-08 19:39:15 iter 100 loss = 0.088743
2018-03-08 19:39:20 iter 125 loss = 0.046265
2018-03-08 19:39:20 epoch 243/500 average_loss = 0.077720

2018-03-08 19:39:20 start epoch 244/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:39:20 iter 1 loss = 0.074205
2018-03-08 19:39:24 iter 25 loss = 0.057085
2018-03-08 19:39:29 iter 50 loss = 0.038743
2018-03-08 19:39:33 iter 75 loss = 0.070233
2018-03-08 19:39:38 iter 100 loss = 0.069883
2018-03-08 19:39:42 iter 125 loss = 0.052773
2018-03-08 19:39:42 epoch 244/500 average_loss = 0.077971

2018-03-08 19:39:42 start epoch 245/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:39:43 iter 1 loss = 0.063238
2018-03-08 19:39:47 iter 25 loss = 0.075464
2018-03-08 19:39:52 iter 50 loss = 0.043030
2018-03-08 19:39:56 iter 75 loss = 0.088722
2018-03-08 19:40:01 iter 100 loss = 0.031153
2018-03-08 19:40:05 iter 125 loss = 0.064396
2018-03-08 19:40:05 epoch 245/500 average_loss = 0.076333

2018-03-08 19:40:05 start epoch 246/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:40:06 iter 1 loss = 0.061012
2018-03-08 19:40:10 iter 25 loss = 0.088786
2018-03-08 19:40:14 iter 50 loss = 0.066287
2018-03-08 19:40:19 iter 75 loss = 0.112412
2018-03-08 19:40:23 iter 100 loss = 0.047976
2018-03-08 19:40:28 iter 125 loss = 0.133990
2018-03-08 19:40:28 epoch 246/500 average_loss = 0.081945

2018-03-08 19:40:28 start epoch 247/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:40:28 iter 1 loss = 0.039581
2018-03-08 19:40:33 iter 25 loss = 0.053238
2018-03-08 19:40:37 iter 50 loss = 0.066264
2018-03-08 19:40:42 iter 75 loss = 0.052281
2018-03-08 19:40:46 iter 100 loss = 0.057510
2018-03-08 19:40:51 iter 125 loss = 0.028411
2018-03-08 19:40:51 epoch 247/500 average_loss = 0.064975

2018-03-08 19:40:51 start epoch 248/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:40:51 iter 1 loss = 0.044262
2018-03-08 19:40:55 iter 25 loss = 0.158364
2018-03-08 19:41:00 iter 50 loss = 0.188142
2018-03-08 19:41:04 iter 75 loss = 0.140642
2018-03-08 19:41:09 iter 100 loss = 0.085974
2018-03-08 19:41:14 iter 125 loss = 0.050822
2018-03-08 19:41:14 epoch 248/500 average_loss = 0.103657

2018-03-08 19:41:14 start epoch 249/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:41:14 iter 1 loss = 0.084175
2018-03-08 19:41:18 iter 25 loss = 0.142473
2018-03-08 19:41:23 iter 50 loss = 0.067852
2018-03-08 19:41:27 iter 75 loss = 0.103593
2018-03-08 19:41:32 iter 100 loss = 0.073826
2018-03-08 19:41:36 iter 125 loss = 0.083792
2018-03-08 19:41:36 epoch 249/500 average_loss = 0.067589

2018-03-08 19:41:36 start epoch 250/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:41:37 iter 1 loss = 0.076703
2018-03-08 19:41:41 iter 25 loss = 0.068965
2018-03-08 19:41:46 iter 50 loss = 0.032271
2018-03-08 19:41:50 iter 75 loss = 0.068080
2018-03-08 19:41:55 iter 100 loss = 0.076546
2018-03-08 19:41:59 iter 125 loss = 0.047885
2018-03-08 19:41:59 epoch 250/500 average_loss = 0.063486

2018-03-08 19:41:59 start epoch 251/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:41:59 iter 1 loss = 0.070358
2018-03-08 19:42:04 iter 25 loss = 0.060331
2018-03-08 19:42:08 iter 50 loss = 0.056426
2018-03-08 19:42:13 iter 75 loss = 0.030672
2018-03-08 19:42:17 iter 100 loss = 0.054966
2018-03-08 19:42:22 iter 125 loss = 0.063068
2018-03-08 19:42:22 epoch 251/500 average_loss = 0.054514

2018-03-08 19:42:22 start epoch 252/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:42:22 iter 1 loss = 0.040014
2018-03-08 19:42:26 iter 25 loss = 0.073644
2018-03-08 19:42:31 iter 50 loss = 0.030987
2018-03-08 19:42:36 iter 75 loss = 0.055751
2018-03-08 19:42:40 iter 100 loss = 0.030363
2018-03-08 19:42:45 iter 125 loss = 0.063764
2018-03-08 19:42:45 epoch 252/500 average_loss = 0.046258

2018-03-08 19:42:45 start epoch 253/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:42:45 iter 1 loss = 0.031856
2018-03-08 19:42:49 iter 25 loss = 0.040079
2018-03-08 19:42:54 iter 50 loss = 0.087761
2018-03-08 19:42:58 iter 75 loss = 0.035856
2018-03-08 19:43:03 iter 100 loss = 0.033063
2018-03-08 19:43:07 iter 125 loss = 0.023056
2018-03-08 19:43:07 epoch 253/500 average_loss = 0.045886

2018-03-08 19:43:07 start epoch 254/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:43:08 iter 1 loss = 0.027319
2018-03-08 19:43:12 iter 25 loss = 0.028017
2018-03-08 19:43:16 iter 50 loss = 0.079835
2018-03-08 19:43:21 iter 75 loss = 0.034842
2018-03-08 19:43:25 iter 100 loss = 0.028988
2018-03-08 19:43:30 iter 125 loss = 0.042386
2018-03-08 19:43:30 epoch 254/500 average_loss = 0.047390

2018-03-08 19:43:30 start epoch 255/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:43:30 iter 1 loss = 0.039610
2018-03-08 19:43:35 iter 25 loss = 0.051189
2018-03-08 19:43:39 iter 50 loss = 0.069305
2018-03-08 19:43:44 iter 75 loss = 0.103551
2018-03-08 19:43:48 iter 100 loss = 0.039686
2018-03-08 19:43:53 iter 125 loss = 0.044627
2018-03-08 19:43:53 epoch 255/500 average_loss = 0.088002

2018-03-08 19:43:53 start epoch 256/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:43:53 iter 1 loss = 0.045157
2018-03-08 19:43:57 iter 25 loss = 0.081444
2018-03-08 19:44:02 iter 50 loss = 0.072783
2018-03-08 19:44:07 iter 75 loss = 0.074171
2018-03-08 19:44:11 iter 100 loss = 0.143444
2018-03-08 19:44:16 iter 125 loss = 0.251890
2018-03-08 19:44:16 epoch 256/500 average_loss = 0.139029

2018-03-08 19:44:16 start epoch 257/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:44:16 iter 1 loss = 0.265878
2018-03-08 19:44:20 iter 25 loss = 0.214135
2018-03-08 19:44:25 iter 50 loss = 0.297457
2018-03-08 19:44:29 iter 75 loss = 0.206541
2018-03-08 19:44:34 iter 100 loss = 0.341706
2018-03-08 19:44:38 iter 125 loss = 0.076321
2018-03-08 19:44:38 epoch 257/500 average_loss = 0.190232

2018-03-08 19:44:38 start epoch 258/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:44:39 iter 1 loss = 0.187792
2018-03-08 19:44:43 iter 25 loss = 0.112212
2018-03-08 19:44:48 iter 50 loss = 0.133747
2018-03-08 19:44:52 iter 75 loss = 0.209700
2018-03-08 19:44:57 iter 100 loss = 0.200139
2018-03-08 19:45:01 iter 125 loss = 0.109468
2018-03-08 19:45:01 epoch 258/500 average_loss = 0.154794

2018-03-08 19:45:01 start epoch 259/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:45:01 iter 1 loss = 0.115245
2018-03-08 19:45:06 iter 25 loss = 0.050355
2018-03-08 19:45:10 iter 50 loss = 0.077785
2018-03-08 19:45:15 iter 75 loss = 0.095124
2018-03-08 19:45:19 iter 100 loss = 0.051758
2018-03-08 19:45:24 iter 125 loss = 0.029967
2018-03-08 19:45:24 epoch 259/500 average_loss = 0.086446

2018-03-08 19:45:24 start epoch 260/500: learning_rate = 0.0002748779069440002 sequence_len = 28
2018-03-08 19:45:24 iter 1 loss = 0.068391
2018-03-08 19:45:29 iter 25 loss = 0.047915
2018-03-08 19:45:33 iter 50 loss = 0.047225
2018-03-08 19:45:38 iter 75 loss = 0.075925
2018-03-08 19:45:42 iter 100 loss = 0.041571
2018-03-08 19:45:47 iter 125 loss = 0.174968
2018-03-08 19:45:47 epoch 260/500 average_loss = 0.071596

2018-03-08 19:45:47 start epoch 261/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:45:47 iter 1 loss = 0.056777
2018-03-08 19:45:52 iter 25 loss = 0.055615
2018-03-08 19:45:56 iter 50 loss = 0.035985
2018-03-08 19:46:01 iter 75 loss = 0.028986
2018-03-08 19:46:05 iter 100 loss = 0.043894
2018-03-08 19:46:10 iter 125 loss = 0.060678
2018-03-08 19:46:10 epoch 261/500 average_loss = 0.047541

2018-03-08 19:46:10 start epoch 262/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:46:10 iter 1 loss = 0.029636
2018-03-08 19:46:14 iter 25 loss = 0.028022
2018-03-08 19:46:19 iter 50 loss = 0.021759
2018-03-08 19:46:23 iter 75 loss = 0.023852
2018-03-08 19:46:28 iter 100 loss = 0.050917
2018-03-08 19:46:32 iter 125 loss = 0.074026
2018-03-08 19:46:32 epoch 262/500 average_loss = 0.041033

2018-03-08 19:46:32 start epoch 263/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:46:33 iter 1 loss = 0.036436
2018-03-08 19:46:37 iter 25 loss = 0.046313
2018-03-08 19:46:42 iter 50 loss = 0.048042
2018-03-08 19:46:46 iter 75 loss = 0.028427
2018-03-08 19:46:51 iter 100 loss = 0.030828
2018-03-08 19:46:55 iter 125 loss = 0.106497
2018-03-08 19:46:55 epoch 263/500 average_loss = 0.045982

2018-03-08 19:46:55 start epoch 264/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:46:56 iter 1 loss = 0.031513
2018-03-08 19:47:00 iter 25 loss = 0.034941
2018-03-08 19:47:04 iter 50 loss = 0.041839
2018-03-08 19:47:09 iter 75 loss = 0.053479
2018-03-08 19:47:13 iter 100 loss = 0.048025
2018-03-08 19:47:18 iter 125 loss = 0.073928
2018-03-08 19:47:18 epoch 264/500 average_loss = 0.038212

2018-03-08 19:47:18 start epoch 265/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:47:18 iter 1 loss = 0.017801
2018-03-08 19:47:23 iter 25 loss = 0.031018
2018-03-08 19:47:27 iter 50 loss = 0.058662
2018-03-08 19:47:32 iter 75 loss = 0.040504
2018-03-08 19:47:36 iter 100 loss = 0.061371
2018-03-08 19:47:41 iter 125 loss = 0.044586
2018-03-08 19:47:41 epoch 265/500 average_loss = 0.041113

2018-03-08 19:47:41 start epoch 266/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:47:41 iter 1 loss = 0.038320
2018-03-08 19:47:45 iter 25 loss = 0.091498
2018-03-08 19:47:50 iter 50 loss = 0.027211
2018-03-08 19:47:54 iter 75 loss = 0.029127
2018-03-08 19:47:59 iter 100 loss = 0.024852
2018-03-08 19:48:03 iter 125 loss = 0.017453
2018-03-08 19:48:03 epoch 266/500 average_loss = 0.035028

2018-03-08 19:48:03 start epoch 267/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:48:04 iter 1 loss = 0.019949
2018-03-08 19:48:08 iter 25 loss = 0.022887
2018-03-08 19:48:13 iter 50 loss = 0.028169
2018-03-08 19:48:17 iter 75 loss = 0.026068
2018-03-08 19:48:22 iter 100 loss = 0.025905
2018-03-08 19:48:26 iter 125 loss = 0.032351
2018-03-08 19:48:26 epoch 267/500 average_loss = 0.032843

2018-03-08 19:48:26 start epoch 268/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:48:27 iter 1 loss = 0.022235
2018-03-08 19:48:31 iter 25 loss = 0.027587
2018-03-08 19:48:35 iter 50 loss = 0.034648
2018-03-08 19:48:40 iter 75 loss = 0.027495
2018-03-08 19:48:44 iter 100 loss = 0.030365
2018-03-08 19:48:49 iter 125 loss = 0.018463
2018-03-08 19:48:49 epoch 268/500 average_loss = 0.033616

2018-03-08 19:48:49 start epoch 269/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:48:49 iter 1 loss = 0.039296
2018-03-08 19:48:54 iter 25 loss = 0.017111
2018-03-08 19:48:58 iter 50 loss = 0.035949
2018-03-08 19:49:03 iter 75 loss = 0.021770
2018-03-08 19:49:07 iter 100 loss = 0.042152
2018-03-08 19:49:12 iter 125 loss = 0.035475
2018-03-08 19:49:12 epoch 269/500 average_loss = 0.027731

2018-03-08 19:49:12 start epoch 270/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:49:12 iter 1 loss = 0.020639
2018-03-08 19:49:16 iter 25 loss = 0.057738
2018-03-08 19:49:21 iter 50 loss = 0.046295
2018-03-08 19:49:25 iter 75 loss = 0.015836
2018-03-08 19:49:30 iter 100 loss = 0.019924
2018-03-08 19:49:34 iter 125 loss = 0.028621
2018-03-08 19:49:34 epoch 270/500 average_loss = 0.033174

2018-03-08 19:49:34 start epoch 271/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:49:35 iter 1 loss = 0.013164
2018-03-08 19:49:39 iter 25 loss = 0.040144
2018-03-08 19:49:43 iter 50 loss = 0.034054
2018-03-08 19:49:48 iter 75 loss = 0.021716
2018-03-08 19:49:52 iter 100 loss = 0.027550
2018-03-08 19:49:57 iter 125 loss = 0.038320
2018-03-08 19:49:57 epoch 271/500 average_loss = 0.033471

2018-03-08 19:49:57 start epoch 272/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:49:57 iter 1 loss = 0.082813
2018-03-08 19:50:02 iter 25 loss = 0.026343
2018-03-08 19:50:06 iter 50 loss = 0.032973
2018-03-08 19:50:11 iter 75 loss = 0.040520
2018-03-08 19:50:15 iter 100 loss = 0.040885
2018-03-08 19:50:20 iter 125 loss = 0.027534
2018-03-08 19:50:20 epoch 272/500 average_loss = 0.041347

2018-03-08 19:50:20 start epoch 273/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:50:20 iter 1 loss = 0.037977
2018-03-08 19:50:24 iter 25 loss = 0.012341
2018-03-08 19:50:29 iter 50 loss = 0.034761
2018-03-08 19:50:33 iter 75 loss = 0.059301
2018-03-08 19:50:38 iter 100 loss = 0.024041
2018-03-08 19:50:42 iter 125 loss = 0.018977
2018-03-08 19:50:42 epoch 273/500 average_loss = 0.034083

2018-03-08 19:50:42 start epoch 274/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:50:43 iter 1 loss = 0.054379
2018-03-08 19:50:47 iter 25 loss = 0.038799
2018-03-08 19:50:51 iter 50 loss = 0.027891
2018-03-08 19:50:56 iter 75 loss = 0.043802
2018-03-08 19:51:01 iter 100 loss = 0.023387
2018-03-08 19:51:05 iter 125 loss = 0.020297
2018-03-08 19:51:05 epoch 274/500 average_loss = 0.025111

2018-03-08 19:51:05 start epoch 275/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:51:05 iter 1 loss = 0.016225
2018-03-08 19:51:10 iter 25 loss = 0.025045
2018-03-08 19:51:14 iter 50 loss = 0.016285
2018-03-08 19:51:19 iter 75 loss = 0.027120
2018-03-08 19:51:23 iter 100 loss = 0.037162
2018-03-08 19:51:28 iter 125 loss = 0.196588
2018-03-08 19:51:28 epoch 275/500 average_loss = 0.026586

2018-03-08 19:51:28 start epoch 276/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:51:28 iter 1 loss = 0.040843
2018-03-08 19:51:33 iter 25 loss = 0.033732
2018-03-08 19:51:37 iter 50 loss = 0.022323
2018-03-08 19:51:42 iter 75 loss = 0.034014
2018-03-08 19:51:46 iter 100 loss = 0.035158
2018-03-08 19:51:51 iter 125 loss = 0.025370
2018-03-08 19:51:51 epoch 276/500 average_loss = 0.034182

2018-03-08 19:51:51 start epoch 277/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:51:51 iter 1 loss = 0.028462
2018-03-08 19:51:55 iter 25 loss = 0.080196
2018-03-08 19:52:00 iter 50 loss = 0.041088
2018-03-08 19:52:04 iter 75 loss = 0.052275
2018-03-08 19:52:09 iter 100 loss = 0.064155
2018-03-08 19:52:14 iter 125 loss = 0.035232
2018-03-08 19:52:14 epoch 277/500 average_loss = 0.043875

2018-03-08 19:52:14 start epoch 278/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:52:14 iter 1 loss = 0.022228
2018-03-08 19:52:18 iter 25 loss = 0.030344
2018-03-08 19:52:23 iter 50 loss = 0.019178
2018-03-08 19:52:27 iter 75 loss = 0.027667
2018-03-08 19:52:32 iter 100 loss = 0.011484
2018-03-08 19:52:36 iter 125 loss = 0.022805
2018-03-08 19:52:36 epoch 278/500 average_loss = 0.024438

2018-03-08 19:52:36 start epoch 279/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:52:37 iter 1 loss = 0.016725
2018-03-08 19:52:41 iter 25 loss = 0.014528
2018-03-08 19:52:46 iter 50 loss = 0.014973
2018-03-08 19:52:50 iter 75 loss = 0.033102
2018-03-08 19:52:55 iter 100 loss = 0.024812
2018-03-08 19:52:59 iter 125 loss = 0.029374
2018-03-08 19:52:59 epoch 279/500 average_loss = 0.024797

2018-03-08 19:52:59 start epoch 280/500: learning_rate = 0.00021990232555520016 sequence_len = 28
2018-03-08 19:53:00 iter 1 loss = 0.055478
2018-03-08 19:53:04 iter 25 loss = 0.020231
2018-03-08 19:53:09 iter 50 loss = 0.026329
2018-03-08 19:53:13 iter 75 loss = 0.020895
2018-03-08 19:53:18 iter 100 loss = 0.016288
2018-03-08 19:53:22 iter 125 loss = 0.049686
2018-03-08 19:53:22 epoch 280/500 average_loss = 0.024184

2018-03-08 19:53:22 start epoch 281/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:53:23 iter 1 loss = 0.012881
2018-03-08 19:53:27 iter 25 loss = 0.034835
2018-03-08 19:53:32 iter 50 loss = 0.009601
2018-03-08 19:53:36 iter 75 loss = 0.026382
2018-03-08 19:53:41 iter 100 loss = 0.010633
2018-03-08 19:53:45 iter 125 loss = 0.020552
2018-03-08 19:53:45 epoch 281/500 average_loss = 0.018131

2018-03-08 19:53:45 start epoch 282/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:53:45 iter 1 loss = 0.011975
2018-03-08 19:53:50 iter 25 loss = 0.021591
2018-03-08 19:53:54 iter 50 loss = 0.011311
2018-03-08 19:53:59 iter 75 loss = 0.022476
2018-03-08 19:54:03 iter 100 loss = 0.012893
2018-03-08 19:54:08 iter 125 loss = 0.012990
2018-03-08 19:54:08 epoch 282/500 average_loss = 0.022657

2018-03-08 19:54:08 start epoch 283/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:54:08 iter 1 loss = 0.016817
2018-03-08 19:54:13 iter 25 loss = 0.006812
2018-03-08 19:54:17 iter 50 loss = 0.050902
2018-03-08 19:54:22 iter 75 loss = 0.010789
2018-03-08 19:54:26 iter 100 loss = 0.013919
2018-03-08 19:54:31 iter 125 loss = 0.010987
2018-03-08 19:54:31 epoch 283/500 average_loss = 0.019651

2018-03-08 19:54:31 start epoch 284/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:54:31 iter 1 loss = 0.016358
2018-03-08 19:54:35 iter 25 loss = 0.013543
2018-03-08 19:54:40 iter 50 loss = 0.014588
2018-03-08 19:54:44 iter 75 loss = 0.011050
2018-03-08 19:54:49 iter 100 loss = 0.016776
2018-03-08 19:54:54 iter 125 loss = 0.027149
2018-03-08 19:54:54 epoch 284/500 average_loss = 0.023353

2018-03-08 19:54:54 start epoch 285/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:54:54 iter 1 loss = 0.040991
2018-03-08 19:54:58 iter 25 loss = 0.046016
2018-03-08 19:55:03 iter 50 loss = 0.042979
2018-03-08 19:55:07 iter 75 loss = 0.029438
2018-03-08 19:55:12 iter 100 loss = 0.033454
2018-03-08 19:55:16 iter 125 loss = 0.107058
2018-03-08 19:55:16 epoch 285/500 average_loss = 0.065385

2018-03-08 19:55:16 start epoch 286/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:55:17 iter 1 loss = 0.036226
2018-03-08 19:55:21 iter 25 loss = 0.038591
2018-03-08 19:55:26 iter 50 loss = 0.049574
2018-03-08 19:55:30 iter 75 loss = 0.045248
2018-03-08 19:55:35 iter 100 loss = 0.019912
2018-03-08 19:55:39 iter 125 loss = 0.034089
2018-03-08 19:55:39 epoch 286/500 average_loss = 0.043706

2018-03-08 19:55:39 start epoch 287/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:55:39 iter 1 loss = 0.031908
2018-03-08 19:55:44 iter 25 loss = 0.073091
2018-03-08 19:55:48 iter 50 loss = 0.019789
2018-03-08 19:55:53 iter 75 loss = 0.134576
2018-03-08 19:55:57 iter 100 loss = 0.251622
2018-03-08 19:56:02 iter 125 loss = 0.029401
2018-03-08 19:56:02 epoch 287/500 average_loss = 0.053356

2018-03-08 19:56:02 start epoch 288/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:56:02 iter 1 loss = 0.086342
2018-03-08 19:56:06 iter 25 loss = 0.048494
2018-03-08 19:56:11 iter 50 loss = 0.024564
2018-03-08 19:56:15 iter 75 loss = 0.038731
2018-03-08 19:56:20 iter 100 loss = 0.039912
2018-03-08 19:56:24 iter 125 loss = 0.077848
2018-03-08 19:56:24 epoch 288/500 average_loss = 0.069352

2018-03-08 19:56:24 start epoch 289/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:56:25 iter 1 loss = 0.039710
2018-03-08 19:56:29 iter 25 loss = 0.018809
2018-03-08 19:56:33 iter 50 loss = 0.050816
2018-03-08 19:56:38 iter 75 loss = 0.025859
2018-03-08 19:56:42 iter 100 loss = 0.036174
2018-03-08 19:56:47 iter 125 loss = 0.021532
2018-03-08 19:56:47 epoch 289/500 average_loss = 0.041851

2018-03-08 19:56:47 start epoch 290/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:56:47 iter 1 loss = 0.019636
2018-03-08 19:56:52 iter 25 loss = 0.019746
2018-03-08 19:56:56 iter 50 loss = 0.027828
2018-03-08 19:57:01 iter 75 loss = 0.013421
2018-03-08 19:57:05 iter 100 loss = 0.012738
2018-03-08 19:57:10 iter 125 loss = 0.010058
2018-03-08 19:57:10 epoch 290/500 average_loss = 0.029861

2018-03-08 19:57:10 start epoch 291/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:57:10 iter 1 loss = 0.024109
2018-03-08 19:57:14 iter 25 loss = 0.013577
2018-03-08 19:57:19 iter 50 loss = 0.052247
2018-03-08 19:57:23 iter 75 loss = 0.022076
2018-03-08 19:57:28 iter 100 loss = 0.035808
2018-03-08 19:57:32 iter 125 loss = 0.021078
2018-03-08 19:57:32 epoch 291/500 average_loss = 0.050789

2018-03-08 19:57:32 start epoch 292/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:57:33 iter 1 loss = 0.022805
2018-03-08 19:57:37 iter 25 loss = 0.027255
2018-03-08 19:57:42 iter 50 loss = 0.027184
2018-03-08 19:57:46 iter 75 loss = 0.051399
2018-03-08 19:57:51 iter 100 loss = 0.026160
2018-03-08 19:57:55 iter 125 loss = 0.072103
2018-03-08 19:57:55 epoch 292/500 average_loss = 0.026457

2018-03-08 19:57:55 start epoch 293/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:57:55 iter 1 loss = 0.017648
2018-03-08 19:58:00 iter 25 loss = 0.021512
2018-03-08 19:58:04 iter 50 loss = 0.011022
2018-03-08 19:58:09 iter 75 loss = 0.017014
2018-03-08 19:58:13 iter 100 loss = 0.018354
2018-03-08 19:58:18 iter 125 loss = 0.031142
2018-03-08 19:58:18 epoch 293/500 average_loss = 0.017403

2018-03-08 19:58:18 start epoch 294/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:58:18 iter 1 loss = 0.017834
2018-03-08 19:58:22 iter 25 loss = 0.017218
2018-03-08 19:58:27 iter 50 loss = 0.057931
2018-03-08 19:58:32 iter 75 loss = 0.021942
2018-03-08 19:58:36 iter 100 loss = 0.011090
2018-03-08 19:58:41 iter 125 loss = 0.030688
2018-03-08 19:58:41 epoch 294/500 average_loss = 0.017837

2018-03-08 19:58:41 start epoch 295/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:58:41 iter 1 loss = 0.020189
2018-03-08 19:58:45 iter 25 loss = 0.028897
2018-03-08 19:58:50 iter 50 loss = 0.045979
2018-03-08 19:58:54 iter 75 loss = 0.010197
2018-03-08 19:58:59 iter 100 loss = 0.018213
2018-03-08 19:59:03 iter 125 loss = 0.017357
2018-03-08 19:59:03 epoch 295/500 average_loss = 0.016896

2018-03-08 19:59:03 start epoch 296/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:59:04 iter 1 loss = 0.012293
2018-03-08 19:59:08 iter 25 loss = 0.011786
2018-03-08 19:59:13 iter 50 loss = 0.023475
2018-03-08 19:59:17 iter 75 loss = 0.012162
2018-03-08 19:59:22 iter 100 loss = 0.031584
2018-03-08 19:59:26 iter 125 loss = 0.010737
2018-03-08 19:59:26 epoch 296/500 average_loss = 0.016996

2018-03-08 19:59:26 start epoch 297/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:59:27 iter 1 loss = 0.009467
2018-03-08 19:59:31 iter 25 loss = 0.011425
2018-03-08 19:59:35 iter 50 loss = 0.016375
2018-03-08 19:59:40 iter 75 loss = 0.011410
2018-03-08 19:59:44 iter 100 loss = 0.012534
2018-03-08 19:59:49 iter 125 loss = 0.014391
2018-03-08 19:59:49 epoch 297/500 average_loss = 0.015311

2018-03-08 19:59:49 start epoch 298/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 19:59:49 iter 1 loss = 0.006665
2018-03-08 19:59:54 iter 25 loss = 0.009954
2018-03-08 19:59:58 iter 50 loss = 0.008649
2018-03-08 20:00:03 iter 75 loss = 0.019031
2018-03-08 20:00:07 iter 100 loss = 0.005447
2018-03-08 20:00:12 iter 125 loss = 0.014409
2018-03-08 20:00:12 epoch 298/500 average_loss = 0.012960

2018-03-08 20:00:12 start epoch 299/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 20:00:12 iter 1 loss = 0.012844
2018-03-08 20:00:16 iter 25 loss = 0.008791
2018-03-08 20:00:21 iter 50 loss = 0.009543
2018-03-08 20:00:25 iter 75 loss = 0.023515
2018-03-08 20:00:30 iter 100 loss = 0.008973
2018-03-08 20:00:34 iter 125 loss = 0.009468
2018-03-08 20:00:34 epoch 299/500 average_loss = 0.013774

2018-03-08 20:00:34 start epoch 300/500: learning_rate = 0.00017592186044416015 sequence_len = 28
2018-03-08 20:00:35 iter 1 loss = 0.009793
2018-03-08 20:00:39 iter 25 loss = 0.012806
2018-03-08 20:00:44 iter 50 loss = 0.010834
2018-03-08 20:00:48 iter 75 loss = 0.010220
2018-03-08 20:00:53 iter 100 loss = 0.009824
2018-03-08 20:00:57 iter 125 loss = 0.009095
2018-03-08 20:00:57 epoch 300/500 average_loss = 0.016721

2018-03-08 20:00:57 start epoch 301/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:00:57 iter 1 loss = 0.007619
2018-03-08 20:01:02 iter 25 loss = 0.007599
2018-03-08 20:01:06 iter 50 loss = 0.007145
2018-03-08 20:01:11 iter 75 loss = 0.017179
2018-03-08 20:01:15 iter 100 loss = 0.006842
2018-03-08 20:01:20 iter 125 loss = 0.012076
2018-03-08 20:01:20 epoch 301/500 average_loss = 0.013136

2018-03-08 20:01:20 start epoch 302/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:01:20 iter 1 loss = 0.017689
2018-03-08 20:01:25 iter 25 loss = 0.009036
2018-03-08 20:01:29 iter 50 loss = 0.136788
2018-03-08 20:01:34 iter 75 loss = 0.013135
2018-03-08 20:01:38 iter 100 loss = 0.015477
2018-03-08 20:01:43 iter 125 loss = 0.008020
2018-03-08 20:01:43 epoch 302/500 average_loss = 0.013904

2018-03-08 20:01:43 start epoch 303/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:01:43 iter 1 loss = 0.007265
2018-03-08 20:01:47 iter 25 loss = 0.007870
2018-03-08 20:01:52 iter 50 loss = 0.007181
2018-03-08 20:01:56 iter 75 loss = 0.009787
2018-03-08 20:02:01 iter 100 loss = 0.007669
2018-03-08 20:02:05 iter 125 loss = 0.010285
2018-03-08 20:02:05 epoch 303/500 average_loss = 0.014015

2018-03-08 20:02:05 start epoch 304/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:02:06 iter 1 loss = 0.010160
2018-03-08 20:02:10 iter 25 loss = 0.008744
2018-03-08 20:02:14 iter 50 loss = 0.009566
2018-03-08 20:02:19 iter 75 loss = 0.010694
2018-03-08 20:02:23 iter 100 loss = 0.008318
2018-03-08 20:02:28 iter 125 loss = 0.011803
2018-03-08 20:02:28 epoch 304/500 average_loss = 0.012875

2018-03-08 20:02:28 start epoch 305/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:02:28 iter 1 loss = 0.009480
2018-03-08 20:02:33 iter 25 loss = 0.010823
2018-03-08 20:02:37 iter 50 loss = 0.006679
2018-03-08 20:02:42 iter 75 loss = 0.007833
2018-03-08 20:02:46 iter 100 loss = 0.005542
2018-03-08 20:02:51 iter 125 loss = 0.007930
2018-03-08 20:02:51 epoch 305/500 average_loss = 0.011520

2018-03-08 20:02:51 start epoch 306/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:02:51 iter 1 loss = 0.010180
2018-03-08 20:02:55 iter 25 loss = 0.006987
2018-03-08 20:03:00 iter 50 loss = 0.009221
2018-03-08 20:03:04 iter 75 loss = 0.008337
2018-03-08 20:03:09 iter 100 loss = 0.008952
2018-03-08 20:03:13 iter 125 loss = 0.007189
2018-03-08 20:03:13 epoch 306/500 average_loss = 0.010887

2018-03-08 20:03:13 start epoch 307/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:03:14 iter 1 loss = 0.009675
2018-03-08 20:03:18 iter 25 loss = 0.009236
2018-03-08 20:03:23 iter 50 loss = 0.016488
2018-03-08 20:03:27 iter 75 loss = 0.008311
2018-03-08 20:03:32 iter 100 loss = 0.006618
2018-03-08 20:03:36 iter 125 loss = 0.016103
2018-03-08 20:03:36 epoch 307/500 average_loss = 0.014216

2018-03-08 20:03:36 start epoch 308/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:03:37 iter 1 loss = 0.010676
2018-03-08 20:03:41 iter 25 loss = 0.009734
2018-03-08 20:03:45 iter 50 loss = 0.006497
2018-03-08 20:03:50 iter 75 loss = 0.007811
2018-03-08 20:03:54 iter 100 loss = 0.018744
2018-03-08 20:03:59 iter 125 loss = 0.005782
2018-03-08 20:03:59 epoch 308/500 average_loss = 0.012181

2018-03-08 20:03:59 start epoch 309/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:03:59 iter 1 loss = 0.009978
2018-03-08 20:04:04 iter 25 loss = 0.012718
2018-03-08 20:04:08 iter 50 loss = 0.027609
2018-03-08 20:04:13 iter 75 loss = 0.006915
2018-03-08 20:04:17 iter 100 loss = 0.009616
2018-03-08 20:04:22 iter 125 loss = 0.009453
2018-03-08 20:04:22 epoch 309/500 average_loss = 0.010146

2018-03-08 20:04:22 start epoch 310/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:04:22 iter 1 loss = 0.008140
2018-03-08 20:04:26 iter 25 loss = 0.006651
2018-03-08 20:04:31 iter 50 loss = 0.006428
2018-03-08 20:04:35 iter 75 loss = 0.011505
2018-03-08 20:04:40 iter 100 loss = 0.012103
2018-03-08 20:04:44 iter 125 loss = 0.005896
2018-03-08 20:04:44 epoch 310/500 average_loss = 0.009494

2018-03-08 20:04:44 start epoch 311/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:04:45 iter 1 loss = 0.006744
2018-03-08 20:04:49 iter 25 loss = 0.006316
2018-03-08 20:04:54 iter 50 loss = 0.008807
2018-03-08 20:04:58 iter 75 loss = 0.004566
2018-03-08 20:05:03 iter 100 loss = 0.007983
2018-03-08 20:05:07 iter 125 loss = 0.009144
2018-03-08 20:05:07 epoch 311/500 average_loss = 0.007869

2018-03-08 20:05:07 start epoch 312/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:05:08 iter 1 loss = 0.022698
2018-03-08 20:05:12 iter 25 loss = 0.005447
2018-03-08 20:05:16 iter 50 loss = 0.014541
2018-03-08 20:05:21 iter 75 loss = 0.005369
2018-03-08 20:05:25 iter 100 loss = 0.004285
2018-03-08 20:05:30 iter 125 loss = 0.005831
2018-03-08 20:05:30 epoch 312/500 average_loss = 0.008449

2018-03-08 20:05:30 start epoch 313/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:05:30 iter 1 loss = 0.008956
2018-03-08 20:05:35 iter 25 loss = 0.009347
2018-03-08 20:05:39 iter 50 loss = 0.015785
2018-03-08 20:05:44 iter 75 loss = 0.005785
2018-03-08 20:05:48 iter 100 loss = 0.009607
2018-03-08 20:05:53 iter 125 loss = 0.006148
2018-03-08 20:05:53 epoch 313/500 average_loss = 0.011748

2018-03-08 20:05:53 start epoch 314/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:05:53 iter 1 loss = 0.011671
2018-03-08 20:05:58 iter 25 loss = 0.328471
2018-03-08 20:06:02 iter 50 loss = 0.021535
2018-03-08 20:06:07 iter 75 loss = 0.056941
2018-03-08 20:06:11 iter 100 loss = 0.042500
2018-03-08 20:06:16 iter 125 loss = 0.041648
2018-03-08 20:06:16 epoch 314/500 average_loss = 0.061924

2018-03-08 20:06:16 start epoch 315/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:06:16 iter 1 loss = 0.015977
2018-03-08 20:06:20 iter 25 loss = 0.020658
2018-03-08 20:06:25 iter 50 loss = 0.013536
2018-03-08 20:06:29 iter 75 loss = 0.010431
2018-03-08 20:06:34 iter 100 loss = 0.086350
2018-03-08 20:06:38 iter 125 loss = 0.022189
2018-03-08 20:06:38 epoch 315/500 average_loss = 0.025222

2018-03-08 20:06:38 start epoch 316/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:06:39 iter 1 loss = 0.012274
2018-03-08 20:06:43 iter 25 loss = 0.026703
2018-03-08 20:06:47 iter 50 loss = 0.035508
2018-03-08 20:06:52 iter 75 loss = 0.011883
2018-03-08 20:06:56 iter 100 loss = 0.026978
2018-03-08 20:07:01 iter 125 loss = 0.031441
2018-03-08 20:07:01 epoch 316/500 average_loss = 0.017978

2018-03-08 20:07:01 start epoch 317/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:07:01 iter 1 loss = 0.010177
2018-03-08 20:07:06 iter 25 loss = 0.009668
2018-03-08 20:07:10 iter 50 loss = 0.008851
2018-03-08 20:07:15 iter 75 loss = 0.009172
2018-03-08 20:07:19 iter 100 loss = 0.009018
2018-03-08 20:07:24 iter 125 loss = 0.007303
2018-03-08 20:07:24 epoch 317/500 average_loss = 0.015182

2018-03-08 20:07:24 start epoch 318/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:07:24 iter 1 loss = 0.008409
2018-03-08 20:07:28 iter 25 loss = 0.017448
2018-03-08 20:07:33 iter 50 loss = 0.009205
2018-03-08 20:07:37 iter 75 loss = 0.010658
2018-03-08 20:07:42 iter 100 loss = 0.010372
2018-03-08 20:07:46 iter 125 loss = 0.007788
2018-03-08 20:07:46 epoch 318/500 average_loss = 0.014581

2018-03-08 20:07:46 start epoch 319/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:07:47 iter 1 loss = 0.010820
2018-03-08 20:07:51 iter 25 loss = 0.009450
2018-03-08 20:07:55 iter 50 loss = 0.013849
2018-03-08 20:08:00 iter 75 loss = 0.015951
2018-03-08 20:08:04 iter 100 loss = 0.020073
2018-03-08 20:08:09 iter 125 loss = 0.013028
2018-03-08 20:08:09 epoch 319/500 average_loss = 0.016232

2018-03-08 20:08:09 start epoch 320/500: learning_rate = 0.00014073748835532812 sequence_len = 28
2018-03-08 20:08:09 iter 1 loss = 0.021648
2018-03-08 20:08:14 iter 25 loss = 0.008213
2018-03-08 20:08:18 iter 50 loss = 0.022285
2018-03-08 20:08:23 iter 75 loss = 0.010401
2018-03-08 20:08:27 iter 100 loss = 0.006457
2018-03-08 20:08:31 iter 125 loss = 0.018383
2018-03-08 20:08:31 epoch 320/500 average_loss = 0.013297

2018-03-08 20:08:31 start epoch 321/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:08:32 iter 1 loss = 0.020044
2018-03-08 20:08:36 iter 25 loss = 0.010609
2018-03-08 20:08:41 iter 50 loss = 0.005200
2018-03-08 20:08:45 iter 75 loss = 0.023195
2018-03-08 20:08:50 iter 100 loss = 0.006039
2018-03-08 20:08:54 iter 125 loss = 0.005935
2018-03-08 20:08:54 epoch 321/500 average_loss = 0.010259

2018-03-08 20:08:54 start epoch 322/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:08:54 iter 1 loss = 0.006221
2018-03-08 20:08:59 iter 25 loss = 0.034382
2018-03-08 20:09:03 iter 50 loss = 0.015513
2018-03-08 20:09:08 iter 75 loss = 0.010959
2018-03-08 20:09:12 iter 100 loss = 0.006556
2018-03-08 20:09:17 iter 125 loss = 0.006388
2018-03-08 20:09:17 epoch 322/500 average_loss = 0.009032

2018-03-08 20:09:17 start epoch 323/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:09:17 iter 1 loss = 0.005359
2018-03-08 20:09:21 iter 25 loss = 0.008798
2018-03-08 20:09:26 iter 50 loss = 0.004585
2018-03-08 20:09:30 iter 75 loss = 0.005361
2018-03-08 20:09:35 iter 100 loss = 0.013825
2018-03-08 20:09:39 iter 125 loss = 0.003836
2018-03-08 20:09:39 epoch 323/500 average_loss = 0.006955

2018-03-08 20:09:39 start epoch 324/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:09:40 iter 1 loss = 0.004451
2018-03-08 20:09:44 iter 25 loss = 0.004021
2018-03-08 20:09:48 iter 50 loss = 0.009524
2018-03-08 20:09:53 iter 75 loss = 0.014601
2018-03-08 20:09:57 iter 100 loss = 0.007636
2018-03-08 20:10:02 iter 125 loss = 0.005088
2018-03-08 20:10:02 epoch 324/500 average_loss = 0.008171

2018-03-08 20:10:02 start epoch 325/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:10:02 iter 1 loss = 0.005331
2018-03-08 20:10:07 iter 25 loss = 0.004194
2018-03-08 20:10:11 iter 50 loss = 0.005178
2018-03-08 20:10:16 iter 75 loss = 0.004979
2018-03-08 20:10:20 iter 100 loss = 0.007160
2018-03-08 20:10:25 iter 125 loss = 0.019101
2018-03-08 20:10:25 epoch 325/500 average_loss = 0.007443

2018-03-08 20:10:25 start epoch 326/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:10:25 iter 1 loss = 0.004961
2018-03-08 20:10:29 iter 25 loss = 0.012598
2018-03-08 20:10:34 iter 50 loss = 0.012174
2018-03-08 20:10:38 iter 75 loss = 0.003811
2018-03-08 20:10:43 iter 100 loss = 0.006851
2018-03-08 20:10:47 iter 125 loss = 0.005992
2018-03-08 20:10:47 epoch 326/500 average_loss = 0.006823

2018-03-08 20:10:47 start epoch 327/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:10:48 iter 1 loss = 0.006330
2018-03-08 20:10:52 iter 25 loss = 0.004260
2018-03-08 20:10:57 iter 50 loss = 0.013155
2018-03-08 20:11:01 iter 75 loss = 0.002946
2018-03-08 20:11:06 iter 100 loss = 0.034775
2018-03-08 20:11:10 iter 125 loss = 0.004620
2018-03-08 20:11:10 epoch 327/500 average_loss = 0.008190

2018-03-08 20:11:10 start epoch 328/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:11:10 iter 1 loss = 0.005268
2018-03-08 20:11:15 iter 25 loss = 0.006129
2018-03-08 20:11:19 iter 50 loss = 0.004516
2018-03-08 20:11:24 iter 75 loss = 0.004073
2018-03-08 20:11:28 iter 100 loss = 0.007543
2018-03-08 20:11:33 iter 125 loss = 0.004636
2018-03-08 20:11:33 epoch 328/500 average_loss = 0.010633

2018-03-08 20:11:33 start epoch 329/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:11:33 iter 1 loss = 0.013977
2018-03-08 20:11:38 iter 25 loss = 0.005290
2018-03-08 20:11:42 iter 50 loss = 0.004825
2018-03-08 20:11:47 iter 75 loss = 0.005166
2018-03-08 20:11:51 iter 100 loss = 0.013037
2018-03-08 20:11:56 iter 125 loss = 0.005930
2018-03-08 20:11:56 epoch 329/500 average_loss = 0.008788

2018-03-08 20:11:56 start epoch 330/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:11:56 iter 1 loss = 0.011121
2018-03-08 20:12:00 iter 25 loss = 0.009854
2018-03-08 20:12:05 iter 50 loss = 0.023823
2018-03-08 20:12:09 iter 75 loss = 0.005254
2018-03-08 20:12:14 iter 100 loss = 0.011858
2018-03-08 20:12:18 iter 125 loss = 0.022441
2018-03-08 20:12:18 epoch 330/500 average_loss = 0.010498

2018-03-08 20:12:18 start epoch 331/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:12:19 iter 1 loss = 0.004799
2018-03-08 20:12:23 iter 25 loss = 0.007161
2018-03-08 20:12:27 iter 50 loss = 0.004873
2018-03-08 20:12:32 iter 75 loss = 0.019825
2018-03-08 20:12:36 iter 100 loss = 0.004413
2018-03-08 20:12:41 iter 125 loss = 0.005960
2018-03-08 20:12:41 epoch 331/500 average_loss = 0.007197

2018-03-08 20:12:41 start epoch 332/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:12:41 iter 1 loss = 0.005689
2018-03-08 20:12:46 iter 25 loss = 0.009475
2018-03-08 20:12:50 iter 50 loss = 0.006500
2018-03-08 20:12:55 iter 75 loss = 0.004901
2018-03-08 20:12:59 iter 100 loss = 0.003596
2018-03-08 20:13:04 iter 125 loss = 0.005661
2018-03-08 20:13:04 epoch 332/500 average_loss = 0.005882

2018-03-08 20:13:04 start epoch 333/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:13:04 iter 1 loss = 0.003044
2018-03-08 20:13:08 iter 25 loss = 0.006088
2018-03-08 20:13:13 iter 50 loss = 0.037467
2018-03-08 20:13:17 iter 75 loss = 0.004016
2018-03-08 20:13:22 iter 100 loss = 0.006526
2018-03-08 20:13:26 iter 125 loss = 0.004521
2018-03-08 20:13:26 epoch 333/500 average_loss = 0.006448

2018-03-08 20:13:26 start epoch 334/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:13:27 iter 1 loss = 0.006500
2018-03-08 20:13:31 iter 25 loss = 0.006601
2018-03-08 20:13:36 iter 50 loss = 0.005868
2018-03-08 20:13:40 iter 75 loss = 0.008147
2018-03-08 20:13:45 iter 100 loss = 0.006668
2018-03-08 20:13:49 iter 125 loss = 0.021702
2018-03-08 20:13:49 epoch 334/500 average_loss = 0.010158

2018-03-08 20:13:49 start epoch 335/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:13:49 iter 1 loss = 0.028030
2018-03-08 20:13:54 iter 25 loss = 0.008470
2018-03-08 20:13:58 iter 50 loss = 0.004046
2018-03-08 20:14:03 iter 75 loss = 0.006241
2018-03-08 20:14:07 iter 100 loss = 0.025823
2018-03-08 20:14:12 iter 125 loss = 0.016387
2018-03-08 20:14:12 epoch 335/500 average_loss = 0.014361

2018-03-08 20:14:12 start epoch 336/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:14:12 iter 1 loss = 0.006760
2018-03-08 20:14:16 iter 25 loss = 0.004369
2018-03-08 20:14:21 iter 50 loss = 0.008522
2018-03-08 20:14:25 iter 75 loss = 0.006370
2018-03-08 20:14:30 iter 100 loss = 0.043633
2018-03-08 20:14:34 iter 125 loss = 0.008483
2018-03-08 20:14:34 epoch 336/500 average_loss = 0.010303

2018-03-08 20:14:34 start epoch 337/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:14:35 iter 1 loss = 0.004592
2018-03-08 20:14:39 iter 25 loss = 0.006817
2018-03-08 20:14:44 iter 50 loss = 0.004564
2018-03-08 20:14:48 iter 75 loss = 0.003367
2018-03-08 20:14:53 iter 100 loss = 0.012034
2018-03-08 20:14:57 iter 125 loss = 0.003983
2018-03-08 20:14:57 epoch 337/500 average_loss = 0.007018

2018-03-08 20:14:57 start epoch 338/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:14:58 iter 1 loss = 0.007934
2018-03-08 20:15:02 iter 25 loss = 0.006184
2018-03-08 20:15:06 iter 50 loss = 0.004200
2018-03-08 20:15:11 iter 75 loss = 0.003448
2018-03-08 20:15:15 iter 100 loss = 0.003011
2018-03-08 20:15:20 iter 125 loss = 0.008888
2018-03-08 20:15:20 epoch 338/500 average_loss = 0.006277

2018-03-08 20:15:20 start epoch 339/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:15:20 iter 1 loss = 0.003955
2018-03-08 20:15:25 iter 25 loss = 0.004214
2018-03-08 20:15:29 iter 50 loss = 0.012764
2018-03-08 20:15:34 iter 75 loss = 0.006991
2018-03-08 20:15:38 iter 100 loss = 0.005150
2018-03-08 20:15:43 iter 125 loss = 0.006538
2018-03-08 20:15:43 epoch 339/500 average_loss = 0.006957

2018-03-08 20:15:43 start epoch 340/500: learning_rate = 0.00011258999068426249 sequence_len = 28
2018-03-08 20:15:43 iter 1 loss = 0.005340
2018-03-08 20:15:47 iter 25 loss = 0.023268
2018-03-08 20:15:52 iter 50 loss = 0.004938
2018-03-08 20:15:56 iter 75 loss = 0.003315
2018-03-08 20:16:01 iter 100 loss = 0.007381
2018-03-08 20:16:05 iter 125 loss = 0.005038
2018-03-08 20:16:05 epoch 340/500 average_loss = 0.006818

2018-03-08 20:16:05 start epoch 341/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:16:06 iter 1 loss = 0.003234
2018-03-08 20:16:10 iter 25 loss = 0.002817
2018-03-08 20:16:14 iter 50 loss = 0.003928
2018-03-08 20:16:19 iter 75 loss = 0.003914
2018-03-08 20:16:24 iter 100 loss = 0.004163
2018-03-08 20:16:28 iter 125 loss = 0.005053
2018-03-08 20:16:28 epoch 341/500 average_loss = 0.005463

2018-03-08 20:16:28 start epoch 342/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:16:28 iter 1 loss = 0.007320
2018-03-08 20:16:33 iter 25 loss = 0.014212
2018-03-08 20:16:37 iter 50 loss = 0.008516
2018-03-08 20:16:42 iter 75 loss = 0.003286
2018-03-08 20:16:46 iter 100 loss = 0.004428
2018-03-08 20:16:51 iter 125 loss = 0.004716
2018-03-08 20:16:51 epoch 342/500 average_loss = 0.004730

2018-03-08 20:16:51 start epoch 343/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:16:51 iter 1 loss = 0.002701
2018-03-08 20:16:55 iter 25 loss = 0.002468
2018-03-08 20:17:00 iter 50 loss = 0.003524
2018-03-08 20:17:04 iter 75 loss = 0.002953
2018-03-08 20:17:09 iter 100 loss = 0.002967
2018-03-08 20:17:13 iter 125 loss = 0.003149
2018-03-08 20:17:13 epoch 343/500 average_loss = 0.004755

2018-03-08 20:17:13 start epoch 344/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:17:14 iter 1 loss = 0.005537
2018-03-08 20:17:18 iter 25 loss = 0.004193
2018-03-08 20:17:23 iter 50 loss = 0.004703
2018-03-08 20:17:27 iter 75 loss = 0.003829
2018-03-08 20:17:32 iter 100 loss = 0.003878
2018-03-08 20:17:36 iter 125 loss = 0.003255
2018-03-08 20:17:36 epoch 344/500 average_loss = 0.004719

2018-03-08 20:17:36 start epoch 345/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:17:36 iter 1 loss = 0.003061
2018-03-08 20:17:41 iter 25 loss = 0.002607
2018-03-08 20:17:45 iter 50 loss = 0.003259
2018-03-08 20:17:50 iter 75 loss = 0.005215
2018-03-08 20:17:54 iter 100 loss = 0.003519
2018-03-08 20:17:59 iter 125 loss = 0.006833
2018-03-08 20:17:59 epoch 345/500 average_loss = 0.004472

2018-03-08 20:17:59 start epoch 346/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:17:59 iter 1 loss = 0.003555
2018-03-08 20:18:03 iter 25 loss = 0.001985
2018-03-08 20:18:08 iter 50 loss = 0.001948
2018-03-08 20:18:12 iter 75 loss = 0.002786
2018-03-08 20:18:17 iter 100 loss = 0.002178
2018-03-08 20:18:21 iter 125 loss = 0.002842
2018-03-08 20:18:21 epoch 346/500 average_loss = 0.004178

2018-03-08 20:18:21 start epoch 347/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:18:22 iter 1 loss = 0.005360
2018-03-08 20:18:26 iter 25 loss = 0.004199
2018-03-08 20:18:31 iter 50 loss = 0.002172
2018-03-08 20:18:35 iter 75 loss = 0.010493
2018-03-08 20:18:40 iter 100 loss = 0.002299
2018-03-08 20:18:44 iter 125 loss = 0.006421
2018-03-08 20:18:44 epoch 347/500 average_loss = 0.004571

2018-03-08 20:18:44 start epoch 348/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:18:45 iter 1 loss = 0.003687
2018-03-08 20:18:49 iter 25 loss = 0.003912
2018-03-08 20:18:54 iter 50 loss = 0.003215
2018-03-08 20:18:58 iter 75 loss = 0.003195
2018-03-08 20:19:03 iter 100 loss = 0.004870
2018-03-08 20:19:07 iter 125 loss = 0.005683
2018-03-08 20:19:07 epoch 348/500 average_loss = 0.004964

2018-03-08 20:19:07 start epoch 349/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:19:07 iter 1 loss = 0.006159
2018-03-08 20:19:12 iter 25 loss = 0.004524
2018-03-08 20:19:16 iter 50 loss = 0.002552
2018-03-08 20:19:21 iter 75 loss = 0.002587
2018-03-08 20:19:25 iter 100 loss = 0.004998
2018-03-08 20:19:30 iter 125 loss = 0.012207
2018-03-08 20:19:30 epoch 349/500 average_loss = 0.005212

2018-03-08 20:19:30 start epoch 350/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:19:30 iter 1 loss = 0.006852
2018-03-08 20:19:34 iter 25 loss = 0.002394
2018-03-08 20:19:39 iter 50 loss = 0.003256
2018-03-08 20:19:43 iter 75 loss = 0.003379
2018-03-08 20:19:48 iter 100 loss = 0.005170
2018-03-08 20:19:52 iter 125 loss = 0.010420
2018-03-08 20:19:52 epoch 350/500 average_loss = 0.004804

2018-03-08 20:19:52 start epoch 351/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:19:53 iter 1 loss = 0.006264
2018-03-08 20:19:57 iter 25 loss = 0.002186
2018-03-08 20:20:02 iter 50 loss = 0.002608
2018-03-08 20:20:06 iter 75 loss = 0.007129
2018-03-08 20:20:11 iter 100 loss = 0.003550
2018-03-08 20:20:15 iter 125 loss = 0.005258
2018-03-08 20:20:15 epoch 351/500 average_loss = 0.005124

2018-03-08 20:20:15 start epoch 352/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:20:16 iter 1 loss = 0.002788
2018-03-08 20:20:20 iter 25 loss = 0.003741
2018-03-08 20:20:24 iter 50 loss = 0.005234
2018-03-08 20:20:29 iter 75 loss = 0.002542
2018-03-08 20:20:33 iter 100 loss = 0.004254
2018-03-08 20:20:38 iter 125 loss = 0.002133
2018-03-08 20:20:38 epoch 352/500 average_loss = 0.004388

2018-03-08 20:20:38 start epoch 353/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:20:38 iter 1 loss = 0.003269
2018-03-08 20:20:43 iter 25 loss = 0.008979
2018-03-08 20:20:47 iter 50 loss = 0.002510
2018-03-08 20:20:52 iter 75 loss = 0.002293
2018-03-08 20:20:56 iter 100 loss = 0.002544
2018-03-08 20:21:01 iter 125 loss = 0.008478
2018-03-08 20:21:01 epoch 353/500 average_loss = 0.004362

2018-03-08 20:21:01 start epoch 354/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:21:01 iter 1 loss = 0.008926
2018-03-08 20:21:05 iter 25 loss = 0.003687
2018-03-08 20:21:10 iter 50 loss = 0.001881
2018-03-08 20:21:14 iter 75 loss = 0.006560
2018-03-08 20:21:19 iter 100 loss = 0.011896
2018-03-08 20:21:23 iter 125 loss = 0.008005
2018-03-08 20:21:23 epoch 354/500 average_loss = 0.005982

2018-03-08 20:21:23 start epoch 355/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:21:24 iter 1 loss = 0.004884
2018-03-08 20:21:28 iter 25 loss = 0.002799
2018-03-08 20:21:32 iter 50 loss = 0.003736
2018-03-08 20:21:37 iter 75 loss = 0.006967
2018-03-08 20:21:41 iter 100 loss = 0.008322
2018-03-08 20:21:46 iter 125 loss = 0.003293
2018-03-08 20:21:46 epoch 355/500 average_loss = 0.005143

2018-03-08 20:21:46 start epoch 356/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:21:46 iter 1 loss = 0.006249
2018-03-08 20:21:51 iter 25 loss = 0.005699
2018-03-08 20:21:55 iter 50 loss = 0.003111
2018-03-08 20:22:00 iter 75 loss = 0.003619
2018-03-08 20:22:04 iter 100 loss = 0.003491
2018-03-08 20:22:09 iter 125 loss = 0.002672
2018-03-08 20:22:09 epoch 356/500 average_loss = 0.004471

2018-03-08 20:22:09 start epoch 357/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:22:09 iter 1 loss = 0.005871
2018-03-08 20:22:13 iter 25 loss = 0.002012
2018-03-08 20:22:18 iter 50 loss = 0.007515
2018-03-08 20:22:22 iter 75 loss = 0.002500
2018-03-08 20:22:27 iter 100 loss = 0.002500
2018-03-08 20:22:31 iter 125 loss = 0.007136
2018-03-08 20:22:31 epoch 357/500 average_loss = 0.005149

2018-03-08 20:22:31 start epoch 358/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:22:32 iter 1 loss = 0.003078
2018-03-08 20:22:36 iter 25 loss = 0.004000
2018-03-08 20:22:40 iter 50 loss = 0.003566
2018-03-08 20:22:45 iter 75 loss = 0.004253
2018-03-08 20:22:49 iter 100 loss = 0.005221
2018-03-08 20:22:54 iter 125 loss = 0.003148
2018-03-08 20:22:54 epoch 358/500 average_loss = 0.005241

2018-03-08 20:22:54 start epoch 359/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:22:54 iter 1 loss = 0.004811
2018-03-08 20:22:59 iter 25 loss = 0.004411
2018-03-08 20:23:03 iter 50 loss = 0.005555
2018-03-08 20:23:08 iter 75 loss = 0.006208
2018-03-08 20:23:12 iter 100 loss = 0.002712
2018-03-08 20:23:17 iter 125 loss = 0.004523
2018-03-08 20:23:17 epoch 359/500 average_loss = 0.005790

2018-03-08 20:23:17 start epoch 360/500: learning_rate = 9.007199254741001e-05 sequence_len = 28
2018-03-08 20:23:17 iter 1 loss = 0.005926
2018-03-08 20:23:21 iter 25 loss = 0.003910
2018-03-08 20:23:26 iter 50 loss = 0.005275
2018-03-08 20:23:30 iter 75 loss = 0.004485
2018-03-08 20:23:35 iter 100 loss = 0.003274
2018-03-08 20:23:39 iter 125 loss = 0.002081
2018-03-08 20:23:39 epoch 360/500 average_loss = 0.004984

2018-03-08 20:23:39 start epoch 361/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:23:40 iter 1 loss = 0.003425
2018-03-08 20:23:44 iter 25 loss = 0.003179
2018-03-08 20:23:49 iter 50 loss = 0.004301
2018-03-08 20:23:53 iter 75 loss = 0.002964
2018-03-08 20:23:58 iter 100 loss = 0.004011
2018-03-08 20:24:02 iter 125 loss = 0.005649
2018-03-08 20:24:02 epoch 361/500 average_loss = 0.004719

2018-03-08 20:24:02 start epoch 362/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:24:02 iter 1 loss = 0.003563
2018-03-08 20:24:07 iter 25 loss = 0.003784
2018-03-08 20:24:11 iter 50 loss = 0.003603
2018-03-08 20:24:16 iter 75 loss = 0.002632
2018-03-08 20:24:20 iter 100 loss = 0.003146
2018-03-08 20:24:25 iter 125 loss = 0.003044
2018-03-08 20:24:25 epoch 362/500 average_loss = 0.004350

2018-03-08 20:24:25 start epoch 363/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:24:25 iter 1 loss = 0.003745
2018-03-08 20:24:29 iter 25 loss = 0.003615
2018-03-08 20:24:34 iter 50 loss = 0.008294
2018-03-08 20:24:38 iter 75 loss = 0.002557
2018-03-08 20:24:43 iter 100 loss = 0.002378
2018-03-08 20:24:47 iter 125 loss = 0.002429
2018-03-08 20:24:47 epoch 363/500 average_loss = 0.003393

2018-03-08 20:24:47 start epoch 364/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:24:48 iter 1 loss = 0.002670
2018-03-08 20:24:52 iter 25 loss = 0.006645
2018-03-08 20:24:57 iter 50 loss = 0.003889
2018-03-08 20:25:01 iter 75 loss = 0.002394
2018-03-08 20:25:06 iter 100 loss = 0.001698
2018-03-08 20:25:10 iter 125 loss = 0.002081
2018-03-08 20:25:10 epoch 364/500 average_loss = 0.003334

2018-03-08 20:25:10 start epoch 365/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:25:10 iter 1 loss = 0.001592
2018-03-08 20:25:15 iter 25 loss = 0.002053
2018-03-08 20:25:19 iter 50 loss = 0.003101
2018-03-08 20:25:24 iter 75 loss = 0.003687
2018-03-08 20:25:28 iter 100 loss = 0.004056
2018-03-08 20:25:33 iter 125 loss = 0.002343
2018-03-08 20:25:33 epoch 365/500 average_loss = 0.003476

2018-03-08 20:25:33 start epoch 366/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:25:33 iter 1 loss = 0.002194
2018-03-08 20:25:38 iter 25 loss = 0.002580
2018-03-08 20:25:42 iter 50 loss = 0.001703
2018-03-08 20:25:47 iter 75 loss = 0.003545
2018-03-08 20:25:51 iter 100 loss = 0.001903
2018-03-08 20:25:56 iter 125 loss = 0.001956
2018-03-08 20:25:56 epoch 366/500 average_loss = 0.003559

2018-03-08 20:25:56 start epoch 367/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:25:56 iter 1 loss = 0.002316
2018-03-08 20:26:00 iter 25 loss = 0.002076
2018-03-08 20:26:05 iter 50 loss = 0.003682
2018-03-08 20:26:09 iter 75 loss = 0.002355
2018-03-08 20:26:14 iter 100 loss = 0.001568
2018-03-08 20:26:18 iter 125 loss = 0.002674
2018-03-08 20:26:18 epoch 367/500 average_loss = 0.003160

2018-03-08 20:26:18 start epoch 368/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:26:19 iter 1 loss = 0.001976
2018-03-08 20:26:23 iter 25 loss = 0.001933
2018-03-08 20:26:28 iter 50 loss = 0.001963
2018-03-08 20:26:32 iter 75 loss = 0.004090
2018-03-08 20:26:37 iter 100 loss = 0.009274
2018-03-08 20:26:41 iter 125 loss = 0.005370
2018-03-08 20:26:41 epoch 368/500 average_loss = 0.006649

2018-03-08 20:26:41 start epoch 369/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:26:41 iter 1 loss = 0.003856
2018-03-08 20:26:46 iter 25 loss = 0.007176
2018-03-08 20:26:50 iter 50 loss = 0.005649
2018-03-08 20:26:55 iter 75 loss = 0.003643
2018-03-08 20:26:59 iter 100 loss = 0.007633
2018-03-08 20:27:04 iter 125 loss = 0.003016
2018-03-08 20:27:04 epoch 369/500 average_loss = 0.005317

2018-03-08 20:27:04 start epoch 370/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:27:04 iter 1 loss = 0.002662
2018-03-08 20:27:09 iter 25 loss = 0.007079
2018-03-08 20:27:13 iter 50 loss = 0.003297
2018-03-08 20:27:18 iter 75 loss = 0.005723
2018-03-08 20:27:22 iter 100 loss = 0.001907
2018-03-08 20:27:27 iter 125 loss = 0.002558
2018-03-08 20:27:27 epoch 370/500 average_loss = 0.003665

2018-03-08 20:27:27 start epoch 371/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:27:27 iter 1 loss = 0.004041
2018-03-08 20:27:31 iter 25 loss = 0.002972
2018-03-08 20:27:36 iter 50 loss = 0.005302
2018-03-08 20:27:40 iter 75 loss = 0.003989
2018-03-08 20:27:45 iter 100 loss = 0.002750
2018-03-08 20:27:49 iter 125 loss = 0.002491
2018-03-08 20:27:49 epoch 371/500 average_loss = 0.003491

2018-03-08 20:27:49 start epoch 372/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:27:50 iter 1 loss = 0.003373
2018-03-08 20:27:54 iter 25 loss = 0.001732
2018-03-08 20:27:59 iter 50 loss = 0.002192
2018-03-08 20:28:03 iter 75 loss = 0.004146
2018-03-08 20:28:08 iter 100 loss = 0.001867
2018-03-08 20:28:12 iter 125 loss = 0.001204
2018-03-08 20:28:12 epoch 372/500 average_loss = 0.002927

2018-03-08 20:28:12 start epoch 373/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:28:13 iter 1 loss = 0.001705
2018-03-08 20:28:17 iter 25 loss = 0.003186
2018-03-08 20:28:21 iter 50 loss = 0.002871
2018-03-08 20:28:26 iter 75 loss = 0.002834
2018-03-08 20:28:30 iter 100 loss = 0.002887
2018-03-08 20:28:35 iter 125 loss = 0.001812
2018-03-08 20:28:35 epoch 373/500 average_loss = 0.003356

2018-03-08 20:28:35 start epoch 374/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:28:35 iter 1 loss = 0.004465
2018-03-08 20:28:40 iter 25 loss = 0.002483
2018-03-08 20:28:44 iter 50 loss = 0.001778
2018-03-08 20:28:49 iter 75 loss = 0.007970
2018-03-08 20:28:53 iter 100 loss = 0.002190
2018-03-08 20:28:58 iter 125 loss = 0.002768
2018-03-08 20:28:58 epoch 374/500 average_loss = 0.004065

2018-03-08 20:28:58 start epoch 375/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:28:58 iter 1 loss = 0.005785
2018-03-08 20:29:02 iter 25 loss = 0.002696
2018-03-08 20:29:07 iter 50 loss = 0.002658
2018-03-08 20:29:11 iter 75 loss = 0.001899
2018-03-08 20:29:16 iter 100 loss = 0.002008
2018-03-08 20:29:21 iter 125 loss = 0.006078
2018-03-08 20:29:21 epoch 375/500 average_loss = 0.003090

2018-03-08 20:29:21 start epoch 376/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:29:21 iter 1 loss = 0.002647
2018-03-08 20:29:25 iter 25 loss = 0.001636
2018-03-08 20:29:30 iter 50 loss = 0.002134
2018-03-08 20:29:34 iter 75 loss = 0.002373
2018-03-08 20:29:39 iter 100 loss = 0.006382
2018-03-08 20:29:43 iter 125 loss = 0.009009
2018-03-08 20:29:43 epoch 376/500 average_loss = 0.002836

2018-03-08 20:29:43 start epoch 377/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:29:44 iter 1 loss = 0.002678
2018-03-08 20:29:48 iter 25 loss = 0.001852
2018-03-08 20:29:52 iter 50 loss = 0.001717
2018-03-08 20:29:57 iter 75 loss = 0.007093
2018-03-08 20:30:01 iter 100 loss = 0.001685
2018-03-08 20:30:06 iter 125 loss = 0.001471
2018-03-08 20:30:06 epoch 377/500 average_loss = 0.003366

2018-03-08 20:30:06 start epoch 378/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:30:06 iter 1 loss = 0.001427
2018-03-08 20:30:11 iter 25 loss = 0.003856
2018-03-08 20:30:15 iter 50 loss = 0.002467
2018-03-08 20:30:20 iter 75 loss = 0.003460
2018-03-08 20:30:24 iter 100 loss = 0.002691
2018-03-08 20:30:29 iter 125 loss = 0.001792
2018-03-08 20:30:29 epoch 378/500 average_loss = 0.002892

2018-03-08 20:30:29 start epoch 379/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:30:29 iter 1 loss = 0.001474
2018-03-08 20:30:33 iter 25 loss = 0.001810
2018-03-08 20:30:38 iter 50 loss = 0.002452
2018-03-08 20:30:42 iter 75 loss = 0.005822
2018-03-08 20:30:47 iter 100 loss = 0.001947
2018-03-08 20:30:51 iter 125 loss = 0.002688
2018-03-08 20:30:51 epoch 379/500 average_loss = 0.003919

2018-03-08 20:30:51 start epoch 380/500: learning_rate = 7.205759403792801e-05 sequence_len = 28
2018-03-08 20:30:52 iter 1 loss = 0.001888
2018-03-08 20:30:56 iter 25 loss = 0.003112
2018-03-08 20:31:01 iter 50 loss = 0.001909
2018-03-08 20:31:05 iter 75 loss = 0.002110
2018-03-08 20:31:10 iter 100 loss = 0.004658
2018-03-08 20:31:14 iter 125 loss = 0.005578
2018-03-08 20:31:14 epoch 380/500 average_loss = 0.003207

2018-03-08 20:31:14 start epoch 381/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:31:14 iter 1 loss = 0.002741
2018-03-08 20:31:19 iter 25 loss = 0.001563
2018-03-08 20:31:23 iter 50 loss = 0.003355
2018-03-08 20:31:28 iter 75 loss = 0.002059
2018-03-08 20:31:32 iter 100 loss = 0.001740
2018-03-08 20:31:37 iter 125 loss = 0.002962
2018-03-08 20:31:37 epoch 381/500 average_loss = 0.003098

2018-03-08 20:31:37 start epoch 382/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:31:37 iter 1 loss = 0.001903
2018-03-08 20:31:42 iter 25 loss = 0.005367
2018-03-08 20:31:46 iter 50 loss = 0.001619
2018-03-08 20:31:51 iter 75 loss = 0.003407
2018-03-08 20:31:55 iter 100 loss = 0.002115
2018-03-08 20:32:00 iter 125 loss = 0.002089
2018-03-08 20:32:00 epoch 382/500 average_loss = 0.002859

2018-03-08 20:32:00 start epoch 383/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:32:00 iter 1 loss = 0.001443
2018-03-08 20:32:04 iter 25 loss = 0.002876
2018-03-08 20:32:09 iter 50 loss = 0.001676
2018-03-08 20:32:13 iter 75 loss = 0.001225
2018-03-08 20:32:18 iter 100 loss = 0.002095
2018-03-08 20:32:22 iter 125 loss = 0.014513
2018-03-08 20:32:22 epoch 383/500 average_loss = 0.003182

2018-03-08 20:32:22 start epoch 384/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:32:23 iter 1 loss = 0.002099
2018-03-08 20:32:27 iter 25 loss = 0.002215
2018-03-08 20:32:32 iter 50 loss = 0.007070
2018-03-08 20:32:36 iter 75 loss = 0.003166
2018-03-08 20:32:41 iter 100 loss = 0.004174
2018-03-08 20:32:45 iter 125 loss = 0.001502
2018-03-08 20:32:45 epoch 384/500 average_loss = 0.003712

2018-03-08 20:32:45 start epoch 385/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:32:45 iter 1 loss = 0.001970
2018-03-08 20:32:50 iter 25 loss = 0.006481
2018-03-08 20:32:54 iter 50 loss = 0.004172
2018-03-08 20:32:59 iter 75 loss = 0.009738
2018-03-08 20:33:03 iter 100 loss = 0.004800
2018-03-08 20:33:08 iter 125 loss = 0.001739
2018-03-08 20:33:08 epoch 385/500 average_loss = 0.002551

2018-03-08 20:33:08 start epoch 386/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:33:08 iter 1 loss = 0.002197
2018-03-08 20:33:12 iter 25 loss = 0.001177
2018-03-08 20:33:17 iter 50 loss = 0.001897
2018-03-08 20:33:21 iter 75 loss = 0.002297
2018-03-08 20:33:26 iter 100 loss = 0.002138
2018-03-08 20:33:31 iter 125 loss = 0.002465
2018-03-08 20:33:31 epoch 386/500 average_loss = 0.003656

2018-03-08 20:33:31 start epoch 387/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:33:31 iter 1 loss = 0.004909
2018-03-08 20:33:35 iter 25 loss = 0.001446
2018-03-08 20:33:40 iter 50 loss = 0.002570
2018-03-08 20:33:44 iter 75 loss = 0.003032
2018-03-08 20:33:49 iter 100 loss = 0.002952
2018-03-08 20:33:53 iter 125 loss = 0.001681
2018-03-08 20:33:53 epoch 387/500 average_loss = 0.002906

2018-03-08 20:33:53 start epoch 388/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:33:54 iter 1 loss = 0.002573
2018-03-08 20:33:58 iter 25 loss = 0.002325
2018-03-08 20:34:02 iter 50 loss = 0.002409
2018-03-08 20:34:07 iter 75 loss = 0.001403
2018-03-08 20:34:11 iter 100 loss = 0.001844
2018-03-08 20:34:16 iter 125 loss = 0.011666
2018-03-08 20:34:16 epoch 388/500 average_loss = 0.002710

2018-03-08 20:34:16 start epoch 389/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:34:16 iter 1 loss = 0.002034
2018-03-08 20:34:21 iter 25 loss = 0.004236
2018-03-08 20:34:25 iter 50 loss = 0.004740
2018-03-08 20:34:30 iter 75 loss = 0.005582
2018-03-08 20:34:34 iter 100 loss = 0.001304
2018-03-08 20:34:39 iter 125 loss = 0.002114
2018-03-08 20:34:39 epoch 389/500 average_loss = 0.005977

2018-03-08 20:34:39 start epoch 390/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:34:39 iter 1 loss = 0.001234
2018-03-08 20:34:43 iter 25 loss = 0.002080
2018-03-08 20:34:48 iter 50 loss = 0.002978
2018-03-08 20:34:52 iter 75 loss = 0.002275
2018-03-08 20:34:57 iter 100 loss = 0.001730
2018-03-08 20:35:01 iter 125 loss = 0.001548
2018-03-08 20:35:01 epoch 390/500 average_loss = 0.002597

2018-03-08 20:35:01 start epoch 391/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:35:02 iter 1 loss = 0.002938
2018-03-08 20:35:06 iter 25 loss = 0.001142
2018-03-08 20:35:11 iter 50 loss = 0.001846
2018-03-08 20:35:15 iter 75 loss = 0.006572
2018-03-08 20:35:20 iter 100 loss = 0.001628
2018-03-08 20:35:24 iter 125 loss = 0.001775
2018-03-08 20:35:24 epoch 391/500 average_loss = 0.003145

2018-03-08 20:35:24 start epoch 392/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:35:24 iter 1 loss = 0.001467
2018-03-08 20:35:29 iter 25 loss = 0.002521
2018-03-08 20:35:33 iter 50 loss = 0.004220
2018-03-08 20:35:38 iter 75 loss = 0.007090
2018-03-08 20:35:42 iter 100 loss = 0.001825
2018-03-08 20:35:47 iter 125 loss = 0.003012
2018-03-08 20:35:47 epoch 392/500 average_loss = 0.002757

2018-03-08 20:35:47 start epoch 393/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:35:47 iter 1 loss = 0.001727
2018-03-08 20:35:52 iter 25 loss = 0.001159
2018-03-08 20:35:56 iter 50 loss = 0.001986
2018-03-08 20:36:01 iter 75 loss = 0.001484
2018-03-08 20:36:05 iter 100 loss = 0.002201
2018-03-08 20:36:10 iter 125 loss = 0.003030
2018-03-08 20:36:10 epoch 393/500 average_loss = 0.002540

2018-03-08 20:36:10 start epoch 394/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:36:10 iter 1 loss = 0.001584
2018-03-08 20:36:14 iter 25 loss = 0.001374
2018-03-08 20:36:19 iter 50 loss = 0.006608
2018-03-08 20:36:23 iter 75 loss = 0.004994
2018-03-08 20:36:28 iter 100 loss = 0.002922
2018-03-08 20:36:32 iter 125 loss = 0.005364
2018-03-08 20:36:32 epoch 394/500 average_loss = 0.011592

2018-03-08 20:36:32 start epoch 395/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:36:33 iter 1 loss = 0.004732
2018-03-08 20:36:37 iter 25 loss = 0.004424
2018-03-08 20:36:41 iter 50 loss = 0.008129
2018-03-08 20:36:46 iter 75 loss = 0.002122
2018-03-08 20:36:51 iter 100 loss = 0.002326
2018-03-08 20:36:55 iter 125 loss = 0.001820
2018-03-08 20:36:55 epoch 395/500 average_loss = 0.003870

2018-03-08 20:36:55 start epoch 396/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:36:55 iter 1 loss = 0.002765
2018-03-08 20:37:00 iter 25 loss = 0.004287
2018-03-08 20:37:04 iter 50 loss = 0.003862
2018-03-08 20:37:09 iter 75 loss = 0.002150
2018-03-08 20:37:13 iter 100 loss = 0.002732
2018-03-08 20:37:18 iter 125 loss = 0.003452
2018-03-08 20:37:18 epoch 396/500 average_loss = 0.005150

2018-03-08 20:37:18 start epoch 397/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:37:18 iter 1 loss = 0.004510
2018-03-08 20:37:22 iter 25 loss = 0.003643
2018-03-08 20:37:27 iter 50 loss = 0.001834
2018-03-08 20:37:32 iter 75 loss = 0.003964
2018-03-08 20:37:36 iter 100 loss = 0.001957
2018-03-08 20:37:41 iter 125 loss = 0.002074
2018-03-08 20:37:41 epoch 397/500 average_loss = 0.003279

2018-03-08 20:37:41 start epoch 398/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:37:41 iter 1 loss = 0.002243
2018-03-08 20:37:45 iter 25 loss = 0.002879
2018-03-08 20:37:50 iter 50 loss = 0.001371
2018-03-08 20:37:54 iter 75 loss = 0.001189
2018-03-08 20:37:59 iter 100 loss = 0.001470
2018-03-08 20:38:03 iter 125 loss = 0.001911
2018-03-08 20:38:03 epoch 398/500 average_loss = 0.003162

2018-03-08 20:38:03 start epoch 399/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:38:04 iter 1 loss = 0.004808
2018-03-08 20:38:08 iter 25 loss = 0.001388
2018-03-08 20:38:12 iter 50 loss = 0.003819
2018-03-08 20:38:17 iter 75 loss = 0.001675
2018-03-08 20:38:21 iter 100 loss = 0.001799
2018-03-08 20:38:26 iter 125 loss = 0.002522
2018-03-08 20:38:26 epoch 399/500 average_loss = 0.002770

2018-03-08 20:38:26 start epoch 400/500: learning_rate = 5.764607523034241e-05 sequence_len = 28
2018-03-08 20:38:26 iter 1 loss = 0.002091
2018-03-08 20:38:31 iter 25 loss = 0.002044
2018-03-08 20:38:35 iter 50 loss = 0.002221
2018-03-08 20:38:40 iter 75 loss = 0.002242
2018-03-08 20:38:44 iter 100 loss = 0.001839
2018-03-08 20:38:49 iter 125 loss = 0.002486
2018-03-08 20:38:49 epoch 400/500 average_loss = 0.002800

2018-03-08 20:38:49 start epoch 401/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:38:49 iter 1 loss = 0.001615
2018-03-08 20:38:53 iter 25 loss = 0.009843
2018-03-08 20:38:58 iter 50 loss = 0.001735
2018-03-08 20:39:02 iter 75 loss = 0.001447
2018-03-08 20:39:07 iter 100 loss = 0.001340
2018-03-08 20:39:11 iter 125 loss = 0.002301
2018-03-08 20:39:11 epoch 401/500 average_loss = 0.002391

2018-03-08 20:39:11 start epoch 402/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:39:12 iter 1 loss = 0.001216
2018-03-08 20:39:16 iter 25 loss = 0.001280
2018-03-08 20:39:20 iter 50 loss = 0.003404
2018-03-08 20:39:25 iter 75 loss = 0.001840
2018-03-08 20:39:29 iter 100 loss = 0.001161
2018-03-08 20:39:34 iter 125 loss = 0.003061
2018-03-08 20:39:34 epoch 402/500 average_loss = 0.002160

2018-03-08 20:39:34 start epoch 403/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:39:34 iter 1 loss = 0.001646
2018-03-08 20:39:39 iter 25 loss = 0.001471
2018-03-08 20:39:43 iter 50 loss = 0.001293
2018-03-08 20:39:48 iter 75 loss = 0.003442
2018-03-08 20:39:52 iter 100 loss = 0.001037
2018-03-08 20:39:57 iter 125 loss = 0.005144
2018-03-08 20:39:57 epoch 403/500 average_loss = 0.001946

2018-03-08 20:39:57 start epoch 404/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:39:57 iter 1 loss = 0.001000
2018-03-08 20:40:01 iter 25 loss = 0.001016
2018-03-08 20:40:06 iter 50 loss = 0.001233
2018-03-08 20:40:10 iter 75 loss = 0.001654
2018-03-08 20:40:15 iter 100 loss = 0.000834
2018-03-08 20:40:19 iter 125 loss = 0.001428
2018-03-08 20:40:19 epoch 404/500 average_loss = 0.001956

2018-03-08 20:40:19 start epoch 405/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:40:20 iter 1 loss = 0.001626
2018-03-08 20:40:24 iter 25 loss = 0.001424
2018-03-08 20:40:29 iter 50 loss = 0.002526
2018-03-08 20:40:33 iter 75 loss = 0.001375
2018-03-08 20:40:38 iter 100 loss = 0.005748
2018-03-08 20:40:42 iter 125 loss = 0.003149
2018-03-08 20:40:42 epoch 405/500 average_loss = 0.002436

2018-03-08 20:40:42 start epoch 406/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:40:42 iter 1 loss = 0.001344
2018-03-08 20:40:47 iter 25 loss = 0.001362
2018-03-08 20:40:51 iter 50 loss = 0.001171
2018-03-08 20:40:56 iter 75 loss = 0.001083
2018-03-08 20:41:00 iter 100 loss = 0.001714
2018-03-08 20:41:05 iter 125 loss = 0.001873
2018-03-08 20:41:05 epoch 406/500 average_loss = 0.001885

2018-03-08 20:41:05 start epoch 407/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:41:05 iter 1 loss = 0.002367
2018-03-08 20:41:10 iter 25 loss = 0.002432
2018-03-08 20:41:14 iter 50 loss = 0.002816
2018-03-08 20:41:19 iter 75 loss = 0.002055
2018-03-08 20:41:23 iter 100 loss = 0.001371
2018-03-08 20:41:28 iter 125 loss = 0.003103
2018-03-08 20:41:28 epoch 407/500 average_loss = 0.002123

2018-03-08 20:41:28 start epoch 408/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:41:28 iter 1 loss = 0.002364
2018-03-08 20:41:32 iter 25 loss = 0.001411
2018-03-08 20:41:37 iter 50 loss = 0.001137
2018-03-08 20:41:41 iter 75 loss = 0.001952
2018-03-08 20:41:46 iter 100 loss = 0.001295
2018-03-08 20:41:50 iter 125 loss = 0.001454
2018-03-08 20:41:50 epoch 408/500 average_loss = 0.002157

2018-03-08 20:41:50 start epoch 409/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:41:51 iter 1 loss = 0.001479
2018-03-08 20:41:55 iter 25 loss = 0.000875
2018-03-08 20:42:00 iter 50 loss = 0.001184
2018-03-08 20:42:04 iter 75 loss = 0.001817
2018-03-08 20:42:09 iter 100 loss = 0.001713
2018-03-08 20:42:13 iter 125 loss = 0.001194
2018-03-08 20:42:13 epoch 409/500 average_loss = 0.002132

2018-03-08 20:42:13 start epoch 410/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:42:13 iter 1 loss = 0.000960
2018-03-08 20:42:18 iter 25 loss = 0.001434
2018-03-08 20:42:22 iter 50 loss = 0.001184
2018-03-08 20:42:27 iter 75 loss = 0.062637
2018-03-08 20:42:31 iter 100 loss = 0.002980
2018-03-08 20:42:36 iter 125 loss = 0.000923
2018-03-08 20:42:36 epoch 410/500 average_loss = 0.002791

2018-03-08 20:42:36 start epoch 411/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:42:36 iter 1 loss = 0.001228
2018-03-08 20:42:40 iter 25 loss = 0.001154
2018-03-08 20:42:45 iter 50 loss = 0.001159
2018-03-08 20:42:49 iter 75 loss = 0.002827
2018-03-08 20:42:54 iter 100 loss = 0.001127
2018-03-08 20:42:58 iter 125 loss = 0.001652
2018-03-08 20:42:58 epoch 411/500 average_loss = 0.001938

2018-03-08 20:42:58 start epoch 412/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:42:59 iter 1 loss = 0.001611
2018-03-08 20:43:03 iter 25 loss = 0.002992
2018-03-08 20:43:08 iter 50 loss = 0.005393
2018-03-08 20:43:12 iter 75 loss = 0.002296
2018-03-08 20:43:17 iter 100 loss = 0.001876
2018-03-08 20:43:21 iter 125 loss = 0.001235
2018-03-08 20:43:21 epoch 412/500 average_loss = 0.001913

2018-03-08 20:43:21 start epoch 413/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:43:21 iter 1 loss = 0.001433
2018-03-08 20:43:26 iter 25 loss = 0.001778
2018-03-08 20:43:30 iter 50 loss = 0.001623
2018-03-08 20:43:35 iter 75 loss = 0.001257
2018-03-08 20:43:39 iter 100 loss = 0.001214
2018-03-08 20:43:44 iter 125 loss = 0.001730
2018-03-08 20:43:44 epoch 413/500 average_loss = 0.002472

2018-03-08 20:43:44 start epoch 414/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:43:44 iter 1 loss = 0.001150
2018-03-08 20:43:48 iter 25 loss = 0.001026
2018-03-08 20:43:53 iter 50 loss = 0.001638
2018-03-08 20:43:57 iter 75 loss = 0.000924
2018-03-08 20:44:02 iter 100 loss = 0.001154
2018-03-08 20:44:06 iter 125 loss = 0.001614
2018-03-08 20:44:06 epoch 414/500 average_loss = 0.002109

2018-03-08 20:44:06 start epoch 415/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:44:07 iter 1 loss = 0.000804
2018-03-08 20:44:11 iter 25 loss = 0.001506
2018-03-08 20:44:16 iter 50 loss = 0.001252
2018-03-08 20:44:20 iter 75 loss = 0.001831
2018-03-08 20:44:25 iter 100 loss = 0.001115
2018-03-08 20:44:29 iter 125 loss = 0.000897
2018-03-08 20:44:29 epoch 415/500 average_loss = 0.001992

2018-03-08 20:44:29 start epoch 416/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:44:29 iter 1 loss = 0.001251
2018-03-08 20:44:34 iter 25 loss = 0.001122
2018-03-08 20:44:38 iter 50 loss = 0.008319
2018-03-08 20:44:43 iter 75 loss = 0.001466
2018-03-08 20:44:47 iter 100 loss = 0.002218
2018-03-08 20:44:52 iter 125 loss = 0.000922
2018-03-08 20:44:52 epoch 416/500 average_loss = 0.001814

2018-03-08 20:44:52 start epoch 417/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:44:52 iter 1 loss = 0.001702
2018-03-08 20:44:56 iter 25 loss = 0.000793
2018-03-08 20:45:01 iter 50 loss = 0.001247
2018-03-08 20:45:05 iter 75 loss = 0.001134
2018-03-08 20:45:10 iter 100 loss = 0.001996
2018-03-08 20:45:14 iter 125 loss = 0.001164
2018-03-08 20:45:14 epoch 417/500 average_loss = 0.001614

2018-03-08 20:45:14 start epoch 418/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:45:15 iter 1 loss = 0.001508
2018-03-08 20:45:19 iter 25 loss = 0.001759
2018-03-08 20:45:24 iter 50 loss = 0.001084
2018-03-08 20:45:28 iter 75 loss = 0.001234
2018-03-08 20:45:33 iter 100 loss = 0.001567
2018-03-08 20:45:37 iter 125 loss = 0.003243
2018-03-08 20:45:37 epoch 418/500 average_loss = 0.001771

2018-03-08 20:45:37 start epoch 419/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:45:38 iter 1 loss = 0.002582
2018-03-08 20:45:42 iter 25 loss = 0.001085
2018-03-08 20:45:46 iter 50 loss = 0.002658
2018-03-08 20:45:51 iter 75 loss = 0.000852
2018-03-08 20:45:55 iter 100 loss = 0.001857
2018-03-08 20:46:00 iter 125 loss = 0.002832
2018-03-08 20:46:00 epoch 419/500 average_loss = 0.003270

2018-03-08 20:46:00 start epoch 420/500: learning_rate = 4.611686018427393e-05 sequence_len = 28
2018-03-08 20:46:00 iter 1 loss = 0.009684
2018-03-08 20:46:05 iter 25 loss = 0.012670
2018-03-08 20:46:09 iter 50 loss = 0.001806
2018-03-08 20:46:14 iter 75 loss = 0.004651
2018-03-08 20:46:18 iter 100 loss = 0.001479
2018-03-08 20:46:23 iter 125 loss = 0.001335
2018-03-08 20:46:23 epoch 420/500 average_loss = 0.002742

2018-03-08 20:46:23 start epoch 421/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:46:23 iter 1 loss = 0.001943
2018-03-08 20:46:27 iter 25 loss = 0.002227
2018-03-08 20:46:32 iter 50 loss = 0.003596
2018-03-08 20:46:36 iter 75 loss = 0.002218
2018-03-08 20:46:41 iter 100 loss = 0.002876
2018-03-08 20:46:45 iter 125 loss = 0.001738
2018-03-08 20:46:45 epoch 421/500 average_loss = 0.008941

2018-03-08 20:46:45 start epoch 422/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:46:46 iter 1 loss = 0.003803
2018-03-08 20:46:50 iter 25 loss = 0.001103
2018-03-08 20:46:55 iter 50 loss = 0.002391
2018-03-08 20:46:59 iter 75 loss = 0.002643
2018-03-08 20:47:04 iter 100 loss = 0.002666
2018-03-08 20:47:08 iter 125 loss = 0.002980
2018-03-08 20:47:08 epoch 422/500 average_loss = 0.002453

2018-03-08 20:47:08 start epoch 423/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:47:09 iter 1 loss = 0.001912
2018-03-08 20:47:13 iter 25 loss = 0.001679
2018-03-08 20:47:17 iter 50 loss = 0.002014
2018-03-08 20:47:22 iter 75 loss = 0.021754
2018-03-08 20:47:27 iter 100 loss = 0.000993
2018-03-08 20:47:31 iter 125 loss = 0.003637
2018-03-08 20:47:31 epoch 423/500 average_loss = 0.002462

2018-03-08 20:47:31 start epoch 424/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:47:31 iter 1 loss = 0.001377
2018-03-08 20:47:36 iter 25 loss = 0.001123
2018-03-08 20:47:40 iter 50 loss = 0.001422
2018-03-08 20:47:45 iter 75 loss = 0.001346
2018-03-08 20:47:49 iter 100 loss = 0.001205
2018-03-08 20:47:54 iter 125 loss = 0.001343
2018-03-08 20:47:54 epoch 424/500 average_loss = 0.001837

2018-03-08 20:47:54 start epoch 425/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:47:54 iter 1 loss = 0.000838
2018-03-08 20:47:58 iter 25 loss = 0.001034
2018-03-08 20:48:03 iter 50 loss = 0.001089
2018-03-08 20:48:07 iter 75 loss = 0.001481
2018-03-08 20:48:12 iter 100 loss = 0.000905
2018-03-08 20:48:16 iter 125 loss = 0.001773
2018-03-08 20:48:16 epoch 425/500 average_loss = 0.002022

2018-03-08 20:48:16 start epoch 426/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:48:17 iter 1 loss = 0.000887
2018-03-08 20:48:21 iter 25 loss = 0.001167
2018-03-08 20:48:26 iter 50 loss = 0.000570
2018-03-08 20:48:30 iter 75 loss = 0.001346
2018-03-08 20:48:35 iter 100 loss = 0.000755
2018-03-08 20:48:39 iter 125 loss = 0.001476
2018-03-08 20:48:39 epoch 426/500 average_loss = 0.001889

2018-03-08 20:48:39 start epoch 427/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:48:39 iter 1 loss = 0.002209
2018-03-08 20:48:44 iter 25 loss = 0.005554
2018-03-08 20:48:48 iter 50 loss = 0.003612
2018-03-08 20:48:53 iter 75 loss = 0.002353
2018-03-08 20:48:57 iter 100 loss = 0.001422
2018-03-08 20:49:02 iter 125 loss = 0.000862
2018-03-08 20:49:02 epoch 427/500 average_loss = 0.003715

2018-03-08 20:49:02 start epoch 428/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:49:02 iter 1 loss = 0.001824
2018-03-08 20:49:06 iter 25 loss = 0.001093
2018-03-08 20:49:11 iter 50 loss = 0.001482
2018-03-08 20:49:15 iter 75 loss = 0.000740
2018-03-08 20:49:20 iter 100 loss = 0.007669
2018-03-08 20:49:25 iter 125 loss = 0.001232
2018-03-08 20:49:25 epoch 428/500 average_loss = 0.002115

2018-03-08 20:49:25 start epoch 429/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:49:25 iter 1 loss = 0.000969
2018-03-08 20:49:29 iter 25 loss = 0.001792
2018-03-08 20:49:34 iter 50 loss = 0.001652
2018-03-08 20:49:38 iter 75 loss = 0.007975
2018-03-08 20:49:43 iter 100 loss = 0.010397
2018-03-08 20:49:47 iter 125 loss = 0.001149
2018-03-08 20:49:47 epoch 429/500 average_loss = 0.002821

2018-03-08 20:49:47 start epoch 430/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:49:48 iter 1 loss = 0.003668
2018-03-08 20:49:52 iter 25 loss = 0.004581
2018-03-08 20:49:56 iter 50 loss = 0.003173
2018-03-08 20:50:01 iter 75 loss = 0.001956
2018-03-08 20:50:05 iter 100 loss = 0.001290
2018-03-08 20:50:10 iter 125 loss = 0.001243
2018-03-08 20:50:10 epoch 430/500 average_loss = 0.002085

2018-03-08 20:50:10 start epoch 431/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:50:10 iter 1 loss = 0.001205
2018-03-08 20:50:15 iter 25 loss = 0.000926
2018-03-08 20:50:19 iter 50 loss = 0.003727
2018-03-08 20:50:24 iter 75 loss = 0.002337
2018-03-08 20:50:28 iter 100 loss = 0.001439
2018-03-08 20:50:33 iter 125 loss = 0.001429
2018-03-08 20:50:33 epoch 431/500 average_loss = 0.002038

2018-03-08 20:50:33 start epoch 432/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:50:33 iter 1 loss = 0.001744
2018-03-08 20:50:37 iter 25 loss = 0.004427
2018-03-08 20:50:42 iter 50 loss = 0.001906
2018-03-08 20:50:46 iter 75 loss = 0.001447
2018-03-08 20:50:51 iter 100 loss = 0.001472
2018-03-08 20:50:55 iter 125 loss = 0.001054
2018-03-08 20:50:55 epoch 432/500 average_loss = 0.002284

2018-03-08 20:50:55 start epoch 433/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:50:56 iter 1 loss = 0.001153
2018-03-08 20:51:00 iter 25 loss = 0.000924
2018-03-08 20:51:05 iter 50 loss = 0.001687
2018-03-08 20:51:09 iter 75 loss = 0.001344
2018-03-08 20:51:14 iter 100 loss = 0.001214
2018-03-08 20:51:18 iter 125 loss = 0.001345
2018-03-08 20:51:18 epoch 433/500 average_loss = 0.002112

2018-03-08 20:51:18 start epoch 434/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:51:18 iter 1 loss = 0.001045
2018-03-08 20:51:23 iter 25 loss = 0.001398
2018-03-08 20:51:27 iter 50 loss = 0.001163
2018-03-08 20:51:32 iter 75 loss = 0.000705
2018-03-08 20:51:36 iter 100 loss = 0.003138
2018-03-08 20:51:41 iter 125 loss = 0.001154
2018-03-08 20:51:41 epoch 434/500 average_loss = 0.001717

2018-03-08 20:51:41 start epoch 435/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:51:41 iter 1 loss = 0.001180
2018-03-08 20:51:45 iter 25 loss = 0.001492
2018-03-08 20:51:50 iter 50 loss = 0.001245
2018-03-08 20:51:54 iter 75 loss = 0.000935
2018-03-08 20:51:59 iter 100 loss = 0.001453
2018-03-08 20:52:03 iter 125 loss = 0.001252
2018-03-08 20:52:03 epoch 435/500 average_loss = 0.001566

2018-03-08 20:52:03 start epoch 436/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:52:04 iter 1 loss = 0.001106
2018-03-08 20:52:08 iter 25 loss = 0.001486
2018-03-08 20:52:12 iter 50 loss = 0.001629
2018-03-08 20:52:17 iter 75 loss = 0.001690
2018-03-08 20:52:21 iter 100 loss = 0.001636
2018-03-08 20:52:26 iter 125 loss = 0.001259
2018-03-08 20:52:26 epoch 436/500 average_loss = 0.001508

2018-03-08 20:52:26 start epoch 437/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:52:26 iter 1 loss = 0.001035
2018-03-08 20:52:31 iter 25 loss = 0.001467
2018-03-08 20:52:35 iter 50 loss = 0.000702
2018-03-08 20:52:40 iter 75 loss = 0.001263
2018-03-08 20:52:44 iter 100 loss = 0.000943
2018-03-08 20:52:49 iter 125 loss = 0.000802
2018-03-08 20:52:49 epoch 437/500 average_loss = 0.001387

2018-03-08 20:52:49 start epoch 438/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:52:49 iter 1 loss = 0.003593
2018-03-08 20:52:53 iter 25 loss = 0.001370
2018-03-08 20:52:58 iter 50 loss = 0.001216
2018-03-08 20:53:02 iter 75 loss = 0.001389
2018-03-08 20:53:07 iter 100 loss = 0.001238
2018-03-08 20:53:11 iter 125 loss = 0.001506
2018-03-08 20:53:11 epoch 438/500 average_loss = 0.001464

2018-03-08 20:53:11 start epoch 439/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:53:12 iter 1 loss = 0.001306
2018-03-08 20:53:16 iter 25 loss = 0.001425
2018-03-08 20:53:21 iter 50 loss = 0.000824
2018-03-08 20:53:25 iter 75 loss = 0.000952
2018-03-08 20:53:30 iter 100 loss = 0.001015
2018-03-08 20:53:34 iter 125 loss = 0.001736
2018-03-08 20:53:34 epoch 439/500 average_loss = 0.001665

2018-03-08 20:53:34 start epoch 440/500: learning_rate = 3.689348814741915e-05 sequence_len = 28
2018-03-08 20:53:34 iter 1 loss = 0.001832
2018-03-08 20:53:39 iter 25 loss = 0.000931
2018-03-08 20:53:43 iter 50 loss = 0.003497
2018-03-08 20:53:48 iter 75 loss = 0.001034
2018-03-08 20:53:52 iter 100 loss = 0.111092
2018-03-08 20:53:57 iter 125 loss = 0.002809
2018-03-08 20:53:57 epoch 440/500 average_loss = 0.002985

2018-03-08 20:53:57 start epoch 441/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:53:57 iter 1 loss = 0.002841
2018-03-08 20:54:01 iter 25 loss = 0.001492
2018-03-08 20:54:06 iter 50 loss = 0.000821
2018-03-08 20:54:11 iter 75 loss = 0.006862
2018-03-08 20:54:15 iter 100 loss = 0.001748
2018-03-08 20:54:20 iter 125 loss = 0.001412
2018-03-08 20:54:20 epoch 441/500 average_loss = 0.002077

2018-03-08 20:54:20 start epoch 442/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:54:20 iter 1 loss = 0.001378
2018-03-08 20:54:24 iter 25 loss = 0.001425
2018-03-08 20:54:29 iter 50 loss = 0.000903
2018-03-08 20:54:33 iter 75 loss = 0.002262
2018-03-08 20:54:38 iter 100 loss = 0.001174
2018-03-08 20:54:42 iter 125 loss = 0.001060
2018-03-08 20:54:42 epoch 442/500 average_loss = 0.001772

2018-03-08 20:54:42 start epoch 443/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:54:43 iter 1 loss = 0.001143
2018-03-08 20:54:47 iter 25 loss = 0.000991
2018-03-08 20:54:51 iter 50 loss = 0.001313
2018-03-08 20:54:56 iter 75 loss = 0.001851
2018-03-08 20:55:00 iter 100 loss = 0.003532
2018-03-08 20:55:05 iter 125 loss = 0.001011
2018-03-08 20:55:05 epoch 443/500 average_loss = 0.001551

2018-03-08 20:55:05 start epoch 444/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:55:05 iter 1 loss = 0.001757
2018-03-08 20:55:10 iter 25 loss = 0.001105
2018-03-08 20:55:14 iter 50 loss = 0.001431
2018-03-08 20:55:19 iter 75 loss = 0.001258
2018-03-08 20:55:23 iter 100 loss = 0.000946
2018-03-08 20:55:28 iter 125 loss = 0.000592
2018-03-08 20:55:28 epoch 444/500 average_loss = 0.001411

2018-03-08 20:55:28 start epoch 445/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:55:28 iter 1 loss = 0.000812
2018-03-08 20:55:32 iter 25 loss = 0.001033
2018-03-08 20:55:37 iter 50 loss = 0.001629
2018-03-08 20:55:41 iter 75 loss = 0.001411
2018-03-08 20:55:46 iter 100 loss = 0.001276
2018-03-08 20:55:50 iter 125 loss = 0.000959
2018-03-08 20:55:50 epoch 445/500 average_loss = 0.002686

2018-03-08 20:55:50 start epoch 446/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:55:51 iter 1 loss = 0.001359
2018-03-08 20:55:55 iter 25 loss = 0.002194
2018-03-08 20:56:00 iter 50 loss = 0.002382
2018-03-08 20:56:04 iter 75 loss = 0.000936
2018-03-08 20:56:09 iter 100 loss = 0.001862
2018-03-08 20:56:13 iter 125 loss = 0.001481
2018-03-08 20:56:13 epoch 446/500 average_loss = 0.001509

2018-03-08 20:56:13 start epoch 447/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:56:13 iter 1 loss = 0.001629
2018-03-08 20:56:18 iter 25 loss = 0.001622
2018-03-08 20:56:22 iter 50 loss = 0.002856
2018-03-08 20:56:27 iter 75 loss = 0.002133
2018-03-08 20:56:31 iter 100 loss = 0.003112
2018-03-08 20:56:36 iter 125 loss = 0.001265
2018-03-08 20:56:36 epoch 447/500 average_loss = 0.002486

2018-03-08 20:56:36 start epoch 448/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:56:36 iter 1 loss = 0.001225
2018-03-08 20:56:41 iter 25 loss = 0.001115
2018-03-08 20:56:45 iter 50 loss = 0.001467
2018-03-08 20:56:50 iter 75 loss = 0.001981
2018-03-08 20:56:54 iter 100 loss = 0.003594
2018-03-08 20:56:59 iter 125 loss = 0.001307
2018-03-08 20:56:59 epoch 448/500 average_loss = 0.002267

2018-03-08 20:56:59 start epoch 449/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:56:59 iter 1 loss = 0.001285
2018-03-08 20:57:03 iter 25 loss = 0.002142
2018-03-08 20:57:08 iter 50 loss = 0.001278
2018-03-08 20:57:12 iter 75 loss = 0.001326
2018-03-08 20:57:17 iter 100 loss = 0.001127
2018-03-08 20:57:21 iter 125 loss = 0.001440
2018-03-08 20:57:21 epoch 449/500 average_loss = 0.001731

2018-03-08 20:57:21 start epoch 450/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:57:22 iter 1 loss = 0.001930
2018-03-08 20:57:26 iter 25 loss = 0.001103
2018-03-08 20:57:30 iter 50 loss = 0.003131
2018-03-08 20:57:35 iter 75 loss = 0.001611
2018-03-08 20:57:39 iter 100 loss = 0.001199
2018-03-08 20:57:44 iter 125 loss = 0.001385
2018-03-08 20:57:44 epoch 450/500 average_loss = 0.001591

2018-03-08 20:57:44 start epoch 451/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:57:44 iter 1 loss = 0.001148
2018-03-08 20:57:49 iter 25 loss = 0.001140
2018-03-08 20:57:53 iter 50 loss = 0.001903
2018-03-08 20:57:58 iter 75 loss = 0.002406
2018-03-08 20:58:02 iter 100 loss = 0.001375
2018-03-08 20:58:07 iter 125 loss = 0.002684
2018-03-08 20:58:07 epoch 451/500 average_loss = 0.004318

2018-03-08 20:58:07 start epoch 452/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:58:07 iter 1 loss = 0.002467
2018-03-08 20:58:11 iter 25 loss = 0.002094
2018-03-08 20:58:16 iter 50 loss = 0.004822
2018-03-08 20:58:20 iter 75 loss = 0.001615
2018-03-08 20:58:25 iter 100 loss = 0.003543
2018-03-08 20:58:29 iter 125 loss = 0.001626
2018-03-08 20:58:29 epoch 452/500 average_loss = 0.002789

2018-03-08 20:58:29 start epoch 453/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:58:30 iter 1 loss = 0.001273
2018-03-08 20:58:34 iter 25 loss = 0.002015
2018-03-08 20:58:39 iter 50 loss = 0.001890
2018-03-08 20:58:43 iter 75 loss = 0.001242
2018-03-08 20:58:48 iter 100 loss = 0.002342
2018-03-08 20:58:52 iter 125 loss = 0.005177
2018-03-08 20:58:52 epoch 453/500 average_loss = 0.001819

2018-03-08 20:58:52 start epoch 454/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:58:52 iter 1 loss = 0.002132
2018-03-08 20:58:57 iter 25 loss = 0.001222
2018-03-08 20:59:01 iter 50 loss = 0.001636
2018-03-08 20:59:06 iter 75 loss = 0.001004
2018-03-08 20:59:10 iter 100 loss = 0.001574
2018-03-08 20:59:15 iter 125 loss = 0.001606
2018-03-08 20:59:15 epoch 454/500 average_loss = 0.002032

2018-03-08 20:59:15 start epoch 455/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:59:15 iter 1 loss = 0.002706
2018-03-08 20:59:20 iter 25 loss = 0.008583
2018-03-08 20:59:24 iter 50 loss = 0.001896
2018-03-08 20:59:29 iter 75 loss = 0.000842
2018-03-08 20:59:33 iter 100 loss = 0.000751
2018-03-08 20:59:38 iter 125 loss = 0.001298
2018-03-08 20:59:38 epoch 455/500 average_loss = 0.001837

2018-03-08 20:59:38 start epoch 456/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 20:59:38 iter 1 loss = 0.001533
2018-03-08 20:59:42 iter 25 loss = 0.001938
2018-03-08 20:59:47 iter 50 loss = 0.003480
2018-03-08 20:59:51 iter 75 loss = 0.000987
2018-03-08 20:59:56 iter 100 loss = 0.001005
2018-03-08 21:00:00 iter 125 loss = 0.002302
2018-03-08 21:00:00 epoch 456/500 average_loss = 0.002128

2018-03-08 21:00:00 start epoch 457/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 21:00:01 iter 1 loss = 0.000915
2018-03-08 21:00:05 iter 25 loss = 0.002193
2018-03-08 21:00:10 iter 50 loss = 0.000788
2018-03-08 21:00:14 iter 75 loss = 0.001119
2018-03-08 21:00:19 iter 100 loss = 0.001167
2018-03-08 21:00:23 iter 125 loss = 0.001223
2018-03-08 21:00:23 epoch 457/500 average_loss = 0.001533

2018-03-08 21:00:23 start epoch 458/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 21:00:23 iter 1 loss = 0.001180
2018-03-08 21:00:28 iter 25 loss = 0.003704
2018-03-08 21:00:32 iter 50 loss = 0.000825
2018-03-08 21:00:37 iter 75 loss = 0.001019
2018-03-08 21:00:41 iter 100 loss = 0.001326
2018-03-08 21:00:46 iter 125 loss = 0.001885
2018-03-08 21:00:46 epoch 458/500 average_loss = 0.001933

2018-03-08 21:00:46 start epoch 459/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 21:00:46 iter 1 loss = 0.000711
2018-03-08 21:00:51 iter 25 loss = 0.001020
2018-03-08 21:00:55 iter 50 loss = 0.000751
2018-03-08 21:01:00 iter 75 loss = 0.001423
2018-03-08 21:01:04 iter 100 loss = 0.000765
2018-03-08 21:01:09 iter 125 loss = 0.000850
2018-03-08 21:01:09 epoch 459/500 average_loss = 0.001554

2018-03-08 21:01:09 start epoch 460/500: learning_rate = 2.951479051793532e-05 sequence_len = 28
2018-03-08 21:01:09 iter 1 loss = 0.001032
2018-03-08 21:01:13 iter 25 loss = 0.002989
2018-03-08 21:01:18 iter 50 loss = 0.001412
2018-03-08 21:01:22 iter 75 loss = 0.001355
2018-03-08 21:01:27 iter 100 loss = 0.001186
2018-03-08 21:01:31 iter 125 loss = 0.000909
2018-03-08 21:01:31 epoch 460/500 average_loss = 0.001593

2018-03-08 21:01:31 start epoch 461/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:01:32 iter 1 loss = 0.000666
2018-03-08 21:01:36 iter 25 loss = 0.001468
2018-03-08 21:01:40 iter 50 loss = 0.001144
2018-03-08 21:01:45 iter 75 loss = 0.000899
2018-03-08 21:01:49 iter 100 loss = 0.001089
2018-03-08 21:01:54 iter 125 loss = 0.000919
2018-03-08 21:01:54 epoch 461/500 average_loss = 0.001432

2018-03-08 21:01:54 start epoch 462/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:01:54 iter 1 loss = 0.001770
2018-03-08 21:01:59 iter 25 loss = 0.000971
2018-03-08 21:02:03 iter 50 loss = 0.001458
2018-03-08 21:02:08 iter 75 loss = 0.000837
2018-03-08 21:02:12 iter 100 loss = 0.001201
2018-03-08 21:02:17 iter 125 loss = 0.001435
2018-03-08 21:02:17 epoch 462/500 average_loss = 0.001429

2018-03-08 21:02:17 start epoch 463/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:02:17 iter 1 loss = 0.001194
2018-03-08 21:02:21 iter 25 loss = 0.001123
2018-03-08 21:02:26 iter 50 loss = 0.001294
2018-03-08 21:02:30 iter 75 loss = 0.001379
2018-03-08 21:02:35 iter 100 loss = 0.000811
2018-03-08 21:02:39 iter 125 loss = 0.001020
2018-03-08 21:02:39 epoch 463/500 average_loss = 0.001433

2018-03-08 21:02:39 start epoch 464/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:02:40 iter 1 loss = 0.000518
2018-03-08 21:02:44 iter 25 loss = 0.001174
2018-03-08 21:02:49 iter 50 loss = 0.001762
2018-03-08 21:02:53 iter 75 loss = 0.002253
2018-03-08 21:02:58 iter 100 loss = 0.000722
2018-03-08 21:03:02 iter 125 loss = 0.000778
2018-03-08 21:03:02 epoch 464/500 average_loss = 0.001279

2018-03-08 21:03:02 start epoch 465/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:03:03 iter 1 loss = 0.000689
2018-03-08 21:03:07 iter 25 loss = 0.000831
2018-03-08 21:03:12 iter 50 loss = 0.001190
2018-03-08 21:03:16 iter 75 loss = 0.000992
2018-03-08 21:03:21 iter 100 loss = 0.000938
2018-03-08 21:03:25 iter 125 loss = 0.000786
2018-03-08 21:03:25 epoch 465/500 average_loss = 0.001251

2018-03-08 21:03:25 start epoch 466/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:03:26 iter 1 loss = 0.001211
2018-03-08 21:03:30 iter 25 loss = 0.001321
2018-03-08 21:03:34 iter 50 loss = 0.002239
2018-03-08 21:03:39 iter 75 loss = 0.000706
2018-03-08 21:03:44 iter 100 loss = 0.000710
2018-03-08 21:03:48 iter 125 loss = 0.001794
2018-03-08 21:03:48 epoch 466/500 average_loss = 0.001304

2018-03-08 21:03:48 start epoch 467/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:03:48 iter 1 loss = 0.000871
2018-03-08 21:03:53 iter 25 loss = 0.001286
2018-03-08 21:03:57 iter 50 loss = 0.000876
2018-03-08 21:04:02 iter 75 loss = 0.001053
2018-03-08 21:04:06 iter 100 loss = 0.000700
2018-03-08 21:04:11 iter 125 loss = 0.000847
2018-03-08 21:04:11 epoch 467/500 average_loss = 0.001246

2018-03-08 21:04:11 start epoch 468/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:04:11 iter 1 loss = 0.001055
2018-03-08 21:04:15 iter 25 loss = 0.001088
2018-03-08 21:04:20 iter 50 loss = 0.000956
2018-03-08 21:04:24 iter 75 loss = 0.000893
2018-03-08 21:04:29 iter 100 loss = 0.000733
2018-03-08 21:04:33 iter 125 loss = 0.002067
2018-03-08 21:04:33 epoch 468/500 average_loss = 0.001248

2018-03-08 21:04:33 start epoch 469/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:04:34 iter 1 loss = 0.002212
2018-03-08 21:04:38 iter 25 loss = 0.000881
2018-03-08 21:04:42 iter 50 loss = 0.000649
2018-03-08 21:04:47 iter 75 loss = 0.001098
2018-03-08 21:04:52 iter 100 loss = 0.000914
2018-03-08 21:04:56 iter 125 loss = 0.001437
2018-03-08 21:04:56 epoch 469/500 average_loss = 0.001155

2018-03-08 21:04:56 start epoch 470/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:04:56 iter 1 loss = 0.001383
2018-03-08 21:05:01 iter 25 loss = 0.001218
2018-03-08 21:05:05 iter 50 loss = 0.003694
2018-03-08 21:05:10 iter 75 loss = 0.000770
2018-03-08 21:05:14 iter 100 loss = 0.000884
2018-03-08 21:05:19 iter 125 loss = 0.003808
2018-03-08 21:05:19 epoch 470/500 average_loss = 0.002110

2018-03-08 21:05:19 start epoch 471/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:05:19 iter 1 loss = 0.000933
2018-03-08 21:05:23 iter 25 loss = 0.001976
2018-03-08 21:05:28 iter 50 loss = 0.000917
2018-03-08 21:05:33 iter 75 loss = 0.000881
2018-03-08 21:05:37 iter 100 loss = 0.001107
2018-03-08 21:05:42 iter 125 loss = 0.000800
2018-03-08 21:05:42 epoch 471/500 average_loss = 0.001211

2018-03-08 21:05:42 start epoch 472/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:05:42 iter 1 loss = 0.001108
2018-03-08 21:05:46 iter 25 loss = 0.000719
2018-03-08 21:05:51 iter 50 loss = 0.000847
2018-03-08 21:05:55 iter 75 loss = 0.002146
2018-03-08 21:06:00 iter 100 loss = 0.002431
2018-03-08 21:06:04 iter 125 loss = 0.001050
2018-03-08 21:06:04 epoch 472/500 average_loss = 0.001283

2018-03-08 21:06:04 start epoch 473/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:06:05 iter 1 loss = 0.001157
2018-03-08 21:06:09 iter 25 loss = 0.000754
2018-03-08 21:06:13 iter 50 loss = 0.002151
2018-03-08 21:06:18 iter 75 loss = 0.001117
2018-03-08 21:06:22 iter 100 loss = 0.000692
2018-03-08 21:06:27 iter 125 loss = 0.000782
2018-03-08 21:06:27 epoch 473/500 average_loss = 0.001263

2018-03-08 21:06:27 start epoch 474/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:06:27 iter 1 loss = 0.000562
2018-03-08 21:06:32 iter 25 loss = 0.000887
2018-03-08 21:06:36 iter 50 loss = 0.002378
2018-03-08 21:06:41 iter 75 loss = 0.001389
2018-03-08 21:06:45 iter 100 loss = 0.002842
2018-03-08 21:06:50 iter 125 loss = 0.001588
2018-03-08 21:06:50 epoch 474/500 average_loss = 0.005390

2018-03-08 21:06:50 start epoch 475/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:06:50 iter 1 loss = 0.001261
2018-03-08 21:06:54 iter 25 loss = 0.004410
2018-03-08 21:06:59 iter 50 loss = 0.001117
2018-03-08 21:07:03 iter 75 loss = 0.002577
2018-03-08 21:07:08 iter 100 loss = 0.000765
2018-03-08 21:07:12 iter 125 loss = 0.001090
2018-03-08 21:07:12 epoch 475/500 average_loss = 0.001460

2018-03-08 21:07:12 start epoch 476/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:07:13 iter 1 loss = 0.001181
2018-03-08 21:07:17 iter 25 loss = 0.001214
2018-03-08 21:07:22 iter 50 loss = 0.001170
2018-03-08 21:07:26 iter 75 loss = 0.001045
2018-03-08 21:07:31 iter 100 loss = 0.001074
2018-03-08 21:07:35 iter 125 loss = 0.001646
2018-03-08 21:07:35 epoch 476/500 average_loss = 0.001637

2018-03-08 21:07:35 start epoch 477/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:07:36 iter 1 loss = 0.001172
2018-03-08 21:07:40 iter 25 loss = 0.000741
2018-03-08 21:07:44 iter 50 loss = 0.001608
2018-03-08 21:07:49 iter 75 loss = 0.000996
2018-03-08 21:07:53 iter 100 loss = 0.001148
2018-03-08 21:07:58 iter 125 loss = 0.001188
2018-03-08 21:07:58 epoch 477/500 average_loss = 0.001787

2018-03-08 21:07:58 start epoch 478/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:07:58 iter 1 loss = 0.000946
2018-03-08 21:08:03 iter 25 loss = 0.003484
2018-03-08 21:08:07 iter 50 loss = 0.001864
2018-03-08 21:08:12 iter 75 loss = 0.001749
2018-03-08 21:08:16 iter 100 loss = 0.001096
2018-03-08 21:08:21 iter 125 loss = 0.000686
2018-03-08 21:08:21 epoch 478/500 average_loss = 0.001287

2018-03-08 21:08:21 start epoch 479/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:08:21 iter 1 loss = 0.003537
2018-03-08 21:08:25 iter 25 loss = 0.001509
2018-03-08 21:08:30 iter 50 loss = 0.001224
2018-03-08 21:08:35 iter 75 loss = 0.000771
2018-03-08 21:08:39 iter 100 loss = 0.001686
2018-03-08 21:08:44 iter 125 loss = 0.000980
2018-03-08 21:08:44 epoch 479/500 average_loss = 0.001289

2018-03-08 21:08:44 start epoch 480/500: learning_rate = 2.3611832414348257e-05 sequence_len = 28
2018-03-08 21:08:44 iter 1 loss = 0.000493
2018-03-08 21:08:48 iter 25 loss = 0.000599
2018-03-08 21:08:53 iter 50 loss = 0.001279
2018-03-08 21:08:57 iter 75 loss = 0.000965
2018-03-08 21:09:02 iter 100 loss = 0.001172
2018-03-08 21:09:06 iter 125 loss = 0.000737
2018-03-08 21:09:06 epoch 480/500 average_loss = 0.002189

2018-03-08 21:09:06 start epoch 481/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:09:07 iter 1 loss = 0.001380
2018-03-08 21:09:11 iter 25 loss = 0.002116
2018-03-08 21:09:16 iter 50 loss = 0.000649
2018-03-08 21:09:20 iter 75 loss = 0.001703
2018-03-08 21:09:25 iter 100 loss = 0.000644
2018-03-08 21:09:29 iter 125 loss = 0.000894
2018-03-08 21:09:29 epoch 481/500 average_loss = 0.001356

2018-03-08 21:09:29 start epoch 482/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:09:29 iter 1 loss = 0.000961
2018-03-08 21:09:34 iter 25 loss = 0.001835
2018-03-08 21:09:38 iter 50 loss = 0.001042
2018-03-08 21:09:43 iter 75 loss = 0.000904
2018-03-08 21:09:47 iter 100 loss = 0.001196
2018-03-08 21:09:52 iter 125 loss = 0.005293
2018-03-08 21:09:52 epoch 482/500 average_loss = 0.001265

2018-03-08 21:09:52 start epoch 483/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:09:52 iter 1 loss = 0.000585
2018-03-08 21:09:57 iter 25 loss = 0.000686
2018-03-08 21:10:01 iter 50 loss = 0.001466
2018-03-08 21:10:06 iter 75 loss = 0.000875
2018-03-08 21:10:10 iter 100 loss = 0.000824
2018-03-08 21:10:15 iter 125 loss = 0.003656
2018-03-08 21:10:15 epoch 483/500 average_loss = 0.001223

2018-03-08 21:10:15 start epoch 484/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:10:15 iter 1 loss = 0.001126
2018-03-08 21:10:19 iter 25 loss = 0.001268
2018-03-08 21:10:24 iter 50 loss = 0.000955
2018-03-08 21:10:28 iter 75 loss = 0.000611
2018-03-08 21:10:33 iter 100 loss = 0.010981
2018-03-08 21:10:37 iter 125 loss = 0.000830
2018-03-08 21:10:37 epoch 484/500 average_loss = 0.001729

2018-03-08 21:10:37 start epoch 485/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:10:38 iter 1 loss = 0.000721
2018-03-08 21:10:42 iter 25 loss = 0.001453
2018-03-08 21:10:47 iter 50 loss = 0.000907
2018-03-08 21:10:51 iter 75 loss = 0.001237
2018-03-08 21:10:56 iter 100 loss = 0.001646
2018-03-08 21:11:00 iter 125 loss = 0.001035
2018-03-08 21:11:00 epoch 485/500 average_loss = 0.001396

2018-03-08 21:11:00 start epoch 486/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:11:01 iter 1 loss = 0.002101
2018-03-08 21:11:05 iter 25 loss = 0.000941
2018-03-08 21:11:09 iter 50 loss = 0.001291
2018-03-08 21:11:14 iter 75 loss = 0.001335
2018-03-08 21:11:18 iter 100 loss = 0.000530
2018-03-08 21:11:23 iter 125 loss = 0.001476
2018-03-08 21:11:23 epoch 486/500 average_loss = 0.001446

2018-03-08 21:11:23 start epoch 487/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:11:23 iter 1 loss = 0.001004
2018-03-08 21:11:28 iter 25 loss = 0.000797
2018-03-08 21:11:32 iter 50 loss = 0.000981
2018-03-08 21:11:37 iter 75 loss = 0.001005
2018-03-08 21:11:41 iter 100 loss = 0.000975
2018-03-08 21:11:46 iter 125 loss = 0.000755
2018-03-08 21:11:46 epoch 487/500 average_loss = 0.001143

2018-03-08 21:11:46 start epoch 488/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:11:46 iter 1 loss = 0.000509
2018-03-08 21:11:50 iter 25 loss = 0.000829
2018-03-08 21:11:55 iter 50 loss = 0.000724
2018-03-08 21:11:59 iter 75 loss = 0.001673
2018-03-08 21:12:04 iter 100 loss = 0.000795
2018-03-08 21:12:08 iter 125 loss = 0.000905
2018-03-08 21:12:08 epoch 488/500 average_loss = 0.001290

2018-03-08 21:12:08 start epoch 489/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:12:09 iter 1 loss = 0.000862
2018-03-08 21:12:13 iter 25 loss = 0.000742
2018-03-08 21:12:18 iter 50 loss = 0.000874
2018-03-08 21:12:22 iter 75 loss = 0.000842
2018-03-08 21:12:27 iter 100 loss = 0.001200
2018-03-08 21:12:31 iter 125 loss = 0.000842
2018-03-08 21:12:31 epoch 489/500 average_loss = 0.001330

2018-03-08 21:12:31 start epoch 490/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:12:32 iter 1 loss = 0.001670
2018-03-08 21:12:36 iter 25 loss = 0.000963
2018-03-08 21:12:40 iter 50 loss = 0.000924
2018-03-08 21:12:45 iter 75 loss = 0.000760
2018-03-08 21:12:49 iter 100 loss = 0.000698
2018-03-08 21:12:54 iter 125 loss = 0.000662
2018-03-08 21:12:54 epoch 490/500 average_loss = 0.001343

2018-03-08 21:12:54 start epoch 491/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:12:54 iter 1 loss = 0.000636
2018-03-08 21:12:59 iter 25 loss = 0.001814
2018-03-08 21:13:03 iter 50 loss = 0.000612
2018-03-08 21:13:08 iter 75 loss = 0.000804
2018-03-08 21:13:12 iter 100 loss = 0.009381
2018-03-08 21:13:17 iter 125 loss = 0.001741
2018-03-08 21:13:17 epoch 491/500 average_loss = 0.002775

2018-03-08 21:13:17 start epoch 492/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:13:17 iter 1 loss = 0.001386
2018-03-08 21:13:22 iter 25 loss = 0.001022
2018-03-08 21:13:26 iter 50 loss = 0.001408
2018-03-08 21:13:31 iter 75 loss = 0.001161
2018-03-08 21:13:35 iter 100 loss = 0.001274
2018-03-08 21:13:40 iter 125 loss = 0.000902
2018-03-08 21:13:40 epoch 492/500 average_loss = 0.001394

2018-03-08 21:13:40 start epoch 493/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:13:40 iter 1 loss = 0.000686
2018-03-08 21:13:44 iter 25 loss = 0.004617
2018-03-08 21:13:49 iter 50 loss = 0.000774
2018-03-08 21:13:53 iter 75 loss = 0.001433
2018-03-08 21:13:58 iter 100 loss = 0.000886
2018-03-08 21:14:02 iter 125 loss = 0.000697
2018-03-08 21:14:02 epoch 493/500 average_loss = 0.001244

2018-03-08 21:14:02 start epoch 494/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:14:03 iter 1 loss = 0.000820
2018-03-08 21:14:07 iter 25 loss = 0.001007
2018-03-08 21:14:12 iter 50 loss = 0.002652
2018-03-08 21:14:16 iter 75 loss = 0.000586
2018-03-08 21:14:21 iter 100 loss = 0.000584
2018-03-08 21:14:25 iter 125 loss = 0.000959
2018-03-08 21:14:25 epoch 494/500 average_loss = 0.001439

2018-03-08 21:14:25 start epoch 495/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:14:25 iter 1 loss = 0.000609
2018-03-08 21:14:30 iter 25 loss = 0.001182
2018-03-08 21:14:34 iter 50 loss = 0.001590
2018-03-08 21:14:39 iter 75 loss = 0.001118
2018-03-08 21:14:43 iter 100 loss = 0.000596
2018-03-08 21:14:48 iter 125 loss = 0.001191
2018-03-08 21:14:48 epoch 495/500 average_loss = 0.001554

2018-03-08 21:14:48 start epoch 496/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:14:48 iter 1 loss = 0.001375
2018-03-08 21:14:53 iter 25 loss = 0.000688
2018-03-08 21:14:57 iter 50 loss = 0.001134
2018-03-08 21:15:02 iter 75 loss = 0.000593
2018-03-08 21:15:06 iter 100 loss = 0.001418
2018-03-08 21:15:11 iter 125 loss = 0.001072
2018-03-08 21:15:11 epoch 496/500 average_loss = 0.001112

2018-03-08 21:15:11 start epoch 497/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:15:11 iter 1 loss = 0.003334
2018-03-08 21:15:16 iter 25 loss = 0.002180
2018-03-08 21:15:20 iter 50 loss = 0.002588
2018-03-08 21:15:25 iter 75 loss = 0.000807
2018-03-08 21:15:29 iter 100 loss = 0.000751
2018-03-08 21:15:34 iter 125 loss = 0.000556
2018-03-08 21:15:34 epoch 497/500 average_loss = 0.001174

2018-03-08 21:15:34 start epoch 498/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:15:34 iter 1 loss = 0.001050
2018-03-08 21:15:38 iter 25 loss = 0.000939
2018-03-08 21:15:43 iter 50 loss = 0.000931
2018-03-08 21:15:47 iter 75 loss = 0.002644
2018-03-08 21:15:52 iter 100 loss = 0.000711
2018-03-08 21:15:56 iter 125 loss = 0.001343
2018-03-08 21:15:56 epoch 498/500 average_loss = 0.001144

2018-03-08 21:15:56 start epoch 499/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:15:57 iter 1 loss = 0.000598
2018-03-08 21:16:01 iter 25 loss = 0.000959
2018-03-08 21:16:06 iter 50 loss = 0.000645
2018-03-08 21:16:10 iter 75 loss = 0.002412
2018-03-08 21:16:15 iter 100 loss = 0.000886
2018-03-08 21:16:19 iter 125 loss = 0.001098
2018-03-08 21:16:19 epoch 499/500 average_loss = 0.001268

2018-03-08 21:16:19 start epoch 500/500: learning_rate = 1.888946593147861e-05 sequence_len = 28
2018-03-08 21:16:19 iter 1 loss = 0.001221
2018-03-08 21:16:24 iter 25 loss = 0.000572
2018-03-08 21:16:28 iter 50 loss = 0.000750
2018-03-08 21:16:33 iter 75 loss = 0.001012
2018-03-08 21:16:37 iter 100 loss = 0.001303
2018-03-08 21:16:42 iter 125 loss = 0.000585
2018-03-08 21:16:42 epoch 500/500 average_loss = 0.001174
